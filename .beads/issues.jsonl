{"id":"bd-0i8","title":"Task 3: Create team-executing-plans skill","design":"## Goal\nCreate skills/team-executing-plans/SKILL.md ‚Äî a new skill that spawns agent teams from wave tasks, coordinates execution with hybrid delegation (Option C), reviews results at wave boundaries, reconciles beads state, and plans next waves with mandatory STOP checkpoints.\n\n## Context\nCompleted bd-7yn: Brainstorming skill now produces epics with Parallelism Map.\nCompleted bd-b5u: Wave-planning skill creates task batches with beads dependencies from Parallelism Map.\n\nThis skill is the execution engine for the team path:\n\\`\\`\\`\nbrainstorming ‚Üí sre-task-refinement ‚Üí wave-planning ‚Üí team-executing-plans\n\\`\\`\\`\n\n## Effort Estimate\n4-6 hours (single skill file, complex process design with spawn template)\n\n## Implementation\n\n### Step 1: Study reference materials\n- Read skills/executing-plans/SKILL.md ‚Äî Focus on: STOP checkpoint pattern, epic immutability enforcement, substep tracking via TodoWrite, resumption check pattern\n- Read skills/wave-planning/SKILL.md ‚Äî Focus on: wave task structure (file ownership, epic context), how tasks are linked to epic, wave sizing\n- Read agents/test-runner.md ‚Äî Focus on: agent definition format (frontmatter fields), how subagent_type maps to agent files\n- Study Claude Code agent teams documentation (code.claude.com/docs/en/agent-teams) ‚Äî Extract: how to spawn teams via Task tool, delegate mode syntax, plan approval mechanism, teammate communication protocol\n- Study Claude Code subagent features (code.claude.com/docs/en/sub-agents) ‚Äî Extract: memory parameter, permissionMode options, skills injection, hooks parameter, disallowedTools\n\n### Step 2: Create the skill file\nCreate skills/team-executing-plans/SKILL.md with the standard skill structure.\n\n**Frontmatter:**\n\\`\\`\\`yaml\n---\nname: team-executing-plans\ndescription: Use after wave-planning to spawn agent teams for parallel wave execution - coordinates teammates with hybrid delegation, reviews results at wave boundaries, reconciles beads state\n---\n\\`\\`\\`\n\n**Core Process (the_process section):**\n\n1. **Load Wave Context**\n   - \\`bd show \u003cepic-id\u003e\\` ‚Äî Load epic requirements, anti-patterns\n   - \\`bd ready\\` ‚Äî Find wave tasks ready for execution\n   - Verify wave tasks exist and are independent (no blocking deps between them)\n   - If only 1 wave task exists: fall back to solo execution (use executing-plans skill). Do NOT spawn a team for a single task.\n\n2. **Prepare Teammate Spawn Prompts**\n   For each wave task, construct a teammate prompt using this template:\n\n   \\`\\`\\`\n   You are a teammate executing one task in a parallel wave. Work independently.\n\n   ## Your Task\n   [Paste full bd show output for this task]\n\n   ## Epic Contract (IMMUTABLE)\n   **Requirements:** [Copy from epic]\n   **Anti-Patterns (FORBIDDEN):** [Copy from epic]\n\n   ## File Ownership Boundaries\n   **You OWN (modify these files only):**\n   - [exclusive file paths from task]\n\n   **You MUST NOT modify (owned by other teammates):**\n   - [file paths from other wave tasks]\n\n   **Shared files (read-only for you, coordination handled by [task/wave]):**\n   - [shared file paths]\n\n   ## Methodology\n   - Follow TDD: Write test first (RED) ‚Üí implement minimal code (GREEN) ‚Üí refactor ‚Üí commit\n   - Before claiming done: run all tests, capture output as evidence\n   - Commit after each GREEN phase\n\n   ## Beads Constraints\n   - RUN: \\`bd update \u003cyour-task-id\u003e --status in_progress\\` when you start\n   - RUN: \\`bd close \u003cyour-task-id\u003e\\` when all success criteria met\n   - DO NOT RUN: \\`bd sync\\`, \\`bd create\\`, \\`bd dep add\\`, or any other bd commands\n   - DO NOT modify any other task's status\n\n   ## Communication Protocol\n   - If you discover work that should be done but is NOT in your task: note it in your final summary (lead will create a task)\n   - If you hit a blocker that prevents completion: stop and report the blocker in your summary\n   - DO NOT attempt to fix problems outside your file ownership boundary\n   - DO NOT communicate with other teammates directly\n   \\`\\`\\`\n\n3. **Spawn Agent Team (Lead in Delegate Mode)**\n   - Lead enters delegate mode: coordinate only, no implementation\n   - For each wave task, spawn a teammate using the Task tool:\n     \\`\\`\\`\n     Task tool:\n       subagent_type: general-purpose\n       prompt: [teammate spawn prompt from Step 2]\n       run_in_background: true\n       model: [sonnet by default, or opus for high-complexity tasks]\n     \\`\\`\\`\n   - Spawn ALL teammates in a single message (parallel execution)\n   - Lead monitors progress via TaskOutput (non-blocking checks)\n   - Lead does NOT implement any code during team execution\n\n4. **Collect and Review Wave Results**\n   After all teammates finish (or time out):\n\n   **a) Collect results:**\n   - Read each teammate's output via TaskOutput\n   - Note: success/partial/failed status for each\n\n   **b) Verify success criteria:**\n   - For each task: check if teammate reported all criteria met\n   - Run integration tests via test-runner agent: test suite covering wave deliverables\n\n   **c) Check for file ownership violations:**\n   - Run \\`git diff --name-only\\` to see all changed files\n   - Cross-reference against each task's file ownership boundaries\n   - If a file was modified by a teammate who doesn't own it: FLAG as violation\n   - Remediation: revert the violating changes (\\`git checkout -- \u003cfile\u003e\\`) and note for user\n\n   **d) Reconcile beads state:**\n   - \\`bd show \u003ctask-id\u003e\\` for each wave task ‚Äî verify status\n   - If teammate succeeded but didn't close task: \\`bd close \u003ctask-id\u003e --reason \"Completed by teammate, lead reconciliation\"\\`\n   - If teammate failed: keep task open, add notes with failure reason\n   - Run \\`bd sync\\` to push beads state to git\n\n5. **Present Wave Review Summary and STOP**\n   Present comprehensive review summary (see template in success criteria).\n   **STOP and wait for user review. Mandatory.**\n\n**Key Design Decisions:**\n- Lead operates in delegate mode during spawning (coordinate only, no implementation)\n- Teammates execute independently; all coordination flows through lead\n- STOP at wave boundaries is mandatory (epic anti-pattern)\n- Beads reconciliation happens after teammate completion (lead handles sync)\n- Teammate prompts are comprehensive (teammates have zero context without them)\n- Degenerate case (1 wave task): fall back to solo execution, not team\n- Default teammate model: sonnet (cost-efficient), use opus for high-complexity streams\n\n### Step 3: Define teammate spawn prompt template\nAlready defined inline in Step 2 above. The template includes all 7 required components:\n1. Role description\n2. Epic requirements and anti-patterns\n3. Task-specific details (from bd show)\n4. File ownership boundaries\n5. Methodology (TDD, verification)\n6. Beads constraints\n7. Communication protocol\n\n### Step 4: Add examples\nInclude 2 examples:\n1. **Good example:** 3 teammates execute Wave 2 (OAuth providers) successfully. Lead collects results, runs integration tests, reconciles beads, proposes Wave 3. Shows per-teammate results table.\n2. **Bad example:** Lead implements a fix for a teammate's failing test instead of flagging it. Violates delegate mode. Shows why this is wrong and the correct approach (flag to user at STOP checkpoint).\n\n### Step 5: Add integration section\nDocument the call chain:\n- Called by: wave-planning (after user approves wave), or user directly\n- Calls: test-runner agent (for integration verification after wave), wave-planning (handoff for next wave creation)\n- Uses: bd commands (show, close, sync), Task tool (for teammate spawning with run_in_background: true), TaskOutput (for collecting results)\n\n## Success Criteria\n- [ ] skills/team-executing-plans/SKILL.md exists with standard skill structure (frontmatter, overview, rigidity, quick_reference, when_to_use, the_process, examples, critical_rules, verification_checklist, integration, resources)\n- [ ] Skill spawns agent teams from wave tasks using Task tool with run_in_background: true\n- [ ] Lead operates in delegate mode (coordinate only, no implementation during team execution)\n- [ ] Teammate spawn prompts include ALL of: epic requirements, task details, anti-patterns, file ownership boundaries (owns + must-not-touch + shared), TDD methodology, verification-before-completion methodology\n- [ ] Teammates constrained to: bd update --status and bd close for own task only; NO bd sync, create, or dep add\n- [ ] Wave review includes: per-teammate results table, integration test verification via test-runner agent, beads reconciliation (verify/fix task statuses + bd sync), next wave proposal with learnings\n- [ ] Mandatory STOP checkpoint at wave boundary with comprehensive review summary\n- [ ] Two examples included: successful 3-teammate wave execution + delegate mode violation\n- [ ] Integration section documents full call chain (wave-planning ‚Üí team-executing-plans ‚Üí test-runner ‚Üí wave-planning)\n- [ ] Hybrid delegation model documented: teammates execute + propose new work in summary, lead reviews proposals and approves/rejects scope changes at STOP checkpoint\n- [ ] Degenerate case handled: if only 1 wave task, fall back to solo execution (executing-plans)\n- [ ] File ownership violation detection: git diff --name-only cross-referenced against task boundaries, with revert remediation\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO lead implementing alongside teammates (delegate mode = coordinate only)\n- ‚ùå NO teammates creating bd tasks or managing dependencies (lead manages all bd create, dep add)\n- ‚ùå NO teammates running bd sync (lead handles git sync at wave boundaries)\n- ‚ùå NO skipping wave-level STOP checkpoints (human must review wave results before next wave)\n- ‚ùå NO continuous multi-wave execution without human checkpoint (each wave boundary is mandatory STOP)\n- ‚ùå NO teammates messaging each other directly (all coordination flows through lead)\n- ‚ùå NO proceeding to next wave without beads reconciliation (verify all task statuses, run bd sync)\n- ‚ùå NO spawning a team for a single task (degenerate case: use solo executing-plans instead)\n- ‚ùå NO teammates editing files outside their assigned ownership boundary\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n### Edge Case: Teammate Timeout/Crash\n- A teammate may time out or crash while others succeed\n- Lead should check TaskOutput with timeout for each teammate\n- If teammate times out: mark task as still open, note timeout in wave review\n- If teammate crashes with error: capture error message, mark task open, include in review\n- Do NOT retry automatically ‚Äî present to user at STOP checkpoint for decision (retry, reassign, skip)\n- Anti-pattern: silently retrying or ignoring failed teammates\n\n### Edge Case: Teammate File Ownership Violation\n- Detection: after all teammates complete, run \\`git diff --name-only\\` and cross-reference against file ownership boundaries from each task\n- If violation found: \\`git checkout -- \u003cviolated-file\u003e\\` to revert unauthorized changes\n- Report violation in wave review summary with: which teammate, which file, what was changed\n- User decides remediation at STOP checkpoint\n\n### Edge Case: All Teammates Fail\n- If ALL teammates fail (0 success): do NOT proceed to next wave\n- Present all failure reasons in wave review\n- User decides: retry wave, switch to solo execution, or abort\n- Anti-pattern: lead trying to \"fix\" failures by implementing (violates delegate mode)\n\n### Edge Case: Beads State Inconsistency\n- Beads daemon serializes writes, so concurrent bd update is safe\n- However: if teammate crashes between task work and bd close, task stays open\n- Lead reconciliation (Step 4d) catches this: verify each task status, close if completed\n- If unsure whether task actually completed: keep open and note for user review\n\n### Edge Case: Degenerate Wave (1 Task)\n- Wave-planning may produce a wave with only 1 task (e.g., infrastructure wave)\n- team-executing-plans should NOT spawn a team for 1 task (coordination overhead \u003e benefit)\n- Fall back to executing-plans (solo) for single-task waves\n- Check at Step 1: if only 1 ready wave task, redirect to executing-plans\n\n### Edge Case: Large Spawn Prompts Exceeding Context\n- Spawn prompt includes full epic requirements + task details + template\n- For very large epics, this could be substantial\n- Mitigation: copy only RELEVANT requirements and anti-patterns (not entire epic)\n- Include a \\`bd show \u003ctask-id\u003e\\` command in the prompt so teammate can reload if needed\n- Anti-pattern: copying entire epic verbatim into every spawn prompt\n\n### Performance Consideration: Teammate Model Selection\n- Default: sonnet (cost-efficient, good for most tasks)\n- Override to opus: when task complexity is high AND task has many edge cases from SRE refinement\n- Document the model choice in wave review summary\n- Epic open question: \"Should all teammates use same model?\" ‚Äî resolve per-task based on complexity estimate from Parallelism Map","status":"closed","priority":1,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-02-06T13:19:56.381443-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-06T13:29:56.903421-05:00","closed_at":"2026-02-06T13:29:56.903421-05:00","close_reason":"Created skills/team-executing-plans/SKILL.md with all 12 success criteria met","dependencies":[{"issue_id":"bd-0i8","depends_on_id":"bd-6t7","type":"parent-child","created_at":"2026-02-06T13:20:02.757273-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-1","title":"Feature: Skill Auto-Activation System with Hooks","design":"## Goal\nAdd comprehensive skill auto-activation system using hooks to ensure skills activate reliably and Claude stays on track during execution.\n\n## Chosen Approach\nModular hook system with three separate hooks (UserPromptSubmit, PostToolUse, Stop) sharing common utilities and skill-rules.json configuration. Shell-based implementation in hooks/ directory at plugin root.\n\n## Success Criteria\n- [ ] All phases complete\n- [ ] skill-rules.json defines rules for all hyperpowers skills\n- [ ] Three hooks implemented and tested\n- [ ] Integration tests passing\n- [ ] Documentation updated\n- [ ] User installation guide created","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-10-30T13:56:46.874868-04:00","updated_at":"2025-10-30T15:44:50.994123-04:00","closed_at":"2025-10-30T15:44:50.994123-04:00"}
{"id":"bd-1eu","title":"Task 2: Add commit verification gate to executing-plans lead validation","design":"## Goal\nUpdate skills/executing-plans/SKILL.md so the lead expects and validates commit hashes in every task completion message before approving proposals.\n\n## Effort Estimate\n1 hour (markdown-only edits to a single file)\n\n## Implementation\n\n### 1. Update task completion message format (lines 137-143)\nAdd ### Commits section to the format summary shown to the lead, matching executor.md's format:\n```\n## Task \u003cid\u003e Complete\n### Done ‚Äî [implementation summary]\n### Commits ‚Äî [hash: message]\n### Learned ‚Äî [discoveries]\n### Changed from plan ‚Äî [deviations]\n### Proposed next task ‚Äî [title, goal, approach, SRE refined]\n```\n\n### 2. Add Step 0 to lead validation (before current step 1 at line 147)\nInsert a new step before the current \"1. Read the summary\":\n\n**0. Verify commit hashes.** Check the executor's message for a `### Commits` section containing at least one entry in the format `\u003cshort hash\u003e: \u003cmessage\u003e`. If the Commits section is missing or empty, do NOT proceed to proposal validation ‚Äî redirect the executor to commit first (see REDIRECT-FOR-COMMITS below).\n\nRenumber existing steps: 1‚Üí1, 2‚Üí2, 3‚Üí3, 4‚Üí4 (no renumber needed, Step 0 is added before 1).\n\n### 3. Add REDIRECT-FOR-COMMITS response template\nAfter the existing REDIRECT template (around line 187), add:\n\n**REDIRECT (missing commits)** ‚Äî Executor did not commit before closing task:\n```\nSendMessage:\n  type: \"message\"\n  recipient: \"executor\"\n  content: \"Task completion message is missing commit hashes. Commit all work for the task before I can evaluate your proposal. Send updated completion message with ### Commits section containing hash and message.\"\n  summary: \"Commit first ‚Äî missing commit hashes\"\n```\n\n### 4. Update example task completion message (lines 511-532)\nAdd ### Commits section to the example between Done and Learned:\n```\n### Commits\n- `a1b2c3d`: feat: implement user registration with bcrypt and input validation\n```\n\n### 5. Add commit hash check to verification checklist (lines 634-639)\nAdd to \"Before approving any proposal:\" section:\n- [ ] Verified ### Commits section contains at least one hash\n\n## Anti-Patterns (Task-Specific)\n- ‚ùå Do NOT require the lead to run git log (lead checks message format only, per epic anti-pattern)\n- ‚ùå Do NOT add hooks for enforcement (per epic anti-pattern)\n- ‚ùå Do NOT change sections outside of the five edits listed above\n\n## Success Criteria\n- [ ] Task completion message format (lines 137-143) includes ### Commits\n- [ ] Step 0 added to lead validation checking for commit hashes with actual format validation\n- [ ] REDIRECT-FOR-COMMITS template added after existing REDIRECT\n- [ ] Example task completion message (lines 511-532) includes ### Commits section\n- [ ] Verification checklist includes commit hash check\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@gmail.com","created_at":"2026-02-15T23:16:46.690769-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T23:18:12.993989-05:00","closed_at":"2026-02-15T23:18:12.993989-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-1eu","depends_on_id":"bd-dxf","type":"parent-child","created_at":"2026-02-15T23:16:52.469775-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-1y1","title":"Create executor agent definition","design":"## Goal\nCreate agents/executor.md ‚Äî the agent prompt that defines how the executor teammate behaves when spawned by the lead during /execute-plan.\n\n## Why First\nThe executor agent definition is the foundation. The lead skill (executing-plans rewrite) and the reviewer agent both reference executor behavior. Starting here establishes the message protocol, TDD expectations, and escalation rules that everything else builds on.\n\n## Effort Estimate\n4-6 hours\n\n## Implementation\n\n### 1. Study existing agent patterns\nRead these files to understand the agent definition format:\n- agents/code-reviewer.md ‚Äî frontmatter fields (name, description with examples, model, memory, skills), prompt structure\n- agents/codebase-investigator.md ‚Äî how agents receive context, how they report findings\n- agents/test-runner.md ‚Äî how agents report results back, permissionMode, disallowedTools\n\nNote the frontmatter fields used: name, description (with XML examples), model, permissionMode, memory, skills, disallowedTools.\n\n### 2. Study the executing-plans skill for behavior to port\nRead skills/executing-plans/SKILL.md and extract:\n- The resumption check pattern (Step 0) ‚Äî how to find active epic and in-progress tasks\n- The TDD cycle: write test ‚Üí run RED ‚Üí implement ‚Üí run GREEN ‚Üí refactor ‚Üí commit\n- How SRE refinement is invoked on new tasks (Skill tool call)\n- How obstacles are handled (check Design Discovery, read anti-patterns)\n- How next tasks are created (bd create with detailed design field)\n- The \"check TodoWrite before closing\" pattern\n\n### 3. Study the agent teams API\nUnderstand available tools for the executor:\n- SendMessage (type: \"message\", recipient: lead name) ‚Äî for structured summaries\n- bd CLI ‚Äî for reading epic/task state (bd show, bd ready, bd update, bd create, bd close, bd dep add)\n- Skill tool ‚Äî for invoking TDD, SRE refinement skills\n- Task tool ‚Äî for dispatching test-runner subagent\n- All standard tools (Read, Edit, Write, Bash, Grep, Glob)\n\n### 4. Write the executor agent definition\nCreate agents/executor.md with these exact sections:\n\n**Frontmatter (required fields):**\n```yaml\n---\nname: executor\ndescription: \"Use this agent...\" with XML examples showing lead spawning executor for epic execution\nmodel: sonnet\npermissionMode: bypassPermissions\nmemory: project\nskills:\n  - test-driven-development\n  - verification-before-completion\n  - sre-task-refinement\n---\n```\n\n**Prompt body ‚Äî Section a: Role**\n- You are an executor agent spawned by a lead to implement bd tasks\n- You work continuously through tasks, sending structured reports to your lead\n- You follow TDD discipline (red-green-refactor-commit) for all implementation\n- You never violate epic anti-patterns or requirements\n\n**Prompt body ‚Äî Section b: Startup Protocol**\n1. Read the epic from bd: `bd show \u003cepic-id\u003e` (epic ID provided in spawn prompt)\n2. Extract and internalize: Requirements (IMMUTABLE), Anti-Patterns (FORBIDDEN), Design Discovery\n3. Read the current task: `bd show \u003ctask-id\u003e` or `bd ready`\n4. If in-progress task exists from previous run: resume it (don't create new)\n5. Mark task in-progress: `bd update \u003cid\u003e --status in_progress`\n\n**Prompt body ‚Äî Section c: Execution Loop**\nFor each task:\n1. Read task details and create TodoWrite for all substeps\n2. Execute with TDD:\n   - Write failing test (RED) ‚Äî specific test for the task's deliverable\n   - Run test via test-runner agent, confirm it fails\n   - Implement minimal code to pass (GREEN)\n   - Run test via test-runner agent, confirm it passes\n   - Refactor if needed (keep tests green)\n   - Commit with descriptive message\n3. After task complete, verify all TodoWrite substeps done\n4. Close task: `bd close \u003cid\u003e`\n5. Run SRE refinement on proposed next task (invoke skill)\n6. Send structured summary to lead (see Message Protocol below)\n7. Wait for lead approval before creating next bd task and continuing\n\n**Prompt body ‚Äî Section d: Message Protocol**\nTask completion message format (send via SendMessage to lead):\n```\n## Task \u003cid\u003e Complete\n\n### Done\n- [1-3 bullet summary of implementation]\n\n### Learned\n- [Discoveries that affect future tasks]\n- [Things that differed from assumptions]\n\n### Changed from plan\n- [What deviated from task description and why]\n- [Or \"None ‚Äî executed as planned\"]\n\n### Proposed next task\nTitle: [task title]\nGoal: [what it delivers ‚Äî one clear outcome]\nApproach: [how, informed by learnings]\nSRE refined: yes/no\n```\n\nEscalation message format:\n```\n## Escalation: [obstacle summary]\n\n### Problem\n[What's blocking ‚Äî specific error, constraint, or design conflict]\n\n### Epic context\n[Which anti-pattern or requirement is relevant]\n[Quote the specific text from epic Design Discovery]\n\n### Options\nA. [option] ‚Äî [tradeoff, complexity estimate]\nB. [option] ‚Äî [tradeoff, complexity estimate]\n\n### My recommendation\n[Which option and why, referencing epic requirements]\n```\n\n**Prompt body ‚Äî Section e: Escalation Triggers**\nMUST escalate to lead when:\n1. Implementation would require violating an epic anti-pattern\n2. A library/API doesn't support what the design assumed\n3. Discovery invalidates a rejected approach (the \"DO NOT REVISIT UNLESS\" condition might be met)\n4. Task scope expands beyond what was approved\n5. Test failures suggest a design flaw (not just a bug)\n6. Two consecutive TDD cycles fail to go green\n\nMUST NOT escalate (handle autonomously):\n1. Normal test failures during RED phase (expected)\n2. Refactoring that stays within task scope\n3. Minor implementation details not specified in task\n4. Choosing between equivalent approaches within anti-pattern bounds\n\n**Prompt body ‚Äî Section f: Completion Protocol**\nWhen all epic success criteria appear met:\n1. Re-read epic: `bd show \u003cepic-id\u003e`\n2. Check each success criterion against implementation\n3. Send completion message to lead:\n```\n## Epic Completion Report\n\n### Success Criteria Status\n- [x] Criterion 1 ‚Äî [evidence]\n- [x] Criterion 2 ‚Äî [evidence]\n...\n\n### Summary\n[2-3 sentence overview of entire implementation]\n\n### Recommendation\nReady for review-implementation.\n```\n\n**Prompt body ‚Äî Section g: Rules (No Exceptions)**\n1. TDD is mandatory ‚Äî never skip RED phase\n2. Never violate epic anti-patterns ‚Äî escalate instead\n3. Never create next task without lead approval\n4. Never skip SRE refinement on proposed tasks\n5. Always use test-runner agent for test execution (context preservation)\n6. Always send structured messages (never ad-hoc)\n7. If context getting exhausted: send status to lead and request continuation guidance\n\n### 5. Verify\n- Read agents/executor.md back and confirm:\n  - [ ] Frontmatter has all fields (name, description with examples, model, permissionMode, memory, skills)\n  - [ ] Startup protocol specifies exact bd commands\n  - [ ] TDD cycle has all 6 steps (write test, RED, implement, GREEN, refactor, commit)\n  - [ ] Both message formats complete (task completion + escalation)\n  - [ ] All 6 escalation triggers listed with concrete examples\n  - [ ] All 4 \"handle autonomously\" cases listed\n  - [ ] Completion protocol includes success criteria checklist\n  - [ ] All 7 rules listed\n  - [ ] No placeholder text (\"[detailed above]\", \"[as specified]\", etc.)\n\n## Success Criteria\n- [ ] agents/executor.md exists with complete frontmatter (name, description, model, permissionMode, memory, skills)\n- [ ] Startup protocol specifies exact bd commands for epic and task loading\n- [ ] TDD cycle explicitly defined with all 6 steps (write test, RED, implement, GREEN, refactor, commit)\n- [ ] Task completion message format defined with all 4 sections (Done, Learned, Changed, Proposed next)\n- [ ] Escalation message format defined with all 4 sections (Problem, Epic context, Options, Recommendation)\n- [ ] 6 concrete escalation triggers listed (anti-pattern violation, API mismatch, rejected approach revisit, scope expansion, design flaw, consecutive failures)\n- [ ] 4 \"handle autonomously\" cases listed\n- [ ] Completion protocol includes success criteria checklist with evidence\n- [ ] 7 rules with no exceptions listed\n- [ ] No placeholder text in any section\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO placeholder instructions in agent prompt (\"follow TDD\" without specifying the cycle steps)\n- ‚ùå NO undefined message fields (every field in protocol must have description and example)\n- ‚ùå NO vague escalation triggers (\"when things go wrong\" ‚Äî must be specific conditions)\n- ‚ùå NO missing frontmatter fields (all fields from existing agents must be considered)\n- ‚ùå NO \"subagent_type\" in frontmatter (that's a Task tool parameter, not an agent definition field)\n\n## Key Considerations (SRE Review)\n\n**Edge Case: Epic not found in bd**\n- Executor receives epic ID in spawn prompt\n- If bd show returns error: send escalation to lead immediately\n- Do NOT attempt to proceed without epic context\n\n**Edge Case: Executor context exhaustion**\n- Long-running tasks may exhaust executor context\n- If approaching limits: send status message to lead with current progress\n- Lead can shut down executor and spawn fresh one with state in bd\n\n**Edge Case: Resumption from previous failed run**\n- Check for in-progress tasks before starting fresh: `bd list --status in_progress`\n- If found: resume that task (don't create duplicate)\n- If task was partially implemented: assess state before continuing\n\n**Edge Case: Lead doesn't respond**\n- Executor sends proposal and waits\n- If no response: executor is idle (this is normal in agent teams)\n- Lead will respond when ready ‚Äî do NOT resend or escalate about silence\n\n**Edge Case: Skill invocation**\n- Executor needs TDD and SRE refinement skills loaded via frontmatter\n- If skill not available: send escalation to lead\n- Do NOT attempt to follow skill from memory ‚Äî must load via Skill tool\n\n**Reference: Existing agent patterns to follow**\n- agents/code-reviewer.md: frontmatter structure, XML examples in description\n- agents/test-runner.md: permissionMode, reporting format, context isolation pattern","status":"closed","priority":2,"issue_type":"feature","owner":"abugosh@gmail.com","created_at":"2026-02-14T10:23:30.462478-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T10:42:48.660294-05:00","closed_at":"2026-02-14T10:42:48.660294-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-1y1","depends_on_id":"bd-t4i","type":"parent-child","created_at":"2026-02-14T10:23:35.397624-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-2","title":"Phase 1: Skill Rules Configuration","design":"## Goal\nCreate skill-rules.json configuration defining triggers for all hyperpowers skills.\n\n## Effort Estimate\n6-8 hours\n\n## Success Criteria\n- [ ] skill-rules.json created with valid JSON (verified with jq . skill-rules.json)\n- [ ] All hyperpowers skills have defined rules (19 skills confirmed)\n- [ ] Each skill has 3-8 keywords and 2-5 intent patterns\n- [ ] Priority levels appropriately assigned (max 3-4 critical skills)\n- [ ] JSON validates successfully with jq\n- [ ] No regex patterns fail catastrophic backtracking test\n- [ ] Sample prompts match expected skills (90%+ accuracy on test set)\n- [ ] File size under 50KB\n- [ ] Documentation comments explain each pattern's purpose\n\n## Implementation Steps (ADDED BY writing-plans)\n\n### Step Group 1: Initial Setup and Skill Inventory\n\n**Files:**\n- Create: hooks/skill-rules.json\n- Reference: skills/skills-auto-activation/resources/skill-rules-examples.md\n\n**Step 1: Count and list all skills**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\nls -1 skills/*/SKILL.md | wc -l\n```\nExpected: 19 skills\n\n**Step 2: Extract all skill names for reference**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\nfor skill in skills/*/SKILL.md; do \n  dirname \"$skill\" | sed 's|skills/||'\ndone | sort\n```\nExpected output: List of 19 skills (brainstorming through writing-skills)\n\n### Step Group 2: Create Core Configuration Structure\n\n**Step 3: Create initial skill-rules.json with schema documentation**\n\nCreate hooks/skill-rules.json:\n```json\n{\n  \"_comment\": \"Skill activation rules for hyperpowers plugin - 19 skills total\",\n  \"_schema\": {\n    \"description\": \"Each skill has type, enforcement, priority, and triggers\",\n    \"type\": \"process|domain|workflow\", \n    \"enforcement\": \"suggest\",\n    \"priority\": \"critical|high|medium|low\",\n    \"promptTriggers\": {\n      \"keywords\": \"Array of case-insensitive strings\",\n      \"intentPatterns\": \"Array of regex patterns for action+object\"\n    }\n  }\n}\n```\n\n**Step 4: Verify JSON syntax**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\njq . hooks/skill-rules.json\n```\nExpected: Valid JSON output with formatted structure\n\n### Step Group 3: Add Core Workflow Skills (5 skills)\n\n**Step 5: Add test-driven-development skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"test-driven-development\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"critical\",\n  \"promptTriggers\": {\n    \"keywords\": [\"test\", \"testing\", \"TDD\", \"spec\", \"unit test\", \"integration test\", \"test first\", \"red green refactor\"],\n    \"intentPatterns\": [\n      \"(write|add|create|implement).*?(test|spec|unit test)\",\n      \"test.*(first|before|driven)\",\n      \"(implement|build|create).*?(feature|function|component)\",\n      \"red.*(green|refactor)\",\n      \"(bug|fix|issue).*?reproduce\"\n    ]\n  }\n}\n```\n\n**Step 6: Add debugging-with-tools skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"debugging-with-tools\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"debug\", \"debugging\", \"error\", \"bug\", \"crash\", \"fails\", \"broken\", \"not working\", \"issue\"],\n    \"intentPatterns\": [\n      \"(debug|fix|solve|investigate|troubleshoot).*?(error|bug|issue|problem)\",\n      \"(why|what).*?(failing|broken|not working|crashing)\",\n      \"(find|locate|identify).*?(bug|issue|problem|root cause)\",\n      \"reproduce.*(bug|issue|error)\",\n      \"stack.*(trace|error)\"\n    ]\n  }\n}\n```\n\n**Step 7: Add refactoring-safely skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"refactoring-safely\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"medium\",\n  \"promptTriggers\": {\n    \"keywords\": [\"refactor\", \"refactoring\", \"cleanup\", \"improve\", \"restructure\", \"reorganize\", \"simplify\"],\n    \"intentPatterns\": [\n      \"(refactor|clean up|improve|restructure).*?(code|function|class|component)\",\n      \"(extract|split|separate).*?(function|method|component|logic)\",\n      \"(rename|move|relocate).*?(file|function|class)\",\n      \"remove.*(duplication|duplicate|repeated code)\"\n    ]\n  }\n}\n```\n\n**Step 8: Add fixing-bugs skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"fixing-bugs\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"bug\", \"fix\", \"issue\", \"problem\", \"defect\", \"regression\"],\n    \"intentPatterns\": [\n      \"(fix|resolve|solve).*?(bug|issue|problem|defect)\",\n      \"(bug|issue|problem).*(report|ticket|found)\",\n      \"regression.*(test|fix|found)\",\n      \"(broken|not working).*(fix|repair)\"\n    ]\n  }\n}\n```\n\n**Step 9: Add root-cause-tracing skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"root-cause-tracing\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"medium\",\n  \"promptTriggers\": {\n    \"keywords\": [\"root cause\", \"trace\", \"origin\", \"source\", \"why\", \"deep dive\"],\n    \"intentPatterns\": [\n      \"root.*(cause|problem|issue)\",\n      \"trace.*(back|origin|source)\",\n      \"(why|how).*(happening|occurring|caused)\",\n      \"deep.*(dive|analysis|investigation)\"\n    ]\n  }\n}\n```\n\n### Step Group 4: Add Planning \u0026 Execution Skills (8 skills)\n\n**Step 10: Add brainstorming skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"brainstorming\": {\n  \"type\": \"workflow\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"plan\", \"design\", \"architecture\", \"approach\", \"brainstorm\", \"idea\", \"feature\", \"implement\"],\n    \"intentPatterns\": [\n      \"(create|build|add|implement).*?(feature|system|component|functionality)\",\n      \"(how should|what's the best way|how to).*?(implement|build|design)\",\n      \"I want to.*(add|create|build|implement)\",\n      \"(plan|design|architect).*?(system|feature|component)\",\n      \"let's.*(think|plan|design)\"\n    ]\n  }\n}\n```\n\n**Step 11: Add writing-plans skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"writing-plans\": {\n  \"type\": \"workflow\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"expand\", \"enhance\", \"detailed steps\", \"implementation steps\", \"bd tasks\"],\n    \"intentPatterns\": [\n      \"expand.*?(bd|task|plan)\",\n      \"enhance.*?with.*(steps|details)\",\n      \"add.*(implementation|detailed).*(steps|instructions)\",\n      \"write.*?plan\"\n    ]\n  }\n}\n```\n\n**Step 12: Add executing-plans skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"executing-plans\": {\n  \"type\": \"workflow\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"execute\", \"implement\", \"start working\", \"begin implementation\", \"work on bd\"],\n    \"intentPatterns\": [\n      \"execute.*(plan|tasks|bd)\",\n      \"(start|begin).*(implementation|work|executing)\",\n      \"implement.*?bd-\\\\d+\",\n      \"work.*?on.*(tasks|bd|plan)\"\n    ]\n  }\n}\n```\n\n**Step 13: Add remaining planning skills**\n\nAdd review-implementation, finishing-a-development-branch, sre-task-refinement, managing-bd-tasks with similar patterns.\n\n### Step Group 5: Add Quality \u0026 Infrastructure Skills (6 skills)\n\n**Step 14: Add verification-before-completion skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"verification-before-completion\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"critical\",\n  \"promptTriggers\": {\n    \"keywords\": [\"done\", \"complete\", \"finished\", \"ready\", \"verified\", \"works\", \"passing\"],\n    \"intentPatterns\": [\n      \"(I'm|it's|work is).*(done|complete|finished)\",\n      \"(ready|prepared).*(merge|commit|push|PR)\",\n      \"everything.*(works|passes|ready)\",\n      \"(verified|tested|checked).*?(everything|all)\",\n      \"can we.*(merge|commit|ship)\"\n    ]\n  }\n}\n```\n\n**Step 15: Add remaining quality and infrastructure skills**\n\nAdd dispatching-parallel-agents, building-hooks, skills-auto-activation, testing-anti-patterns, using-hyper, writing-skills with appropriate patterns.\n\n### Step Group 6: Test and Validate Configuration\n\n**Step 16: Validate complete JSON file**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\njq . hooks/skill-rules.json \u003e /dev/null \u0026\u0026 echo \"‚úì Valid JSON\" || echo \"‚úó Invalid JSON\"\n```\nExpected: ‚úì Valid JSON\n\n**Step 17: Check file size**\n\nRun:\n```bash\nls -lh hooks/skill-rules.json | awk '{print $5}'\n```\nExpected: \u003c 50KB (should be around 15-20KB)\n\n**Step 18: Count skills in configuration**\n\nRun:\n```bash\njq 'keys - [\"_comment\", \"_schema\"] | length' hooks/skill-rules.json\n```\nExpected: 19\n\n**Step 19: Test keyword matching with sample prompts**\n\nCreate test script:\n```bash\n#!/bin/bash\n# Test skill activation patterns\nprompt=\"I want to write a test for the login function\"\njq --arg prompt \"$prompt\" '\n  to_entries | \n  map(select(.value.promptTriggers.keywords as $kw | \n    $prompt | ascii_downcase | \n    test($kw | map(. | ascii_downcase) | join(\"|\"))\n  )) | \n  map(.key)\n' hooks/skill-rules.json\n```\nExpected: Should match \"test-driven-development\"\n\n**Step 20: Commit the configuration**\n\nRun:\n```bash\ngit add hooks/skill-rules.json\ngit commit -m \"feat(bd-2): create skill-rules.json configuration\n\nImplements bd-2: Skill Rules Configuration\n- Defines activation rules for all 19 hyperpowers skills\n- Includes keywords and intent patterns for each skill\n- Sets appropriate priority levels (critical/high/medium/low)\n- Validated JSON syntax and file size \u003c 50KB\"\n```\n\n### Step Group 7: Document Pattern Testing\n\n**Step 21: Create regex testing documentation**\n\nCreate hooks/REGEX_TESTING.md:\n```markdown\n# Regex Pattern Testing for skill-rules.json\n\n## Tested Patterns\n\nAll regex patterns in skill-rules.json have been tested on regex101.com for:\n- Catastrophic backtracking (10000 'a's input)\n- Unicode handling\n- Performance\n\n### Test Results\n\n| Pattern | Backtracking Safe | Unicode Safe | Avg Time |\n|---------|------------------|--------------|----------|\n| (create|add).*?(feature|component) | ‚úì | ‚úì | \u003c1ms |\n| (debug|fix).*?(error|bug) | ‚úì | ‚úì | \u003c1ms |\n[... document all patterns ...]\n```\n\n**Step 22: Final validation**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\necho \"=== Skill Rules Validation ===\"\necho \"1. JSON valid: $(jq . hooks/skill-rules.json \u003e /dev/null 2\u003e\u00261 \u0026\u0026 echo '‚úì' || echo '‚úó')\"\necho \"2. Skill count: $(jq 'keys - [\"_comment\", \"_schema\"] | length' hooks/skill-rules.json) (expected: 19)\"\necho \"3. File size: $(ls -lh hooks/skill-rules.json | awk '{print $5}')\"\n```\nExpected: All validations pass\n\n## Key Considerations (ADDED BY SRE REVIEW)\n- Pattern Design: Intent patterns should be broad enough to catch variations but specific enough to avoid false positives\n- Priority Balance: Don't overuse \"critical\" - reserve for verification and safety-critical workflows\n- Regex Performance: Keep patterns simple; avoid catastrophic backtracking\n- Maintenance: Document reasoning for each pattern to help future updates\n- File Size: Large JSON files can slow parsing - keep under 50KB\n- Testing Regex: MUST test all patterns on regex101.com with pathological inputs (10000 'a's)\n- Unicode Handling: Patterns should handle Unicode input gracefully\n- Case Sensitivity: All matching must be case-insensitive\n\n## Anti-patterns to Avoid\n- ‚ùå Overly broad keywords that match too many prompts (e.g., \"code\", \"file\", \"data\")\n- ‚ùå Complex regex patterns that are hard to maintain or have backtracking issues\n- ‚ùå Marking too many skills as \"critical\" priority (dilutes importance)\n- ‚ùå Missing common variations in intent patterns\n- ‚ùå Untested regex patterns (MUST test on regex101.com)\n- ‚ùå No comments explaining pattern intent\n- ‚ùå File size over 50KB (performance impact)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:56:54.618233-04:00","updated_at":"2025-10-30T14:56:49.100685-04:00","closed_at":"2025-10-30T14:56:49.100685-04:00","dependencies":[{"issue_id":"bd-2","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.44578-04:00","created_by":"ryan"}]}
{"id":"bd-26z","title":"Task 3: Update skill-rules.json, README, HOOKS documentation","design":"## Goal\nUpdate skill-rules.json with new trigger keywords and update documentation files.\n\n## Effort Estimate\n1 hour\n\n## Files to Update\n1. hooks/skill-rules.json - Add 'validate', 'lint', 'typecheck', 'format' keywords\n2. README.md - Update test-runner description\n3. HOOKS.md - Update pre-commit assumption documentation\n4. hooks/post-tool-use/04-block-pre-existing-checks.py - Update messaging\n\n## Implementation\n\n### skill-rules.json\nAdd new keywords to test-runner triggers:\n- 'validate'\n- 'lint' \n- 'typecheck'\n- 'format'\n- 'Run: validate'\n\n### README.md\nUpdate test-runner description around line 61, 82, 104:\n- Remove 'pre-commit hooks' from descriptions\n- Add 'validations' and 'Run: validate'\n\n### HOOKS.md\nUpdate sections around lines 192-201:\n- Remove pre-commit assumption section\n- Update to use universal validation language\n\n### hooks/post-tool-use/04-block-pre-existing-checks.py\nUpdate error messages to not reference pre-commit specifically.\n\n## Success Criteria\n- [ ] skill-rules.json has 'validate', 'lint', 'typecheck' keywords in test-runner triggers\n- [ ] README.md updated to reference 'Run: validate' instead of pre-commit\n- [ ] HOOKS.md updated with universal validation language\n- [ ] Changes committed","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-01-22T12:38:27.501753-05:00","created_by":"Alex Bugosh","updated_at":"2026-01-22T12:42:24.9349-05:00","closed_at":"2026-01-22T12:42:24.9349-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-26z","depends_on_id":"bd-9gk","type":"blocks","created_at":"2026-01-22T12:38:34.387238-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-3","title":"Phase 2: Shared Utility Functions","design":"## Goal\nBuild shared utility functions for skill matching and output formatting.\n\n## Effort Estimate  \n6-8 hours\n\n## Success Criteria\n- [ ] Both utility scripts created\n- [ ] Dependency checks implemented and tested\n- [ ] All functions implemented with proper error handling\n- [ ] Scripts fail gracefully if jq not installed (exit 1, clear error message)\n- [ ] Functions can be tested independently\n- [ ] All functions properly documented with comments\n- [ ] Handle empty/null inputs gracefully (return appropriate error code)\n- [ ] Handle malformed JSON gracefully (error message, exit 1)\n- [ ] Handle very long inputs (\u003e10KB) without hanging\n- [ ] Performance: match_keywords completes in \u003c50ms for typical input\n- [ ] Performance: find_matching_skills completes in \u003c200ms for 20 skills\n\n## Implementation Steps (ADDED BY writing-plans)\n\n### Step Group 1: Create Directory Structure\n\n**Files:**\n- Create: hooks/utils/skill-matcher.sh\n- Create: hooks/utils/format-output.sh\n\n**Step 1: Verify utils directory**\nRun:\n```bash\ncd /Users/ryan/src/hyper\nls -la hooks/utils/\n```\nExpected: Directory exists and is writable\n\n### Step Group 2: Create skill-matcher.sh Core Structure\n\n**Step 2: Create skill-matcher.sh with dependency checking**\nCreate hooks/utils/skill-matcher.sh:\n```bash\n#!/usr/bin/env bash\nset -e\n\ncheck_dependencies() {\n  local missing=()\n  command -v jq \u003e/dev/null 2\u003e\u00261 || missing+=(\"jq\")\n  command -v grep \u003e/dev/null 2\u003e\u00261 || missing+=(\"grep\")\n  \n  if [ ${#missing[@]} -gt 0 ]; then\n    echo \"ERROR: Missing required dependencies: ${missing[*]}\" \u003e\u00262\n    echo \"Please install missing tools and try again.\" \u003e\u00262\n    return 1\n  fi\n  return 0\n}\n\ncheck_dependencies || exit 1\n```\n\n**Step 3: Make executable**\nRun: `chmod +x hooks/utils/skill-matcher.sh`\n\n**Step 4: Test dependency checking**\nRun: `source hooks/utils/skill-matcher.sh \u0026\u0026 echo \"OK: $?\"`\nExpected: \"OK: 0\"\n\n### Step Group 3: Implement Skill Matcher Functions\n\n**Step 5: Add load_skill_rules function**\nAdd to skill-matcher.sh:\n```bash\nload_skill_rules() {\n  local rules_path=\"$1\"\n  \n  if [ -z \"$rules_path\" ]; then\n    echo \"ERROR: No rules path provided\" \u003e\u00262\n    return 1\n  fi\n  \n  if [ ! -f \"$rules_path\" ]; then\n    echo \"ERROR: Rules file not found: $rules_path\" \u003e\u00262\n    return 1\n  fi\n  \n  if ! jq . \"$rules_path\" 2\u003e/dev/null; then\n    echo \"ERROR: Invalid JSON in $rules_path\" \u003e\u00262\n    return 1\n  fi\n  \n  return 0\n}\n```\n\n**Step 6: Add match_keywords function**\nAdd to skill-matcher.sh:\n```bash\nmatch_keywords() {\n  local text=\"$1\"\n  local keywords=\"$2\"\n  \n  if [ -z \"$text\" ] || [ -z \"$keywords\" ]; then\n    return 1\n  fi\n  \n  local lower_text=$(echo \"$text\" | tr '[:upper:]' '[:lower:]')\n  \n  IFS=',' read -ra KEYWORD_ARRAY \u003c\u003c\u003c \"$keywords\"\n  for keyword in \"${KEYWORD_ARRAY[@]}\"; do\n    local lower_keyword=$(echo \"$keyword\" | tr '[:upper:]' '[:lower:]' | xargs)\n    if [[ \"$lower_text\" == *\"$lower_keyword\"* ]]; then\n      return 0\n    fi\n  done\n  \n  return 1\n}\n```\n\n**Step 7: Add match_patterns function**\nAdd to skill-matcher.sh:\n```bash\nmatch_patterns() {\n  local text=\"$1\"\n  local patterns=\"$2\"\n  \n  if [ -z \"$text\" ] || [ -z \"$patterns\" ]; then\n    return 1\n  fi\n  \n  local timeout_cmd=\"\"\n  if command -v timeout \u003e/dev/null 2\u003e\u00261; then\n    timeout_cmd=\"timeout 1\"\n  fi\n  \n  IFS=',' read -ra PATTERN_ARRAY \u003c\u003c\u003c \"$patterns\"\n  for pattern in \"${PATTERN_ARRAY[@]}\"; do\n    pattern=$(echo \"$pattern\" | xargs)\n    \n    if $timeout_cmd grep -Ei \"$pattern\" \u003c\u003c\u003c \"$text\" \u003e/dev/null 2\u003e\u00261; then\n      return 0\n    fi\n  done\n  \n  return 1\n}\n```\n\n**Step 8: Add find_matching_skills function**\nAdd complete function to match skills based on prompts, sorting by priority and limiting to top 3.\n\n**Step 9: Test functions**\nRun:\n```bash\nsource hooks/utils/skill-matcher.sh\nmatch_keywords \"I want to write a test\" \"test,testing,TDD\" \u0026\u0026 echo \"‚úì Works\"\nmatch_patterns \"create a new feature\" \"(create|add).*?(feature|component)\" \u0026\u0026 echo \"‚úì Works\"\nmatch_keywords \"\" \"test\" || echo \"‚úì Empty handled\"\n```\nExpected: All pass\n\n### Step Group 4: Create format-output.sh\n\n**Step 10: Create format-output.sh with dependency checking**\nCreate hooks/utils/format-output.sh:\n```bash\n#!/usr/bin/env bash\nset -e\n\ncheck_dependencies() {\n  local missing=()\n  command -v jq \u003e/dev/null 2\u003e\u00261 || missing+=(\"jq\")\n  \n  if [ ${#missing[@]} -gt 0 ]; then\n    echo \"ERROR: Missing required dependencies: ${missing[*]}\" \u003e\u00262\n    return 1\n  fi\n  return 0\n}\n\ncheck_dependencies || exit 1\n\nget_priority_emoji() {\n  local priority=\"$1\"\n  case \"$priority\" in\n    \"critical\") echo \"üî¥\" ;;\n    \"high\") echo \"‚≠ê\" ;;\n    \"medium\") echo \"üìå\" ;;\n    \"low\") echo \"üí°\" ;;\n    *) echo \"‚Ä¢\" ;;\n  esac\n}\n```\n\n**Step 11: Add format_skill_reminder function**\nAdd function to format matched skills into activation reminder text.\n\n**Step 12: Add format_gentle_reminder function**\nAdd function for TDD, testing, and verification reminders.\n\n**Step 13: Make executable**\nRun: `chmod +x hooks/utils/format-output.sh`\n\n**Step 14: Test functions**\nRun:\n```bash\nsource hooks/utils/format-output.sh\n[ \"$(get_priority_emoji critical)\" = \"üî¥\" ] \u0026\u0026 echo \"‚úì Emoji works\"\nformat_gentle_reminder \"tdd\" | grep \"RED-GREEN-REFACTOR\" \u0026\u0026 echo \"‚úì Reminder works\"\n```\n\n### Step Group 5: Performance Testing\n\n**Step 15: Create performance test**\nCreate hooks/utils/test-performance.sh to test match_keywords \u003c50ms and find_matching_skills \u003c200ms.\n\n**Step 16: Run performance tests**\nRun: `bash hooks/utils/test-performance.sh`\nExpected: Both under targets\n\n### Step Group 6: Validation and Testing\n\n**Step 17: Test edge cases**\nTest with empty inputs, malformed JSON, very long inputs (\u003e10KB).\n\n**Step 18: Commit utilities**\nRun:\n```bash\ngit add hooks/utils/skill-matcher.sh hooks/utils/format-output.sh\ngit commit -m \"feat(bd-3): create shared utility functions\n\nImplements bd-3: Shared Utility Functions\n- skill-matcher.sh with keyword/pattern matching\n- format-output.sh with formatting functions\n- Dependency checking for jq and grep\n- Performance optimized\n- Edge case handling\"\n```\n\n**Step 19-20: Create and run test suite**\nCreate comprehensive test suite and verify all tests pass.\n\n## Key Considerations (ADDED BY SRE REVIEW)\n- Dependency Failures: Scripts must fail immediately if jq not found\n- Error Messages: Clear, actionable error messages for missing deps\n- Pure Functions: No side effects, easy to test independently\n- JSON I/O: Use jq for all JSON operations\n- Error Handling: Functions return error codes, caller decides handling\n- Modularity: Each function does one thing well\n- Regex Timeout: Long regex can hang - consider GNU timeout wrapper if available\n- Input Validation: Check for empty/null inputs before processing\n- Output Escaping: Properly escape special characters in formatted output\n- Performance: Cache compiled regex patterns if possible\n- Large Input Handling: Gracefully handle prompts \u003e10KB\n\n## Anti-patterns to Avoid\n- ‚ùå Assuming dependencies are installed without checking\n- ‚ùå Silent failures when dependencies missing\n- ‚ùå Functions with side effects (writing files, modifying globals)\n- ‚ùå Complex regex that's hard to debug or has catastrophic backtracking\n- ‚ùå Hardcoded paths instead of using parameters\n- ‚ùå No input validation (empty strings, null values)\n- ‚ùå No timeout protection for regex operations\n- ‚ùå Unbounded memory usage for large inputs","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.276093-04:00","updated_at":"2025-10-30T15:00:23.673747-04:00","closed_at":"2025-10-30T15:00:23.673747-04:00","dependencies":[{"issue_id":"bd-3","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.461298-04:00","created_by":"ryan"},{"issue_id":"bd-3","depends_on_id":"bd-2","type":"blocks","created_at":"2025-10-30T13:57:16.81907-04:00","created_by":"ryan"}]}
{"id":"bd-3ao","title":"Rewrite executing-plans skill as lead orchestration workflow","design":"## Goal\nComplete rewrite of skills/executing-plans/SKILL.md to use Claude Code agent teams for delegation. The lead stays in the main conversation context, spawns a single executor teammate, and orchestrates task execution without implementing directly.\n\n## Context\nWave 1 complete:\n- agents/executor.md ‚Äî Executor agent with TDD discipline, structured message protocol, escalation triggers\n- agents/reviewer.md ‚Äî Reviewer agent dispatched as subagent, returns APPROVED/GAPS FOUND verdict\n\nThe executor expects: epic ID in spawn prompt, structured approval/redirect messages from lead, SendMessage-based communication.\nThe reviewer expects: epic ID in dispatch prompt, returns verdict as Task tool output (subagent, not teammate).\n\n## Effort Estimate\n5-6 hours\n\n## Implementation\n\n### 1. Study the current executing-plans/SKILL.md\nRead the current skill to understand what to preserve vs. replace:\n- PRESERVE: Frontmatter format, skill_overview/rigidity_level/quick_reference/when_to_use/examples/critical_rules/verification_checklist/integration/resources XML structure\n- PRESERVE: Core philosophy ‚Äî epic requirements are immutable, tasks adapt to reality\n- PRESERVE: Design Discovery check when hitting obstacles\n- REPLACE: Solo execution loop ‚Üí lead orchestration with executor teammate\n- REPLACE: Manual STOP checkpoints ‚Üí continuous execution with structured messages\n- REPLACE: Direct implementation in lead context ‚Üí delegation to executor\n- REPLACE: Direct review-implementation skill invocation ‚Üí reviewer agent dispatch\n- UPDATE: Resumption check to handle team state (existing team, idle executor)\n\n### 2. Study the agent teams API capabilities\nUnderstand the tools the lead will use:\n- TeamCreate: creates team with shared task list\n- Task tool with team_name param and name param: spawns teammate (executor)\n- Task tool without team_name: spawns subagent (reviewer)\n- SendMessage type: \"message\": direct message to executor (approval, redirect, fix instructions)\n- SendMessage type: \"shutdown_request\": gracefully shut down executor\n- TeamDelete: cleanup team after completion\n- Teammates go idle between turns (this is normal ‚Äî do not treat as error)\n- Messages from teammates auto-delivered to lead\n- Lead receives idle notifications when teammates stop\n\n### 3. Write the new skill ‚Äî section by section\n\n**Frontmatter:**\n```yaml\n---\nname: executing-plans\ndescription: Use to execute bd tasks via agent teams delegation - lead orchestrates, executor implements with TDD, reviewer verifies. No manual /clear cycling needed.\n---\n```\n\n**skill_overview:** Lead orchestrates execution via agent teams. Spawns a single executor teammate for implementation, receives structured summaries after each task, validates proposals against epic requirements and anti-patterns, dispatches reviewer agent for final verification. No manual /clear cycling needed ‚Äî the lead preserves context continuously.\n\n**rigidity_level:** LOW FREEDOM ‚Äî follow exact orchestration process. Lead never implements directly. Epic requirements immutable. Do not skip proposal validation, reviewer dispatch, or shutdown protocol.\n\n**quick_reference:** Table with these rows:\n| Step | Action | Tool/Command |\n|------|--------|--------------|\n| Load Epic | Read epic requirements | `bd show \u003cepic-id\u003e` |\n| Create Team | Initialize team | TeamCreate |\n| Spawn Executor | Start executor teammate | Task tool with team_name and name params |\n| Receive Summary | Read executor's structured report | Auto-delivered message |\n| Validate Proposal | Check against epic requirements/anti-patterns | `bd show \u003cepic-id\u003e` + manual check |\n| Approve | Tell executor to proceed | SendMessage type: \"message\" |\n| Redirect | Tell executor to change course | SendMessage type: \"message\" with modified task |\n| Handle Escalation | Decide on obstacle | Check Design Discovery + SendMessage |\n| Dispatch Reviewer | Final verification | Task tool (subagent, no team_name) |\n| Shutdown | Terminate executor | SendMessage type: \"shutdown_request\" |\n| Cleanup | Remove team | TeamDelete |\n\n**when_to_use:** After brainstorming/writing-plans creates a bd epic with tasks ready for execution. Same trigger as old solo mode ‚Äî epic exists, first task ready.\n\n**the_process ‚Äî Step 0: Resumption Check**\nEvery invocation:\n1. Check bd state: `bd list --type epic --status open`, `bd ready`, `bd list --status in_progress`\n2. Check for existing team: Read ~/.claude/teams/ directory for active team config\n3. Decision matrix:\n   - No team + no in-progress tasks ‚Üí Fresh start at Step 1\n   - No team + in-progress task exists ‚Üí Fresh start at Step 1 (will create team and executor will resume from bd state)\n   - Team exists + executor idle ‚Üí Resume: SendMessage to executor to continue\n   - Team exists + executor active ‚Üí Resume: Wait for executor's next message\n   - All tasks closed + epic open ‚Üí Skip to Step 4 (reviewer dispatch)\n\n**the_process ‚Äî Step 1: Load Epic Context**\nSame as current skill:\n```bash\nbd list --type epic --status open\nbd show \u003cepic-id\u003e\n```\nExtract and HOLD: Requirements (IMMUTABLE), Success Criteria, Anti-Patterns (FORBIDDEN), Design Discovery (reference context for obstacle decisions).\nKey advantage: lead holds this context for the entire session ‚Äî no more losing it to /clear cycling.\n\n**the_process ‚Äî Step 2: Create Team and Spawn Executor**\n```\nTeamCreate:\n  team_name: \"epic-\u003cepic-id\u003e\"\n  description: \"Executing epic \u003cepic-id\u003e: \u003cepic title\u003e\"\n\nTask tool:\n  subagent_type: \"general-purpose\"\n  team_name: \"epic-\u003cepic-id\u003e\"\n  name: \"executor\"\n  mode: \"bypassPermissions\"\n  prompt: \"You are the executor agent. Execute tasks for epic \u003cepic-id\u003e. Follow the executor agent definition in agents/executor.md exactly. Start with: bd show \u003cepic-id\u003e\"\n```\n\n**the_process ‚Äî Step 3: Lead Orchestration Loop**\nLead receives auto-delivered messages from executor. For each:\n\n**A) Task completion message (Done, Learned, Changed, Proposed next):**\n1. Read the structured summary\n2. Re-read epic: `bd show \u003cepic-id\u003e` (keep requirements fresh)\n3. Check proposed next task against:\n   - Epic requirements (does it advance toward success criteria?)\n   - Epic anti-patterns (does it avoid forbidden shortcuts?)\n   - Design Discovery (does it touch any rejected approaches?)\n4. Decide and respond via SendMessage:\n   - APPROVE: \"Approved. Proceed with proposed task as described.\"\n   - MODIFY: \"Approved with changes: [specific modifications]. Proceed.\"\n   - REDIRECT: \"Do not proceed with proposed task. Instead: [different task with rationale].\"\n\n**B) Escalation message (Problem, Epic context, Options, Recommendation):**\n1. Read the problem and options\n2. Check Design Discovery ‚Äî specifically the \"Approaches Considered\" section\n3. If escalation involves a previously rejected approach:\n   - Read \"‚ö†Ô∏è REJECTED BECAUSE\" and \"üö´ DO NOT REVISIT UNLESS\"\n   - If revisit conditions NOT met: reject the alternative, explain why\n   - If revisit conditions ARE met: present to USER for confirmation before approving\n4. SendMessage to executor with decision and reasoning\n\n**C) Completion report (Success Criteria Status with evidence):**\n1. Verify each success criterion in the report against the epic\n2. Spot-check evidence (re-read epic, confirm criteria match)\n3. Proceed to Step 4 (reviewer dispatch)\n\n**the_process ‚Äî Step 3a: Obstacle Handling (Escalations from Executor)**\nDetailed escalation decision process:\n1. Receive escalation via auto-delivered message\n2. Re-read epic: `bd show \u003cepic-id\u003e`\n3. Find relevant section in Design Discovery\n4. Check \"Approaches Considered\" for any rejected approach the executor wants to try\n5. Apply same logic as current skill Section 2a:\n   - Document current approach and obstacle\n   - Check rejection reason ‚Äî does it still apply?\n   - Check \"DO NOT REVISIT UNLESS\" ‚Äî is condition met?\n   - If rejected approach needed: present to USER (AskUserQuestion), do NOT decide alone\n6. SendMessage to executor with decision + reasoning from Design Discovery\n\n**the_process ‚Äî Step 4: Dispatch Reviewer**\nWhen executor reports all success criteria met:\n```\nTask tool:\n  subagent_type: \"general-purpose\"\n  prompt: \"You are the reviewer agent. Review the implementation for epic \u003cepic-id\u003e. Follow the reviewer agent definition in agents/reviewer.md exactly. Start with: bd show \u003cepic-id\u003e\"\n```\nReviewer is a SUBAGENT (no team_name) ‚Äî one-shot analysis, returns verdict in Task output.\n\nHandle verdict:\n- APPROVED ‚Üí proceed to Step 5\n- GAPS FOUND ‚Üí SendMessage to executor with gap details from reviewer verdict, return to Step 3 loop\n\n**the_process ‚Äî Step 5: Shutdown and Present**\n1. SendMessage type: \"shutdown_request\" to executor\n2. Wait for shutdown_response (executor approves)\n3. TeamDelete to cleanup\n4. Present final status to user:\n   - Summary of all completed tasks\n   - Success criteria evidence\n   - Reviewer verdict\n5. User runs `/hyperpowers:finish-branch` to close epic and integrate\n\n**examples:** 4 examples:\n\nExample 1 ‚Äî Lead implements directly (anti-pattern):\nScenario: Lead receives executor's task completion and starts writing the next feature directly in the main context.\nWhy it fails: Lead accumulates implementation verbosity, loses orchestration context, duplicates executor's role.\nCorrection: Lead validates the proposal and SendMessages approval to executor.\n\nExample 2 ‚Äî Lead auto-approves without checking epic (anti-pattern):\nScenario: Executor proposes next task. Lead immediately approves without re-reading epic requirements.\nWhy it fails: Proposed task might violate anti-patterns or drift from success criteria. Lead's value is validation.\nCorrection: Re-read epic with bd show before every approval decision.\n\nExample 3 ‚Äî Lead dismisses escalation (anti-pattern):\nScenario: Executor escalates an obstacle. Lead responds \"figure it out\" without checking Design Discovery.\nWhy it fails: Executor lacks Design Discovery context. Lead is supposed to provide design-level decisions.\nCorrection: Check Design Discovery, check Approaches Considered, make informed decision, send reasoning to executor.\n\nExample 4 ‚Äî Proper flow (success case):\nScenario: Executor completes task, proposes next. Lead re-reads epic, validates against anti-patterns, modifies proposal to address edge case from Design Discovery, approves with modification. Executor proceeds.\nWhy it works: Lead preserves context, catches drift, adds value through design-level validation.\n\n**critical_rules:**\n1. Lead NEVER implements ‚Äî only orchestrates via messages\n2. Lead validates EVERY proposal against epic before approving\n3. Lead checks Design Discovery for ALL escalations involving rejected approaches\n4. If rejected approach needed: present to USER first, never decide alone\n5. Reviewer dispatched as subagent (no team_name), not teammate\n6. Epic requirements are immutable ‚Äî lead enforces this on all executor proposals\n7. Shutdown executor before TeamDelete (graceful, not abrupt)\n8. Idle executor = normal (don't treat as error, don't spam messages)\n\n**verification_checklist:**\nBefore approving proposals:\n- [ ] Re-read epic (bd show)\n- [ ] Checked proposal against requirements\n- [ ] Checked proposal against anti-patterns\n- [ ] Checked Design Discovery if relevant\n- [ ] Decision documented in SendMessage\n\nBefore dispatching reviewer:\n- [ ] All success criteria reported as met by executor\n- [ ] Evidence provided for each criterion\n- [ ] No pending tasks in bd (all closed)\n\nBefore shutting down:\n- [ ] Reviewer returned APPROVED\n- [ ] Executor shutdown requested and confirmed\n- [ ] TeamDelete called\n- [ ] Status presented to user\n\n**integration:**\nThis skill calls:\n- agents/executor.md (spawned as teammate via Task tool)\n- agents/reviewer.md (dispatched as subagent via Task tool)\n- sre-task-refinement (executor runs this, lead receives refined proposals)\n- test-driven-development (executor follows this, lead doesn't need to invoke)\n- verification-before-completion (reviewer invokes this as part of review)\n\nThis skill is called by:\n- User via /hyperpowers:execute-plan command\n- After brainstorming/writing-plans creates epic\n- Explicitly to resume after context clear or new session\n\nAgents used:\n- executor (teammate ‚Äî persistent context, continuous work)\n- reviewer (subagent ‚Äî one-shot verdict)\n- test-runner (used by executor internally, not by lead)\n\nWorkflow pattern:\n```\n/hyperpowers:execute-plan ‚Üí Create team ‚Üí Spawn executor\n  ‚Üí Executor works ‚Üí sends summary ‚Üí Lead validates ‚Üí approves/redirects\n  ‚Üí ...repeats until all criteria met...\n  ‚Üí Lead dispatches reviewer ‚Üí APPROVED/GAPS\n  ‚Üí Shutdown ‚Üí Present to user ‚Üí /hyperpowers:finish-branch\n```\n\n**resources:**\n- bd command reference: see skills/common-patterns/bd-commands.md\n- Agent teams API: TeamCreate, Task (with/without team_name), SendMessage, TeamDelete\n- When stuck:\n  - Executor not responding ‚Üí Check if team exists, executor might need respawn\n  - Reviewer returns GAPS ‚Üí Send details to executor, return to orchestration loop\n  - Escalation about rejected approach ‚Üí Check Design Discovery, ask USER if needed\n  - Don't understand executor summary ‚Üí Ask executor for clarification via SendMessage\n\n### 4. Verify the rewrite\nRead the new skill back and confirm:\n- [ ] All XML sections present (skill_overview, rigidity_level, quick_reference, when_to_use, the_process, examples, critical_rules, verification_checklist, integration, resources)\n- [ ] Lead never implements directly (search for any step that has lead writing code)\n- [ ] TeamCreate, Task tool, SendMessage used correctly\n- [ ] Executor spawned as teammate (team_name param)\n- [ ] Reviewer dispatched as subagent (no team_name)\n- [ ] Resumption handles existing team state\n- [ ] Design Discovery check preserved for obstacle handling\n- [ ] All 10 success criteria from epic addressed\n- [ ] All anti-patterns from epic avoided\n- [ ] No placeholder text in any section\n- [ ] Pre-commit hooks passing\n\n## Success Criteria\n- [ ] skills/executing-plans/SKILL.md is a complete rewrite (not a patch on the old version)\n- [ ] Lead orchestration workflow uses TeamCreate, Task(executor), SendMessage, Task(reviewer), TeamDelete\n- [ ] Lead never implements directly ‚Äî only orchestrates via messages\n- [ ] Executor spawned as teammate with team_name and name params\n- [ ] Reviewer dispatched as subagent without team_name param\n- [ ] Resumption check handles existing team state (5-case decision matrix)\n- [ ] Escalation handling preserves Design Discovery check logic including AskUserQuestion for rejected approaches\n- [ ] Message validation against epic requirements and anti-patterns is explicit (3 approval types: approve, modify, redirect)\n- [ ] All XML sections present with actual content (overview, rigidity, quick_reference, when_to_use, process, examples, rules, checklist, integration, resources)\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n- NO patching the old skill ‚Äî this is a complete rewrite\n- NO lead implementing anything directly (code, files, tests) ‚Äî delegation is the whole point\n- NO skipping the message validation step (lead must check proposals against epic)\n- NO making reviewer a teammate (it's a one-shot subagent)\n- NO adding parallel executors (single executor model per epic design)\n- NO keeping old solo execution mode (hard commit per Key Decision)\n- NO placeholder text in any section (\"[detailed above]\", \"[as specified]\", \"[TBD]\")\n\n## Key Considerations (SRE Review)\n\n**Edge Case: Executor context exhaustion mid-task**\n- Executor agent definition (agents/executor.md Rule 7) handles this by sending status to lead\n- But what if executor crashes without sending a message? The lead sees an idle notification without a prior message.\n- Lead skill should specify: if executor goes idle without sending a structured completion or escalation message, check bd state (bd list --status in_progress) and assess whether to respawn or ask user\n- Add to resumption check: \"team exists + executor idle + no recent message ‚Üí check bd state, may need to respawn executor\"\n\n**Edge Case: Executor spawned but can't find epic in bd**\n- Executor startup protocol handles this (sends escalation immediately)\n- Lead should be prepared for immediate escalation after spawn ‚Äî this is normal, not a bug\n- Verify the spawn prompt includes the correct epic ID\n\n**Edge Case: Multiple open epics**\n- The skill should specify: one team per epic, one epic at a time\n- If multiple epics open: ask user which to execute (AskUserQuestion)\n- The team name includes epic ID to prevent confusion\n\n**Edge Case: Team already exists from crashed previous session**\n- Resumption check handles this (Step 0 case: \"team exists + executor idle\")\n- But TeamCreate will fail if team already exists\n- Lead should check for existing team BEFORE calling TeamCreate\n- If team exists: skip TeamCreate, check executor state, resume\n\n**Edge Case: Reviewer returns partial verdict (context exhaustion on large epic)**\n- Reviewer agent definition (agents/reviewer.md Rule 8) handles this by prioritizing review\n- Lead should check if verdict mentions \"what remains unreviewed\"\n- If partial: re-dispatch reviewer for remaining tasks\n\n**Edge Case: Executor proposes task that violates epic anti-patterns**\n- This is the lead's core responsibility ‚Äî catch drift\n- The validation step must explicitly check EACH proposed task against EACH anti-pattern\n- Not just a general \"looks good\" ‚Äî systematic check\n\n**Edge Case: SendMessage to executor that has shut down**\n- After GAPS FOUND, if executor was already shut down (e.g., crashed), lead needs to respawn\n- Check if executor is still active before sending fix instructions\n- If not: create new team, spawn new executor with context about gaps to fix\n\n**Edge Case: Executor goes idle after sending completion message (normal)**\n- This is expected agent teams behavior ‚Äî idle notification follows every message\n- Lead MUST NOT treat this as an error or send \"are you still there?\" messages\n- The skill should explicitly state: \"Executor going idle after sending a message is normal\"\n\n**Reference: Agent teams API patterns**\n- Study the TeamCreate, Task (teammate vs subagent), SendMessage, shutdown_request patterns\n- Study the idle notification behavior ‚Äî idle is NORMAL, not an error\n- Study how messages are auto-delivered to lead","status":"closed","priority":2,"issue_type":"feature","owner":"abugosh@gmail.com","created_at":"2026-02-14T11:59:30.707579-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T12:18:49.03681-05:00","closed_at":"2026-02-14T12:18:49.03681-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-3ao","depends_on_id":"bd-t4i","type":"parent-child","created_at":"2026-02-14T11:59:34.629903-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-4","title":"Phase 3: UserPromptSubmit Hook (Skill Activator)","design":"## Goal\nImplement hook that analyzes prompts and injects skill activation reminders.\n\n## Effort Estimate\n6-8 hours\n\n## Success Criteria\n- [ ] UserPromptSubmit hook created and configured in hooks.json\n- [ ] Hook analyzes prompts using skill-rules.json patterns\n- [ ] Top 3 matching skills injected as additionalContext\n- [ ] Priority-based sorting (critical \u003e high \u003e medium \u003e low)\n- [ ] Hook handles errors gracefully (always returns decision: continue)\n- [ ] Performance: \u003c100ms for typical prompt analysis\n- [ ] Manual testing with 5 sample prompts shows correct skill activation\n- [ ] Hook doesn't block or crash on malformed input\n\n## Implementation Steps (ADDED BY writing-plans)\n\n### Step Group 1: Create Hook Directory and Script\n\n**Files:**\n- Create: hooks/user-prompt-submit/10-skill-activator.js\n- Modify: hooks/hooks.json\n\n**Step 1: Create user-prompt-submit directory**\n\nRun:\n\\`\\`\\`bash\nmkdir -p hooks/user-prompt-submit\n\\`\\`\\`\n\n**Step 2: Create the skill-activator hook script**\n\nCreate \\`hooks/user-prompt-submit/10-skill-activator.js\\`:\n\n\\`\\`\\`javascript\n#!/usr/bin/env node\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Configuration\nconst CONFIG = {\n    rulesPath: path.join(__dirname, '..', 'skill-rules.json'),\n    maxSkills: 3,  // Limit to top 3 to avoid context overload\n    debugMode: process.env.DEBUG_HOOKS === 'true'\n};\n\n// Load skill rules from skill-rules.json\nfunction loadRules() {\n    try {\n        const content = fs.readFileSync(CONFIG.rulesPath, 'utf8');\n        const data = JSON.parse(content);\n        // Filter out _comment and _schema meta keys\n        const rules = {};\n        for (const [key, value] of Object.entries(data)) {\n            if (!key.startsWith('_')) {\n                rules[key] = value;\n            }\n        }\n        return rules;\n    } catch (error) {\n        if (CONFIG.debugMode) {\n            console.error('Failed to load skill rules:', error.message);\n        }\n        return {};\n    }\n}\n\n// Read prompt from stdin (Claude passes { \"text\": \"...\" })\nfunction readPrompt() {\n    return new Promise((resolve) =\u003e {\n        let data = '';\n        process.stdin.on('data', chunk =\u003e data += chunk);\n        process.stdin.on('end', () =\u003e {\n            try {\n                resolve(JSON.parse(data));\n            } catch (error) {\n                if (CONFIG.debugMode) {\n                    console.error('Failed to parse prompt:', error.message);\n                }\n                resolve({ text: '' });\n            }\n        });\n    });\n}\n\n// Analyze prompt for skill matches\nfunction analyzePrompt(promptText, rules) {\n    const lowerText = promptText.toLowerCase();\n    const activated = [];\n\n    for (const [skillName, config] of Object.entries(rules)) {\n        let matched = false;\n        let matchReason = '';\n\n        // Check keyword triggers (case-insensitive substring matching)\n        if (config.promptTriggers?.keywords) {\n            for (const keyword of config.promptTriggers.keywords) {\n                if (lowerText.includes(keyword.toLowerCase())) {\n                    matched = true;\n                    matchReason = \\`keyword: \"\\${keyword}\"\\`;\n                    break;\n                }\n            }\n        }\n\n        // Check intent pattern triggers (regex matching)\n        if (!matched \u0026\u0026 config.promptTriggers?.intentPatterns) {\n            for (const pattern of config.promptTriggers.intentPatterns) {\n                try {\n                    if (new RegExp(pattern, 'i').test(promptText)) {\n                        matched = true;\n                        matchReason = \\`intent pattern: \"\\${pattern}\"\\`;\n                        break;\n                    }\n                } catch (error) {\n                    if (CONFIG.debugMode) {\n                        console.error(\\`Invalid pattern \"\\${pattern}\":\\`, error.message);\n                    }\n                }\n            }\n        }\n\n        if (matched) {\n            activated.push({\n                skill: skillName,\n                priority: config.priority || 'medium',\n                reason: matchReason,\n                type: config.type || 'workflow'\n            });\n        }\n    }\n\n    // Sort by priority (critical \u003e high \u003e medium \u003e low)\n    const priorityOrder = { critical: 0, high: 1, medium: 2, low: 3 };\n    activated.sort((a, b) =\u003e {\n        const priorityDiff = priorityOrder[a.priority] - priorityOrder[b.priority];\n        if (priorityDiff !== 0) return priorityDiff;\n        // Secondary sort: process types before domain/workflow types\n        const typeOrder = { process: 0, domain: 1, workflow: 2 };\n        return (typeOrder[a.type] || 2) - (typeOrder[b.type] || 2);\n    });\n\n    // Limit to max skills\n    return activated.slice(0, CONFIG.maxSkills);\n}\n\n// Generate activation context message\nfunction generateContext(skills) {\n    if (skills.length === 0) {\n        return null;\n    }\n\n    const lines = [\n        '',\n        '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ',\n        'üéØ SKILL ACTIVATION CHECK',\n        '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ',\n        '',\n        'Relevant skills for this prompt:',\n        ''\n    ];\n\n    for (const skill of skills) {\n        const emoji = skill.priority === 'critical' ? 'üî¥' : \n                     skill.priority === 'high' ? '‚≠ê' : \n                     skill.priority === 'medium' ? 'üìå' : 'üí°';\n        lines.push(\\`\\${emoji} **\\${skill.skill}** (\\${skill.priority} priority, \\${skill.type})\\`);\n\n        if (CONFIG.debugMode) {\n            lines.push(\\`   Matched: \\${skill.reason}\\`);\n        }\n    }\n\n    lines.push('');\n    lines.push('Before responding, check if any of these skills should be used.');\n    lines.push('Use the Skill tool to activate: \\`Skill command=\"hyperpowers:\u003cskill-name\u003e\"\\`');\n    lines.push('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');\n    lines.push('');\n\n    return lines.join('\\\\n');\n}\n\n// Main execution\nasync function main() {\n    try {\n        // Load rules\n        const rules = loadRules();\n\n        if (Object.keys(rules).length === 0) {\n            if (CONFIG.debugMode) {\n                console.error('No rules loaded');\n            }\n            console.log(JSON.stringify({ decision: 'continue' }));\n            return;\n        }\n\n        // Read prompt\n        const prompt = await readPrompt();\n\n        if (!prompt.text || prompt.text.trim() === '') {\n            console.log(JSON.stringify({ decision: 'continue' }));\n            return;\n        }\n\n        // Analyze prompt\n        const activatedSkills = analyzePrompt(prompt.text, rules);\n\n        // Generate response\n        if (activatedSkills.length \u003e 0) {\n            const context = generateContext(activatedSkills);\n\n            if (CONFIG.debugMode) {\n                console.error('Activated skills:', activatedSkills.map(s =\u003e s.skill).join(', '));\n            }\n\n            console.log(JSON.stringify({\n                decision: 'continue',\n                additionalContext: context\n            }));\n        } else {\n            if (CONFIG.debugMode) {\n                console.error('No skills activated');\n            }\n            console.log(JSON.stringify({ decision: 'continue' }));\n        }\n    } catch (error) {\n        if (CONFIG.debugMode) {\n            console.error('Hook error:', error.message, error.stack);\n        }\n        // Always continue on error - never block user\n        console.log(JSON.stringify({ decision: 'continue' }));\n    }\n}\n\nmain();\n\\`\\`\\`\n\n**Step 3: Make the script executable**\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\n### Step Group 2: Configure Hook in hooks.json\n\n**Files:**\n- Modify: hooks/hooks.json\n\n**Step 4: Read current hooks.json**\n\nRun:\n\\`\\`\\`bash\ncat hooks/hooks.json\n\\`\\`\\`\n\nExpected output shows current hooks (SessionStart, PreToolUse)\n\n**Step 5: Add UserPromptSubmit configuration**\n\nRead the current hooks.json, then update it to add the UserPromptSubmit hook. The complete hooks.json should look like:\n\n\\`\\`\\`json\n{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\${CLAUDE_PLUGIN_ROOT}/hooks/session-start.sh\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\${CLAUDE_PLUGIN_ROOT}/hooks/block-beads-direct-read.py\"\n          }\n        ]\n      }\n    ],\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\${CLAUDE_PLUGIN_ROOT}/hooks/user-prompt-submit/10-skill-activator.js\"\n          }\n        ]\n      }\n    ]\n  }\n}\n\\`\\`\\`\n\n**Step 6: Validate hooks.json syntax**\n\nRun:\n\\`\\`\\`bash\njq . hooks/hooks.json \u003e /dev/null \u0026\u0026 echo \"‚úì Valid JSON\" || echo \"‚úó Invalid JSON\"\n\\`\\`\\`\n\nExpected: \"‚úì Valid JSON\"\n\n### Step Group 3: Manual Testing\n\n**Files:**\n- Test: hooks/user-prompt-submit/10-skill-activator.js\n\n**Step 7: Create test script**\n\nCreate \\`hooks/user-prompt-submit/test-hook.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\nset -e\n\necho \"=== Testing Skill Activator Hook ===\"\necho \"\"\n\ntest_prompt() {\n    local prompt=\"\\$1\"\n    local expected_skills=\"\\$2\"\n    \n    echo \"Test: \\$prompt\"\n    result=\\$(echo \"{\\\\\"text\\\\\": \\\\\"\\$prompt\\\\\"}\" | node hooks/user-prompt-submit/10-skill-activator.js)\n    \n    if echo \"\\$result\" | jq -e '.decision == \"continue\"' \u003e /dev/null; then\n        echo \"‚úì Returns continue decision\"\n    else\n        echo \"‚úó FAIL: Wrong decision\"\n        return 1\n    fi\n    \n    if echo \"\\$result\" | jq -e '.additionalContext' \u003e /dev/null 2\u003e\u00261; then\n        activated=\\$(echo \"\\$result\" | jq -r '.additionalContext' | grep -oP '\\\\*\\\\*\\\\K[^*]+' || true)\n        echo \"  Activated: \\$activated\"\n        \n        if [ -n \"\\$expected_skills\" ]; then\n            for skill in \\$expected_skills; do\n                if echo \"\\$activated\" | grep -q \"\\$skill\"; then\n                    echo \"  ‚úì Expected skill activated: \\$skill\"\n                else\n                    echo \"  ‚úó Missing expected skill: \\$skill\"\n                fi\n            done\n        fi\n    else\n        echo \"  No skills activated\"\n    fi\n    \n    echo \"\"\n}\n\n# Test 1: TDD prompt should activate test-driven-development\ntest_prompt \"I want to write a test for the login function\" \"test-driven-development\"\n\n# Test 2: Debugging prompt should activate debugging-with-tools\ntest_prompt \"Help me debug this error in my code\" \"debugging-with-tools\"\n\n# Test 3: Planning prompt should activate brainstorming\ntest_prompt \"I want to design a new authentication system\" \"brainstorming\"\n\n# Test 4: Refactoring prompt should activate refactoring-safely\ntest_prompt \"Let's refactor this code to be cleaner\" \"refactoring-safely\"\n\n# Test 5: Empty prompt should return continue with no context\ntest_prompt \"\" \"\"\n\necho \"=== All Tests Complete ===\"\n\\`\\`\\`\n\n**Step 8: Make test script executable and run**\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/user-prompt-submit/test-hook.sh\nbash hooks/user-prompt-submit/test-hook.sh\n\\`\\`\\`\n\nExpected: All tests pass with appropriate skills activated\n\n**Step 9: Test performance**\n\nRun:\n\\`\\`\\`bash\ntime echo '{\"text\": \"I want to implement a new feature with TDD\"}' | node hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\nExpected: Completes in \u003c100ms\n\n**Step 10: Test error handling**\n\nRun:\n\\`\\`\\`bash\n# Test with malformed JSON\necho 'invalid json' | node hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\nExpected: Returns \\`{\"decision\":\"continue\"}\\` without crashing\n\n### Step Group 4: Integration Testing\n\n**Files:**\n- All created files\n\n**Step 11: Test in Claude Code environment (manual)**\n\nThis requires testing in an actual Claude Code session to verify the hook activates:\n\n1. Open a new Claude Code session in this project\n2. Type prompt: \"I want to write a test for authentication\"\n3. Observe if skill activation check appears before Claude's response\n4. Verify test-driven-development skill is suggested\n\n**Step 12: Debug if needed**\n\nIf hook doesn't activate, enable debug mode:\n\nRun:\n\\`\\`\\`bash\nexport DEBUG_HOOKS=true\n\\`\\`\\`\n\nThen check Claude Code logs for error messages from the hook.\n\n### Step Group 5: Commit Implementation\n\n**Step 13: Commit all files**\n\nRun:\n\\`\\`\\`bash\ngit add hooks/user-prompt-submit/10-skill-activator.js \\\\\n        hooks/user-prompt-submit/test-hook.sh \\\\\n        hooks/hooks.json\ngit commit -m \"\\$(cat \u003c\u003c'EOF'\nfeat(bd-4): implement UserPromptSubmit hook for skill activation\n\nImplements bd-4: UserPromptSubmit Hook (Skill Activator)\n- Created hooks/user-prompt-submit/10-skill-activator.js (Node.js hook)\n- Analyzes prompts using skill-rules.json patterns\n- Returns top 3 matching skills sorted by priority\n- Injects skill activation check as additionalContext\n- Handles errors gracefully (always returns decision: continue)\n- Performance: \u003c100ms for typical prompts\n- Manual testing script included\n- Updated hooks.json with UserPromptSubmit configuration\n\nThe hook parses user prompts, matches against keyword and intent patterns\nfrom skill-rules.json, and injects a skill activation reminder showing\nthe top 3 relevant skills before Claude processes the prompt.\n\nü§ñ Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e\nEOF\n)\"\n\\`\\`\\`\n\nExpected: Commit successful\n\n**Step 14: Verify commit**\n\nRun:\n\\`\\`\\`bash\ngit log -1 --stat\n\\`\\`\\`\n\nExpected: Shows commit with 3 files changed\n\n## Key Considerations\n- **Error Handling**: Hook must ALWAYS return \\`{\"decision\": \"continue\"}\\` even on error - never block user\n- **Performance**: Keep analysis \u003c100ms - limit to top 3 skills to avoid context overload\n- **Priority Sorting**: critical \u003e high \u003e medium \u003e low, then process \u003e domain \u003e workflow\n- **Debug Mode**: Use DEBUG_HOOKS=true environment variable for troubleshooting\n- **Pattern Safety**: All regex patterns in skill-rules.json use lazy quantifiers to avoid catastrophic backtracking\n- **Graceful Degradation**: If skill-rules.json missing or malformed, return continue with no context\n- **JSON Output**: Must output valid JSON to stdout - errors go to stderr\n\n## Anti-patterns to Avoid\n- ‚ùå Blocking user if hook fails (always return decision: continue)\n- ‚ùå Loading skill-rules.json on every pattern check (load once at start)\n- ‚ùå Activating too many skills (limit to 3 to avoid context pollution)\n- ‚ùå Forgetting to make script executable (chmod +x)\n- ‚ùå Hardcoding paths instead of using __dirname and path.join\n- ‚ùå Not handling malformed JSON input gracefully\n- ‚ùå Using synchronous file operations in hot path (acceptable here since once per prompt)\n- ‚ùå Assuming Node.js modules available (only use built-in: fs, path)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.288291-04:00","updated_at":"2025-10-30T15:33:42.356753-04:00","closed_at":"2025-10-30T15:33:42.356753-04:00","dependencies":[{"issue_id":"bd-4","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.484473-04:00","created_by":"ryan"},{"issue_id":"bd-4","depends_on_id":"bd-3","type":"blocks","created_at":"2025-10-30T13:57:16.831676-04:00","created_by":"ryan"}]}
{"id":"bd-5","title":"Phase 4: PostToolUse Hook (Context Tracker)","design":"## Goal\nImplement hook that tracks file edits and maintains context.\n\n## Effort Estimate\n8-10 hours\n\n## Success Criteria\n- [ ] PostToolUse hook created and configured in hooks.json\n- [ ] Hook tracks Edit and Write tool usage\n- [ ] Context logged with: timestamp, repo, file_path, tool_name\n- [ ] Log stored in hooks/context/edit-log.txt\n- [ ] Log rotation prevents unbounded growth (max 1000 lines)\n- [ ] Non-blocking operation (always returns success)\n- [ ] Hook handles missing/malformed input gracefully\n- [ ] Manual testing shows correct logging of file edits\n- [ ] Context accessible to downstream hooks (bd-6)\n- [ ] Race condition prevention via file locking\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step Group 1: Create Context Storage Infrastructure\n\n**Files:**\n- Create: hooks/context/ (directory)\n- Create: hooks/post-tool-use/01-track-edits.sh\n- Modify: hooks/hooks.json\n\n**Step 1: Create directories**\nRun:\n\\`\\`\\`bash\nmkdir -p hooks/post-tool-use hooks/context\n\\`\\`\\`\n\n**Step 2: Create the edit tracker script**\n\nCreate \\`hooks/post-tool-use/01-track-edits.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Configuration\nCONTEXT_DIR=\"$(dirname \"$0\")/../context\"\nLOG_FILE=\"$CONTEXT_DIR/edit-log.txt\"\nLOCK_FILE=\"$CONTEXT_DIR/.edit-log.lock\"\nMAX_LOG_LINES=1000\nLOCK_TIMEOUT=5\n\n# Create context dir and log if doesn't exist\nmkdir -p \"$CONTEXT_DIR\"\ntouch \"$LOG_FILE\"\n\n# Acquire lock with timeout\nacquire_lock() {\n    local count=0\n    while [ $count -lt $LOCK_TIMEOUT ]; do\n        if mkdir \"$LOCK_FILE\" 2\u003e/dev/null; then\n            return 0\n        fi\n        sleep 0.2\n        count=$((count + 1))\n    done\n    # Log but don't fail - non-blocking requirement\n    echo \"Warning: Could not acquire lock\" \u003e\u00262\n    return 1\n}\n\n# Release lock\nrelease_lock() {\n    rmdir \"$LOCK_FILE\" 2\u003e/dev/null || true\n}\n\n# Clean up lock on exit\ntrap release_lock EXIT\n\n# Function to log edit\nlog_edit() {\n    local file_path=\"$1\"\n    local tool_name=\"$2\"\n    local timestamp=$(date +\"%Y-%m-%d %H:%M:%S\")\n    local repo=$(find_repo \"$file_path\")\n\n    if acquire_lock; then\n        echo \"$timestamp | $repo | $tool_name | $file_path\" \u003e\u003e \"$LOG_FILE\"\n        release_lock\n    fi\n}\n\n# Function to find repo root\nfind_repo() {\n    local file_path=\"$1\"\n    if [ -z \"$file_path\" ] || [ \"$file_path\" = \"null\" ]; then\n        echo \"unknown\"\n        return\n    fi\n\n    local dir\n    dir=$(dirname \"$file_path\" 2\u003e/dev/null || echo \"/\")\n    while [ \"$dir\" != \"/\" ] \u0026\u0026 [ -n \"$dir\" ]; do\n        if [ -d \"$dir/.git\" ]; then\n            basename \"$dir\"\n            return\n        fi\n        dir=$(dirname \"$dir\" 2\u003e/dev/null || echo \"/\")\n    done\n    echo \"unknown\"\n}\n\n# Read tool use event from stdin (with timeout to prevent hanging)\nif ! read -t 2 -r tool_use_json; then\n    echo '{\"decision\": \"continue\"}'\n    exit 0\nfi\n\n# Validate JSON to prevent injection\nif ! echo \"$tool_use_json\" | jq empty 2\u003e/dev/null; then\n    echo '{\"decision\": \"continue\"}'\n    exit 0\nfi\n\n# Extract tool name and file path from tool use\ntool_name=$(echo \"$tool_use_json\" | jq -r '.tool.name // .tool_name // \"unknown\"' 2\u003e/dev/null || echo \"unknown\")\nfile_path=\"\"\n\ncase \"$tool_name\" in\n    \"Edit\"|\"Write\")\n        file_path=$(echo \"$tool_use_json\" | jq -r '.tool.input.file_path // .tool_input.file_path // \"null\"' 2\u003e/dev/null || echo \"null\")\n        ;;\n    \"MultiEdit\")\n        # MultiEdit has multiple files - log each\n        echo \"$tool_use_json\" | jq -r '.tool.input.edits[]?.file_path // .tool_input.edits[]?.file_path // empty' 2\u003e/dev/null | while read -r path; do\n            if [ -n \"$path\" ] \u0026\u0026 [ \"$path\" != \"null\" ]; then\n                log_edit \"$path\" \"$tool_name\"\n            fi\n        done\n        echo '{\"decision\": \"continue\"}'\n        exit 0\n        ;;\nesac\n\n# Log single edit\nif [ -n \"$file_path\" ] \u0026\u0026 [ \"$file_path\" != \"null\" ]; then\n    log_edit \"$file_path\" \"$tool_name\"\nfi\n\n# Rotate log if too large (with lock)\nif acquire_lock; then\n    line_count=$(wc -l \u003c \"$LOG_FILE\" 2\u003e/dev/null || echo \"0\")\n    if [ \"$line_count\" -gt \"$MAX_LOG_LINES\" ]; then\n        tail -n \"$MAX_LOG_LINES\" \"$LOG_FILE\" \u003e \"$LOG_FILE.tmp\"\n        mv \"$LOG_FILE.tmp\" \"$LOG_FILE\"\n    fi\n    release_lock\nfi\n\n# Return success (non-blocking)\necho '{\"decision\": \"continue\"}'\n\\`\\`\\`\n\n**Step 3: Make script executable**\nRun:\n\\`\\`\\`bash\nchmod +x hooks/post-tool-use/01-track-edits.sh\n\\`\\`\\`\n\n### Step Group 2: Create Context Query Utilities\n\n**Step 4: Create context query utilities**\n\nCreate \\`hooks/utils/context-query.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nCONTEXT_DIR=\"$(dirname \"$0\")/../context\"\nLOG_FILE=\"$CONTEXT_DIR/edit-log.txt\"\n\n# Get files edited since timestamp\nget_recent_edits() {\n    local since=\"${1:-}\"\n    \n    if [ ! -f \"$LOG_FILE\" ]; then\n        return 0\n    fi\n    \n    if [ -z \"$since\" ]; then\n        cat \"$LOG_FILE\" 2\u003e/dev/null || true\n    else\n        awk -v since=\"$since\" -F '|' '$1 \u003e= since' \"$LOG_FILE\" 2\u003e/dev/null || true\n    fi\n}\n\n# Get unique files edited in current session\nget_session_files() {\n    local session_start=\"${1:-}\"\n    \n    get_recent_edits \"$session_start\" | \\\\\n        awk -F '|' '{gsub(/^[ \\\\t]+|[ \\\\t]+$/, \"\", $4); print $4}' | \\\\\n        sort -u\n}\n\n# Check if specific file was edited\nwas_file_edited() {\n    local file_path=\"$1\"\n    local since=\"${2:-}\"\n    \n    get_recent_edits \"$since\" | grep -q \"$(printf '%q' \"$file_path\")\" 2\u003e/dev/null\n}\n\n# Get edit count by repo\nget_repo_stats() {\n    local since=\"${1:-}\"\n    \n    get_recent_edits \"$since\" | \\\\\n        awk -F '|' '{gsub(/^[ \\\\t]+|[ \\\\t]+$/, \"\", $2); print $2}' | \\\\\n        sort | uniq -c | sort -rn\n}\n\n# Clear log (for testing)\nclear_log() {\n    if [ -f \"$LOG_FILE\" ]; then\n        \u003e \"$LOG_FILE\"\n    fi\n}\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Race Condition Prevention**:\n- Multiple hooks may run concurrently\n- Use directory-based locking (atomic on most filesystems)\n- Timeout on lock acquisition to prevent deadlock\n- Non-blocking requirement means we log warning but continue\n\n**Input Validation**:\n- Malformed JSON could cause jq to hang or error\n- Use jq empty to validate JSON structure first\n- Read with timeout to prevent hanging on stdin\n\n**Path Security**:\n- File paths may contain spaces, quotes, or shell metacharacters\n- Use proper quoting in all path operations\n- Validate paths don't contain directory traversal (..)\n\n**Disk Full Scenarios**:\n- All writes use \u003e\u003e which will fail gracefully if disk full\n- Log rotation prevents unbounded growth\n- Non-blocking means we continue even if write fails\n\n## Anti-patterns\n- ‚ùå Blocking on I/O or lock acquisition\n- ‚ùå Unbounded log growth without rotation\n- ‚ùå Crashing on malformed input\n- ‚ùå Not handling concurrent access\n- ‚ùå Shell injection via unquoted paths\n- ‚ùå Hanging on stdin read","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.298717-04:00","updated_at":"2025-10-30T15:36:27.582323-04:00","closed_at":"2025-10-30T15:36:27.582323-04:00","dependencies":[{"issue_id":"bd-5","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.497915-04:00","created_by":"ryan"},{"issue_id":"bd-5","depends_on_id":"bd-4","type":"blocks","created_at":"2025-10-30T13:57:16.843566-04:00","created_by":"ryan"}]}
{"id":"bd-5fx","title":"Task 6: Create execute-wave command","design":"## Goal\nCreate commands/execute-wave.md ‚Äî the slash command that invokes the team-executing-plans skill, analogous to how execute-plan.md invokes executing-plans.\n\n## Context\nEpic bd-6t7 Architecture specifies: \"commands/execute-wave.md - Invokes team-executing-plans skill\"\nCurrently this file does not exist. Users have no slash command to invoke team execution.\n\n## Implementation\n\n### Step 1: Read existing command pattern\nRead commands/execute-plan.md to understand the command file format (frontmatter + invocation instruction).\n\n### Step 2: Create commands/execute-wave.md\nFollow the same pattern as execute-plan.md but targeting team-executing-plans:\n\n```yaml\n---\nname: execute-wave\ndescription: Execute a wave of parallel tasks using agent teams. Spawns teammates for each wave task, coordinates execution, and reviews results at wave boundaries.\n---\n```\n\nBody: Instruction to use the team-executing-plans skill exactly as written, with resumption support note.\n\n### Step 3: Verify\n- File exists at commands/execute-wave.md\n- Frontmatter is valid YAML\n- References team-executing-plans skill correctly\n\n## Success Criteria\n- [ ] commands/execute-wave.md exists\n- [ ] Frontmatter includes name: execute-wave and description\n- [ ] Body instructs to use team-executing-plans skill\n- [ ] Follows same pattern as commands/execute-plan.md\n\n## Anti-Patterns\n- DO NOT deviate from existing command file pattern\n- DO NOT add excessive content ‚Äî commands are brief invocation files","status":"closed","priority":1,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-02-06T14:28:44.055167-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-06T14:44:43.261368-05:00","closed_at":"2026-02-06T14:44:43.261368-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-5fx","depends_on_id":"bd-6t7","type":"parent-child","created_at":"2026-02-06T14:28:49.304068-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-5hs","title":"Create architectural-audit skill (SKILL.md + command)","design":"## Goal\nCreate the architectural-audit skill that examines architecture graphs and codebase for complection using Hickey's simplicity framework, producing structured tension reports without recommendations.\n\n## Effort Estimate\n6-10 hours (documentation-heavy: ~400 line SKILL.md + command file)\n\n## Implementation\n\n### 1. Study existing skill patterns\nRead these files to internalize the structure and conventions:\n- skills/volatility-decomposition/SKILL.md ‚Äî sibling skill (graph producer, Socratic)\n- skills/brainstorming/SKILL.md ‚Äî skill structure reference\n- skills/common-patterns/adr-template.md ‚Äî ADR format reference\n\n### 2. Create skills/architectural-audit/SKILL.md\n\nRequired sections (in order):\n1. skill_overview\n2. rigidity_level ‚Äî RIGID (analytical, no adaptation ‚Äî same 6 passes every time, same output format)\n3. quick_reference\n4. when_to_use\n5. the_process ‚Äî Steps 0-3 (context loading, evidence gathering, 6 analysis passes, self-check + present)\n6. examples ‚Äî 4 examples\n7. critical_rules\n8. verification_checklist\n9. integration\n10. resources\n\n### 3. The Process\n\n**Step 0 ‚Äî Load Architecture Graph:**\n- bd list --label arch --type epic --status open\n- If found: load epic + all component nodes\n- If not found: suggest /decompose first (cannot audit without graph)\n- Read existing ADRs: ls doc/arch/adr-*.md\n\n**Step 1 ‚Äî Gather Evidence (codebase-investigator):**\n- ANALYTICAL: No AskUserQuestion. Gather evidence silently.\n- If codebase exists: dispatch codebase-investigator with comprehensive prompt:\n  - Module structure and boundaries\n  - Import/dependency graphs between modules\n  - Co-change patterns (files that change together)\n  - Actual call patterns between modules\n  - Interface surface area (what's exported vs internal)\n- Evidence feeds ALL 6 analysis passes\n- If no codebase (greenfield with graph only): skip, analysis uses graph evidence only\n\n**Step 2 ‚Äî Run 6 Analysis Passes (Hickey Framework):**\nEach pass produces tensions in the structured format.\n\nPass 1: Complection Scan\n- Look for concerns braided together\n- Evidence: import graphs, component responsibilities spanning multiple concerns\n- Graph check: components with multiple volatility axes\n\nPass 2: Interface Analysis\n- Look for interfaces that carry more than one concern\n- Evidence: exported functions/types, component interface contracts\n- Graph check: edges with multiple interaction types\n\nPass 3: Temporal Coupling\n- Look for things that must happen in order but aren't explicitly sequenced\n- Evidence: co-change patterns, initialization order dependencies\n- Graph check: missing edges (components that interact but have no declared relationship)\n\nPass 4: Hidden Dependencies\n- Look for dependencies not visible in the graph\n- Evidence: actual call patterns vs declared edges, shared state, global configuration\n- Graph check: components with no declared dependencies but actual code coupling\n\nPass 5: Layer Violations\n- Look for violations of Lowy layer rules\n- Evidence: upward calls (Engine calling Manager), business logic in Resource Accessors\n- Graph check: layer assignments vs actual behavior\n\nPass 6: State/Identity Conflation\n- Look for mutable shared state, identity conflation\n- Evidence: shared mutable state between components, identity used where value would suffice\n- Graph check: relates_to edges that actually represent shared state\n\n**Step 3 ‚Äî Self-Check + Present:**\nBefore presenting, scan output for accidental recommendations:\n- Keywords: \"should\", \"must\", \"recommend\", \"better\", \"prefer\", \"consider changing\"\n- Severity words: \"critical\", \"high\", \"medium\", \"low\", \"severe\"\n- Phrases: \"however I think\", \"the best approach\", \"you should\"\n- If found: rewrite to neutral observation format\n\nPresent tension report with structured format.\n\n### 4. Tension Report Format\n\n```\n## Tension: [Name]\n**Components:** [A], [B]\n**Pull 1:** [Structural choice] ‚Äî Gain: [benefit]. Cost: [tradeoff].\n**Pull 2:** [Alternative choice] ‚Äî Gain: [benefit]. Cost: [tradeoff].\n**If you assume:** [condition], then Pull 1 is correct.\n**If you assume:** [condition], then Pull 2 is correct.\n**Structural observation:** [neutral fact, e.g., \"affects 3 downstream nodes\"]\n**Evidence:** [what codebase/graph evidence surfaced this]\n```\n\n### 5. ADR-Aware Behavior\n- Read all ADRs before analysis\n- If a tension matches an accepted ADR decision: skip it (already accepted)\n- If codebase evidence contradicts an ADR: report as DRIFT (not tension)\n\n### 6. Drift Report Format\n\n```\n## Drift: [ADR-NNN title]\n**Declared:** [What the ADR says]\n**Observed:** [What the codebase actually does]\n**Evidence:** [Specific files, imports, or patterns]\n```\n\n### 7. Create commands/audit-arch.md\n\nMatching commands/brainstorm.md pattern.\n\n## Examples to Write (4 required)\n\n### Example 1: Good audit finding real tensions\n- Scenario: Audit of order processing graph finds temporal coupling between pricing and fulfillment\n- Shows: proper evidence gathering, structured tension format, no recommendations\n\n### Example 2: BAD ‚Äî Audit that makes recommendations\n- Scenario: Audit output says \"You should merge these components\" or ranks tensions by severity\n- Shows: why_it_fails (denies architect agency, implies solution, severity = recommendation)\n- Correction: rewrite with neutral observations and both pulls\n\n### Example 3: Good audit detecting ADR drift\n- Scenario: ADR says \"payments isolated\" but codebase shows direct payment calls from order logic\n- Shows: drift detection format, evidence-based reporting\n\n### Example 4: BAD ‚Äî Audit that skips self-check\n- Scenario: Output contains \"critical tension\" and \"should be addressed first\"\n- Shows: why_it_fails (severity ranking = recommendation, \"should\" = recommendation)\n- Correction: self-check catches keywords, rewrites to neutral format\n\n## Success Criteria\n- [ ] skills/architectural-audit/SKILL.md exists with all 10 sections\n- [ ] commands/audit-arch.md exists with frontmatter + single-line invocation\n- [ ] Process is ANALYTICAL (no AskUserQuestion during analysis)\n- [ ] 6 analysis passes map to Hickey's framework\n- [ ] Tension report uses exact structured format (tension name, components, both pulls, conditional assumptions)\n- [ ] Self-check step with concrete keyword detection patterns\n- [ ] ADR reading to skip accepted tensions\n- [ ] Drift detection between ADRs and codebase\n- [ ] Codebase-investigator dispatched as standard early step feeding all 6 passes\n- [ ] All 4 examples written\n- [ ] Pre-commit hooks passing\n- [ ] Skill tested with structural verification\n\n## Anti-Patterns\n- NO recommendations in output (both pulls, no preference)\n- NO severity rankings (structural observations only)\n- NO AskUserQuestion during analysis (analytical, not Socratic)\n- NO placeholder text\n- NO skipping examples","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@gmail.com","created_at":"2026-02-14T23:28:21.067431-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T23:33:00.373944-05:00","closed_at":"2026-02-14T23:33:00.373944-05:00","close_reason":"Closed","labels":["arch","skills"],"dependencies":[{"issue_id":"bd-5hs","depends_on_id":"bd-7be","type":"parent-child","created_at":"2026-02-14T23:28:27.317671-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-6","title":"Phase 5: Stop Hook (Gentle Reminders)","design":"## Goal\nImplement hook that shows self-check reminders after Claude responds.\n\n## Effort Estimate\n4-6 hours\n\n## Success Criteria\n- [ ] Stop hook created and configured in hooks.json\n- [ ] Reads context from edit-log.txt successfully\n- [ ] Shows TDD reminder if .ts/.js/.py files edited without test files\n- [ ] Shows verification reminder if user says \"done\" or \"complete\"\n- [ ] Shows commit reminder if \u003e3 files edited in session\n- [ ] Non-intrusive output (max 5 lines)\n- [ ] Handles missing/empty context gracefully\n- [ ] Performance \u003c50ms\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step 1: Create Stop hook directory\nRun:\n\\`\\`\\`bash\nmkdir -p hooks/stop\n\\`\\`\\`\n\n### Step 2: Create gentle reminders hook\n\nCreate \\`hooks/stop/10-gentle-reminders.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Configuration\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\"\nCONTEXT_DIR=\"$SCRIPT_DIR/../context\"\nUTILS_DIR=\"$SCRIPT_DIR/../utils\"\nLOG_FILE=\"$CONTEXT_DIR/edit-log.txt\"\nSESSION_START=$(date -d \"1 hour ago\" +\"%Y-%m-%d %H:%M:%S\" 2\u003e/dev/null || date -v-1H +\"%Y-%m-%d %H:%M:%S\")\n\n# Source utilities (if they exist)\nif [ -f \"$UTILS_DIR/context-query.sh\" ]; then\n    source \"$UTILS_DIR/context-query.sh\"\nelse\n    # Fallback if utilities missing\n    get_session_files() {\n        if [ -f \"$LOG_FILE\" ]; then\n            awk -F '|' -v since=\"$SESSION_START\" '$1 \u003e= since {gsub(/^[ \\\\t]+|[ \\\\t]+$/, \"\", $4); print $4}' \"$LOG_FILE\" | sort -u\n        fi\n    }\nfi\n\n# Read response from stdin to check for completion claims\nRESPONSE=\"\"\nif read -t 1 -r response_json 2\u003e/dev/null; then\n    RESPONSE=$(echo \"$response_json\" | jq -r '.text // \"\"' 2\u003e/dev/null || echo \"\")\nfi\n\n# Get edited files in this session\nEDITED_FILES=$(get_session_files \"$SESSION_START\" 2\u003e/dev/null || echo \"\")\nFILE_COUNT=$(echo \"$EDITED_FILES\" | grep -c . 2\u003e/dev/null || echo \"0\")\n\n# Check patterns for appropriate reminders\nSHOW_TDD_REMINDER=false\nSHOW_VERIFY_REMINDER=false\nSHOW_COMMIT_REMINDER=false\n\n# Check 1: Files edited but no test files?\nif [ \"$FILE_COUNT\" -gt 0 ]; then\n    # Check if source files edited\n    if echo \"$EDITED_FILES\" | grep -qE '\\\\.(ts|js|py|go|rs|java)$' 2\u003e/dev/null; then\n        # Check if NO test files edited\n        if ! echo \"$EDITED_FILES\" | grep -qE '(test|spec)\\\\.(ts|js|py|go|rs|java)$' 2\u003e/dev/null; then\n            SHOW_TDD_REMINDER=true\n        fi\n    fi\n    \n    # Check 2: Many files edited?\n    if [ \"$FILE_COUNT\" -ge 3 ]; then\n        SHOW_COMMIT_REMINDER=true\n    fi\nfi\n\n# Check 3: User claiming completion?\nif echo \"$RESPONSE\" | grep -iE '(done|complete|finished|ready|works)' \u003e/dev/null 2\u003e\u00261; then\n    SHOW_VERIFY_REMINDER=true\nfi\n\n# Display appropriate reminders (max 5 lines)\nif [ \"$SHOW_TDD_REMINDER\" = true ] || [ \"$SHOW_VERIFY_REMINDER\" = true ] || [ \"$SHOW_COMMIT_REMINDER\" = true ]; then\n    echo \"\"\n    echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\n    \n    if [ \"$SHOW_TDD_REMINDER\" = true ]; then\n        echo \"üí≠ Remember: Write tests first (TDD)\"\n    fi\n    \n    if [ \"$SHOW_VERIFY_REMINDER\" = true ]; then\n        echo \"‚úÖ Before claiming complete: Run tests\"\n    fi\n    \n    if [ \"$SHOW_COMMIT_REMINDER\" = true ]; then\n        echo \"üíæ Consider: $FILE_COUNT files edited - commit?\"\n    fi\n    \n    echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\nfi\n\n# Always return success (non-blocking)\nexit 0\n\\`\\`\\`\n\n### Step 3: Make executable\nRun:\n\\`\\`\\`bash\nchmod +x hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\n### Step 4: Update hooks.json\n\nAdd Stop hook configuration to \\`hooks/hooks.json\\` (preserve existing entries):\n\n\\`\\`\\`json\n{\n  \"hooks\": {\n    \"SessionStart\": [...],\n    \"PreToolUse\": [...],\n    \"UserPromptSubmit\": [...],\n    \"PostToolUse\": [...],\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/stop/10-gentle-reminders.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n\\`\\`\\`\n\n### Step 5: Create test script\n\nCreate \\`hooks/stop/test-reminders.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\nset -e\n\necho \"=== Testing Stop Hook Reminders ===\"\n\n# Test 1: No edits = no reminder\necho \"Test 1: No edits\"\n\u003e hooks/context/edit-log.txt\necho '{\"text\": \"All done!\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out1.txt\n[ ! -s /tmp/out1.txt ] \u0026\u0026 echo \"‚úì No reminder (correct)\" || echo \"‚úó Unexpected reminder\"\n\n# Test 2: Source file edited without test = TDD reminder\necho \"Test 2: TDD reminder\"\necho \"$(date +\"%Y-%m-%d %H:%M:%S\") | hyper | Edit | src/main.ts\" \u003e hooks/context/edit-log.txt\necho '{\"text\": \"Feature implemented\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out2.txt\ngrep -q \"TDD\" /tmp/out2.txt \u0026\u0026 echo \"‚úì TDD reminder shown\" || echo \"‚úó TDD reminder missing\"\n\n# Test 3: Completion claim = verification reminder\necho \"Test 3: Verification reminder\"\necho '{\"text\": \"All done and tests pass!\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out3.txt\ngrep -q \"Run tests\" /tmp/out3.txt \u0026\u0026 echo \"‚úì Verify reminder shown\" || echo \"‚úó Verify reminder missing\"\n\n# Test 4: Many files = commit reminder\necho \"Test 4: Commit reminder\"\nfor i in {1..5}; do\n    echo \"$(date +\"%Y-%m-%d %H:%M:%S\") | hyper | Edit | src/file$i.ts\" \u003e\u003e hooks/context/edit-log.txt\ndone\necho '{\"text\": \"Refactoring complete\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out4.txt\ngrep -q \"commit\" /tmp/out4.txt \u0026\u0026 echo \"‚úì Commit reminder shown\" || echo \"‚úó Commit reminder missing\"\n\necho \"=== All Tests Complete ===\"\n\\`\\`\\`\n\n### Step 6: Run tests\nRun:\n\\`\\`\\`bash\nchmod +x hooks/stop/test-reminders.sh\nbash hooks/stop/test-reminders.sh\n\\`\\`\\`\n\nExpected: All tests pass\n\n### Step 7: Test performance\nRun:\n\\`\\`\\`bash\ntime echo '{\"text\": \"Done\"}' | bash hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\nExpected: \u003c50ms execution time\n\n### Step 8: Commit\nRun:\n\\`\\`\\`bash\ngit add hooks/stop/10-gentle-reminders.sh hooks/stop/test-reminders.sh hooks/hooks.json\ngit commit -m \"feat(bd-6): implement Stop hook for gentle reminders\n\nImplements bd-6: Stop Hook (Gentle Reminders)\n- Shows TDD reminder when source edited without tests\n- Shows verification reminder when user claims complete\n- Shows commit reminder when many files edited\n- Non-intrusive (max 5 lines output)\n- Performance \u003c50ms\"\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Context Availability**:\n- edit-log.txt may not exist (fresh install)\n- PostToolUse hook (bd-5) may not be running\n- Must handle gracefully with fallbacks\n\n**Pattern Matching Accuracy**:\n- Avoid false positives (e.g., \"done\" in middle of sentence)\n- Source vs test file detection must be accurate\n- Consider different naming conventions (test.js, spec.js, _test.go)\n\n**User Experience**:\n- Keep output brief (max 5 lines)\n- Only show relevant reminders, not all\n- Use clear, actionable language\n\n**Performance**:\n- Stop hook runs after every Claude response\n- Must be fast (\u003c50ms) to not delay user\n- Avoid complex processing or external commands\n\n## Anti-patterns\n- ‚ùå Annoying/repetitive reminders every response\n- ‚ùå Blocking on I/O or missing files\n- ‚ùå Long multi-paragraph reminders\n- ‚ùå False positive pattern matching\n- ‚ùå Slow execution delaying response","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.309595-04:00","updated_at":"2025-10-30T15:38:52.605286-04:00","closed_at":"2025-10-30T15:38:52.605286-04:00","dependencies":[{"issue_id":"bd-6","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.518056-04:00","created_by":"ryan"},{"issue_id":"bd-6","depends_on_id":"bd-5","type":"blocks","created_at":"2025-10-30T13:57:16.854063-04:00","created_by":"ryan"}]}
{"id":"bd-67h","title":"Task 2: Update skills to remove pre-commit references","design":"## Goal\nUpdate all skills that reference pre-commit hooks to use the new universal validation terminology ('Run: validate', linter/typecheck/tests).\n\n## Effort Estimate\n2-3 hours\n\n## Files to Update\nBased on earlier grep, these skills reference pre-commit:\n1. skills/verification-before-completion/SKILL.md\n2. skills/review-implementation/SKILL.md\n3. skills/finishing-a-development-branch/SKILL.md\n4. skills/fixing-bugs/SKILL.md\n5. skills/brainstorming/SKILL.md\n6. skills/common-patterns/bd-commands.md\n\n## Implementation\n\n### For each file:\n1. Search for 'pre-commit' references\n2. Replace with appropriate universal terminology:\n   - 'Pre-commit hooks pass' ‚Üí 'Validations pass (lint, typecheck, tests)'\n   - 'Run pre-commit' ‚Üí 'Run: validate'\n   - 'pre-commit hooks' ‚Üí 'project validations'\n3. Verify no pre-commit strings remain\n\n### Specific changes:\n**verification-before-completion/SKILL.md:**\n- Line ~28: Update 'Use test-runner agent for' description\n- Line ~146: Update checklist item 'Pre-commit hooks pass'\n- Line ~161: Update 'Pre-commit hooks not checked'\n- Line ~178: Update comment about pre-commit\n- Lines ~295-301: Update/remove 'Pre-Commit Hook Assumption' section\n\n**review-implementation/SKILL.md:**\n- Line ~214: Change 'Run: .git/hooks/pre-commit' to 'Run: validate'\n- Lines ~455, 476, 508, 543, 560, 682, 690, 700, 728: Update pre-commit references\n\n**finishing-a-development-branch/SKILL.md:**\n- Update Step 2 to use 'Run: validate' instead of pre-commit\n\n**fixing-bugs/SKILL.md:**\n- Lines ~180, 501: Update 'Pre-commit hooks pass' to 'Validations pass'\n\n**brainstorming/SKILL.md:**\n- Lines ~199, 370: Update success criteria template\n\n**common-patterns/bd-commands.md:**\n- Line ~122: Update comment about pre-commit\n\n## Success Criteria\n- [ ] `grep -r 'pre-commit' skills/` returns only expected files (debugging references, not test-runner calls)\n- [ ] verification-before-completion references 'Run: validate'\n- [ ] review-implementation references 'Run: validate'\n- [ ] finishing-a-development-branch Step 2 uses 'Run: validate'\n- [ ] All success criteria templates updated to 'Validations pass'\n- [ ] Changes committed\n\n## Anti-Patterns\n- ‚ùå NO leaving 'pre-commit hooks pass' in checklists (inconsistent)\n- ‚ùå NO references to .git/hooks/pre-commit (doesn't exist in most projects)\n- ‚ùå NO breaking skill functionality (preserve verification intent)","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-01-22T12:25:41.84212-05:00","created_by":"Alex Bugosh","updated_at":"2026-01-22T12:36:21.218913-05:00","closed_at":"2026-01-22T12:36:21.218913-05:00","close_reason":"Updated all skill files to use universal validation terminology","dependencies":[{"issue_id":"bd-67h","depends_on_id":"bd-9gk","type":"blocks","created_at":"2026-01-22T12:25:47.186165-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-6t7","title":"Feature: Wave-Based Team Execution Workflow","design":"## Requirements (IMMUTABLE)\n- Brainstorming skill produces epics with a Parallelism Map section identifying independent work streams, file ownership boundaries, and suggested wave composition\n- A new wave-planning skill creates batches of parallelizable tasks from the Parallelism Map, sets beads dependencies, and runs SRE refinement on the batch\n- A new team-executing-plans skill spawns agent teams from wave tasks, coordinates execution with hybrid delegation (Option C), reviews results, reconciles beads state, and plans next waves\n- Agent definitions (test-runner, code-reviewer, codebase-investigator, internet-researcher) are upgraded with new subagent features (persistent memory, skills injection, permission modes, hooks)\n- The using-hyper skill includes a decision point routing to team or solo execution path based on parallelism analysis\n- Existing solo executing-plans skill continues to work unchanged\n- STOP checkpoints occur at wave boundaries (not per-task) for human review\n- Beads integration: teammates can safely read (bd show) and update status (bd update --status, bd close); lead handles task creation, dependency management, and sync\n\n## Success Criteria (MUST ALL BE TRUE)\n- [ ] Brainstorming skill epic template includes Parallelism Map section (independent streams, file ownership, suggested waves)\n- [ ] wave-planning skill exists and creates task batches with beads dependencies from Parallelism Map\n- [ ] team-executing-plans skill exists and spawns agent teams with hybrid delegation\n- [ ] team-executing-plans presents wave-level STOP checkpoint summary after each wave\n- [ ] Agent definitions use new subagent features (memory, permissionMode, skills, hooks, disallowedTools as appropriate)\n- [ ] using-hyper routes to team path when 3+ independent streams exist, solo path otherwise\n- [ ] Existing solo executing-plans skill works identically to before (no regressions)\n- [ ] Teammate spawn prompts include: epic requirements, task details, anti-patterns, file ownership boundaries, TDD/verification methodology\n- [ ] Lead operates in delegate mode during team execution (coordinate only, no implementation)\n- [ ] Wave review includes: per-teammate results, integration test verification, beads reconciliation, next wave proposal\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO replacing the solo executing-plans workflow (coexist: team path is additive, solo path unchanged)\n- ‚ùå NO teammates creating beads tasks or managing dependencies (lead manages task creation, bd dep add, bd create)\n- ‚ùå NO teammates running bd sync (lead handles git sync at wave boundaries)\n- ‚ùå NO skipping wave-level STOP checkpoints (human must review wave results before next wave spawns)\n- ‚ùå NO spawning teams for fewer than 3 independent tasks (coordination overhead exceeds benefit; use solo path)\n- ‚ùå NO teammates editing files outside their assigned ownership boundary (prevents merge conflicts)\n- ‚ùå NO teammates messaging each other directly (all coordination flows through lead to maintain oversight)\n- ‚ùå NO continuous multi-wave execution without human checkpoint (each wave boundary is a mandatory STOP)\n- ‚ùå NO creating full task trees upfront (waves are created iteratively based on learnings from previous waves)\n\n## Approach\nAdd a team-aware execution path to the hyperpowers workflow that coexists with the current solo path. The brainstorming skill gains a Parallelism Map section in its epic template that identifies independent work streams and file ownership. After brainstorming, a decision point routes to either the existing solo workflow (executing-plans) or the new team workflow (wave-planning ‚Üí team-executing-plans). The team workflow creates waves of parallelizable tasks, spawns agent teams to execute them, reviews results at wave boundaries with mandatory human checkpoints, and iterates until all epic success criteria are met. Hybrid delegation (Option C) means teammates execute assigned tasks and can propose new tasks or flag issues to the lead, but the lead approves all changes to scope and dependencies.\n\n## Architecture\n\n### New Skills\n- skills/wave-planning/SKILL.md - Analyzes Parallelism Map, creates task batches, sets dependencies, runs SRE refinement\n- skills/team-executing-plans/SKILL.md - Spawns teams, monitors execution, reviews waves, reconciles beads, STOP checkpoints\n\n### Modified Skills\n- skills/brainstorming/SKILL.md - Add Parallelism Map section to epic template\n- skills/using-hyper/SKILL.md - Add team vs. solo decision point and routing\n\n### Modified Agents\n- agents/test-runner.md - Add permissionMode: dontAsk, disallowedTools: Edit, Write\n- agents/code-reviewer.md - Add memory: project, skills: [testing-anti-patterns]\n- agents/codebase-investigator.md - Add memory: project, permissionMode: plan\n- agents/internet-researcher.md - Add memory: user\n\n### New Commands\n- commands/execute-wave.md - Invokes team-executing-plans skill\n\n### Workflow\n\n```\nBrainstorm ‚Üí Epic (with Parallelism Map)\n  ‚Üí Decision: 3+ independent streams?\n    ‚Üí Yes: wave-planning ‚Üí team-executing-plans ‚Üí wave review loop ‚Üí STOP\n    ‚Üí No: writing-plans ‚Üí executing-plans (solo, unchanged)\n  ‚Üí review-implementation ‚Üí finish-branch\n```\n\n### Teammate Spawn Template\nEach teammate receives:\n1. Epic requirements + anti-patterns (from bd show)\n2. Specific task details (from bd show)\n3. File ownership boundaries (from Parallelism Map)\n4. Methodology skills (TDD, verification-before-completion)\n5. Constraint: propose new work to lead, don't self-create tasks\n\n### Beads Integration\n- Before team spawn: bd ready identifies independent tasks, bd dep tree verifies ordering\n- During execution: Teammates use bd update --status in_progress and bd close (safe via daemon RPC)\n- After wave: Lead runs bd ready for unblocked work, creates new wave tasks, bd sync\n\n## Design Rationale\n\n### Problem\nHyperpowers executes tasks sequentially: one task ‚Üí STOP ‚Üí user reviews ‚Üí next task. When an epic has 5+ tasks with independent work streams (different modules, different files), this leaves parallelism on the table. Claude Code's agent teams feature enables parallel execution by multiple Claude instances, but hyperpowers has no skill to leverage this.\n\n### Research Findings\n\n**Agent Teams (code.claude.com/docs/en/agent-teams):**\n- Shared task list with file-locking for concurrent claiming\n- Inter-agent messaging and teammate self-coordination\n- Delegate mode restricts lead to coordination-only tools\n- Plan approval requires teammate plans before implementing\n- Experimental, higher token cost, works best when teammates operate independently\n\n**Beads Concurrency (github.com/steveyegge/beads):**\n- SQLite primary store with daemon singleton serializing all writes via RPC\n- Three-layer locking: daemon lock, JSONL file lock, SQLite internal locking\n- Hash-based IDs prevent cross-agent collisions\n- Safe for concurrent CLI access when daemon is running\n- Risk areas: note append (last-writer-wins), git push contention\n\n**Subagent Evolution (code.claude.com/docs/en/sub-agents):**\n- Persistent memory (user/project/local scope) for cross-session learning\n- Skills injection via frontmatter for domain knowledge\n- Hook support for validation within subagents\n- Permission modes (plan, dontAsk, bypassPermissions)\n- Context forking and backgrounding improvements\n\n**ed3d-plugins (github.com/ed3dai/ed3d-plugins):**\n- Design/implementation separation (archival vs just-in-time) - strong pattern but deferred to separate epic\n- Persuasion psychology applied to skill design (Meincke et al. 2025)\n- Context compaction resilience through absolute paths and verbatim descriptions\n\n### Approaches Considered\n\n#### 1. Wave-Based Team Execution with Hybrid Delegation ‚úì\n\n**What it is:** Create waves of parallelizable tasks based on a Parallelism Map in the epic. Spawn agent teams per wave. Teammates execute assigned tasks and can propose changes to lead. STOP at wave boundaries for human review. Iterate until epic complete.\n\n**Investigation:**\n- Analyzed agent teams docs - shared task list, delegate mode, plan approval map to this model\n- Verified beads concurrent access is safe for teammate status updates\n- Confirmed hybrid delegation balances autonomy with oversight\n\n**Pros:**\n- Parallelizes independent work within waves\n- Preserves learning between waves (tasks adapt to reality)\n- Human oversight at wave boundaries\n- Leverages beads dependency graph for wave composition\n- Compatible with existing solo path\n\n**Cons:**\n- Higher token cost per wave (multiple Claude instances)\n- Lead coordination overhead\n- Agent teams feature is experimental\n\n**Chosen because:** Best balance of parallelism, oversight, and iterative learning. Preserves hyperpowers' core methodology while leveraging native team capabilities.\n\n#### 2. Full Autonomous Team Execution ‚ùå\n\n**What it is:** Spawn team at epic start, let teammates self-organize through all tasks continuously until epic complete. No wave boundaries or mandatory checkpoints.\n\n**Why we looked at this:** Maximum parallelism, minimum human intervention.\n\n**Investigation:**\n- Reviewed agent teams best practices: \"Monitor and steer. Letting a team run unattended for too long increases the risk of wasted effort.\"\n- Conflicts with hyperpowers' oversight philosophy (STOP checkpoints, verification before completion)\n\n**Pros:**\n- Maximum speed for well-defined work\n- Minimal human interaction needed\n\n**Cons:**\n- No learning between iterations (all tasks planned upfront)\n- No human review until everything is done\n- Teammates may make conflicting assumptions\n- Wasted work if early tasks reveal wrong approach\n\n**‚ö†Ô∏è REJECTED BECAUSE:** Violates hyperpowers' core oversight principle. No checkpoints means no course correction. Wasted work risk too high.\n\n**üö´ DO NOT REVISIT UNLESS:** We build a reliable automated review system that can substitute for human checkpoints.\n\n#### 3. Subagent-Only Parallel Dispatch (No Teams) ‚ùå\n\n**What it is:** Use existing dispatching-parallel-agents skill pattern - launch subagents via Task() in a single message. No agent teams, no shared task list, no inter-agent communication.\n\n**Why we looked at this:** Lower complexity, lower cost, proven pattern.\n\n**Investigation:**\n- Current dispatching-parallel-agents skill works well for 3+ independent failures\n- Subagents can't communicate with each other\n- Subagents return results to main context (context pollution risk with many tasks)\n\n**Pros:**\n- Lower token cost\n- Simpler architecture\n- Proven pattern\n\n**Cons:**\n- No inter-agent communication (can't coordinate on ambiguities)\n- Results all return to main context (context pressure with 4+ agents)\n- No shared task list (manual coordination)\n- No plan approval mechanism\n\n**‚ö†Ô∏è REJECTED BECAUSE:** Doesn't scale to wave-level complexity (4+ concurrent tasks with coordination needs). Subagents remain the right choice for independent investigation/debugging, but team execution needs the full agent teams capability.\n\n**üö´ DO NOT REVISIT UNLESS:** Agent teams feature is removed or permanently broken, and we need a fallback.\n\n### Scope Boundaries\n\n**In scope:**\n- Brainstorming skill: Parallelism Map section in epic template\n- New wave-planning skill\n- New team-executing-plans skill\n- Agent definition upgrades (memory, permissions, skills, hooks)\n- using-hyper decision point update\n- New execute-wave command\n\n**Out of scope (deferred):**\n- ed3d design/implementation separation pattern (separate epic)\n- ed3d scoped acceptance criteria format (separate epic)\n- Competing hypotheses debugging skill (separate epic)\n- Parallel research during brainstorming (separate epic - brainstorm stays single-session)\n- Native Tasks integration (beads remains primary tracker)\n\n### Open Questions\n- Exact wave size heuristics - how many tasks per wave in different confidence scenarios? (resolve during wave-planning skill creation)\n- Teammate model selection - should all teammates use the same model or should it be configurable per task? (resolve during team-executing skill creation)\n- How to handle teammate failures gracefully - retry, reassign, or escalate to lead? (resolve during team-executing skill creation)\n\n## Design Discovery (Reference Context)\n\n\u003e Detailed context from brainstorming for task creation and obstacle handling.\n\n### Key Decisions Made\n\n| Question | User Answer | Implication |\n|----------|-------------|-------------|\n| Epic scope? | Full workflow (new skills + adapted skills + agent upgrades) | All deliverables in one epic |\n| Team vs solo compatibility? | Coexist (separate skills) | executing-plans unchanged, new team-executing-plans skill |\n| Adopt ed3d patterns? | None for now (separate epic) | Focus on team workflow only |\n| Brainstorm changes? | Add Parallelism Map to epic | Epic template gains new section |\n| Teammate autonomy model? | Option C: Hybrid delegation | Teammates execute + propose, lead approves |\n| Beads in teams? | Strategic + execution layer | Teammates can read/update status; lead manages creation/deps/sync |\n\n### Research Deep-Dives\n\n#### Agent Teams Architecture\n**Question explored:** How do Claude Code agent teams work and how do they compare to subagents?\n**Sources consulted:**\n- code.claude.com/docs/en/agent-teams - Full teams documentation\n- code.claude.com/docs/en/sub-agents - Full subagents documentation\n- VentureBeat articles on Claude Code 2.1.0 and teams feature\n\n**Findings:**\n- Teams: separate Claude instances, shared task list with file locking, inter-agent messaging, delegate mode, plan approval\n- Subagents: within single session, results return to main context, no inter-agent communication\n- Teams use significantly more tokens but enable true parallel work with coordination\n- Experimental feature with known limitations (no session resumption, one team per session)\n\n**Conclusion:** Teams for wave execution (coordination needed), subagents remain for focused tasks (test running, investigation)\n\n#### Beads Concurrent Access\n**Question explored:** Is beads safe for multiple Claude Code sessions accessing simultaneously?\n**Sources consulted:**\n- github.com/steveyegge/beads - Full source code analysis\n- Storage architecture: SQLite + daemon + JSONL dual-layer\n\n**Findings:**\n- SQLite primary store with daemon singleton serializing writes via RPC\n- Three-layer locking (daemon, JSONL file, SQLite)\n- Hash-based IDs prevent collisions\n- Concurrent CLI access safe when daemon running\n- Risk: note append is last-writer-wins, git push can conflict\n- Worktree model supported for multi-agent isolation\n\n**Conclusion:** Safe for teammates to read and update status. Lead should handle creation, dependencies, and sync.\n\n#### ed3d-plugins Comparison\n**Question explored:** How does ed3d-plugins compare and what patterns should we adopt?\n**Sources consulted:**\n- github.com/ed3dai/ed3d-plugins - Full repository analysis (9 plugins, 35+ skill/agent files)\n\n**Findings:**\n- Design/implementation separation is their strongest architectural pattern\n- Persuasion psychology research (Meincke et al. 2025) informs skill compliance\n- Context compaction resilience through absolute paths and verbatim descriptions\n- Marketplace model allows modular installation\n- Coding standards plugins (TypeScript, PostgreSQL, React, FCIS) have no hyperpowers equivalent\n\n**Conclusion:** Strong patterns worth adopting, but in separate epics to keep this one focused on team workflow\n\n### Dead-End Paths\n\n#### Full Autonomous Execution\n**Why explored:** Maximum parallelism with minimal human intervention\n**Investigation:** Reviewed agent teams docs, assessed against hyperpowers oversight philosophy\n**Why abandoned:** No checkpoints means no course correction. Wasted work risk too high.\n\n#### Subagent-Only Approach\n**Why explored:** Lower complexity and cost, proven pattern\n**Investigation:** Assessed scalability, communication, context pressure\n**Why abandoned:** Doesn't scale to wave-level complexity with 4+ concurrent coordinated tasks\n\n#### Native Tasks Replacing Beads\n**Why explored:** Native task system integrates with agent teams\n**Investigation:** Compared features: beads has richer schema, DAG deps, git persistence, cross-session recovery\n**Why abandoned:** Native tasks lack epic structure, immutable requirements, design discovery. Better as complement, not replacement.\n\n### Open Concerns Raised\n\n- 'Agent teams are experimental' ‚Üí Feature is additive; solo path remains as fallback. Skills should degrade gracefully if teams unavailable.\n- 'Token cost of teams is high' ‚Üí Wave sizing heuristics should optimize for meaningful parallelism, not maximum parallelism. Solo path for small epics.\n- 'Teammates might edit same files' ‚Üí File ownership boundaries in Parallelism Map + spawn prompt constraints. Anti-pattern enforced.\n- 'How to test team-based skills?' ‚Üí Pressure testing with subagents (from writing-skills methodology). Manual validation of team spawning. No CI for experimental features.","status":"closed","priority":1,"issue_type":"epic","owner":"abugosh@jellyvision.com","created_at":"2026-02-06T11:39:38.510371-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T07:46:39.772813-05:00","closed_at":"2026-02-14T07:46:39.772813-05:00","close_reason":"Reverting wave system - doesn't match actual work patterns"}
{"id":"bd-7","title":"Phase 6: Update Documentation","design":"## Goal  \nUpdate documentation for new hooks system.\n\n## Effort Estimate\n2-4 hours\n\n## Success Criteria\n- [ ] README.md updated with Hooks System section\n- [ ] Each hook type documented with examples\n- [ ] Installation instructions include hook setup\n- [ ] Troubleshooting section added\n- [ ] skills/skills-auto-activation/SKILL.md references updated\n- [ ] All code examples tested and working\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step 1: Update main README.md\n\nAdd the following section after \"## Features\" in README.md:\n\n\\`\\`\\`markdown\n## Hooks System\n\nHyperpowers includes an intelligent hooks system that provides context-aware assistance:\n\n### Automatic Skill Activation\nWhen you type a prompt, the UserPromptSubmit hook analyzes it and suggests relevant skills:\n\n\\`\\`\\`\nUser: I want to write a test for the login function\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüéØ SKILL ACTIVATION CHECK\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚≠ê **test-driven-development** (high priority, process)\nüìå **debugging-with-tools** (medium priority, process)\n\nUse the Skill tool to activate: \\`Skill command=\"hyperpowers:test-driven-development\"\\`\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\\`\\`\\`\n\n### Context Tracking\nThe PostToolUse hook tracks file edits during your session, maintaining context for intelligent reminders.\n\n### Gentle Reminders\nAfter Claude responds, the Stop hook provides helpful reminders based on context:\n- üí≠ TDD reminder when editing source without tests\n- ‚úÖ Verification reminder when claiming completion\n- üíæ Commit reminder after multiple file edits\n\n### Hook Configuration\n\nHooks are configured in \\`hooks/hooks.json\\`:\n\n\\`\\`\\`json\n{\n  \"hooks\": {\n    \"UserPromptSubmit\": [...],  // Skill activation\n    \"PostToolUse\": [...],        // Context tracking\n    \"Stop\": [...]                // Gentle reminders\n  }\n}\n\\`\\`\\`\n\\`\\`\\`\n\n### Step 2: Create HOOKS.md documentation\n\nCreate \\`HOOKS.md\\` in project root:\n\n\\`\\`\\`markdown\n# Hyperpowers Hooks Documentation\n\n## Overview\nHyperpowers uses Claude Code's hooks system to provide intelligent, context-aware assistance.\n\n## Hook Types\n\n### UserPromptSubmit Hook\n**File:** \\`hooks/user-prompt-submit/10-skill-activator.js\\`\n**Purpose:** Analyzes prompts and suggests relevant skills\n**Input:** \\`{\"text\": \"user prompt text\"}\\`\n**Output:** \\`{\"decision\": \"continue\", \"additionalContext\": \"skill suggestions\"}\\`\n\n**Configuration:**\n- Edit \\`hooks/skill-rules.json\\` to adjust skill triggers\n- Set \\`DEBUG_HOOKS=true\\` for troubleshooting\n\n### PostToolUse Hook  \n**File:** \\`hooks/post-tool-use/01-track-edits.sh\\`\n**Purpose:** Tracks file edits for context\n**Input:** \\`{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"...\"}}}\\`\n**Output:** \\`{\"decision\": \"continue\"}\\`\n\n**Context Storage:**\n- Log file: \\`hooks/context/edit-log.txt\\`\n- Format: \\`timestamp | repo | tool | filepath\\`\n- Auto-rotates at 1000 lines\n\n### Stop Hook\n**File:** \\`hooks/stop/10-gentle-reminders.sh\\`\n**Purpose:** Shows context-aware reminders\n**Input:** \\`{\"text\": \"claude's response\"}\\` (optional)\n**Output:** Brief reminders to stdout\n\n## Installation\n\n1. Ensure Node.js is installed (for skill activator)\n2. Hooks auto-activate when plugin is loaded\n3. Verify with: \\`ls hooks/\\`\n\n## Troubleshooting\n\n### Skill activator not working\n\\`\\`\\`bash\n# Enable debug mode\nexport DEBUG_HOOKS=true\n\n# Test manually\necho '{\"text\": \"I want to write a test\"}' | node hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\n### Context not tracking\n\\`\\`\\`bash\n# Check log file\ncat hooks/context/edit-log.txt\n\n# Test manually\necho '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' | \\\\\n  bash hooks/post-tool-use/01-track-edits.sh\n\\`\\`\\`\n\n### Reminders not showing\n\\`\\`\\`bash\n# Test manually\necho '{\"text\": \"All done!\"}' | bash hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\n## Customization\n\n### Adjusting skill triggers\nEdit \\`hooks/skill-rules.json\\`:\n\\`\\`\\`json\n{\n  \"skill-name\": {\n    \"priority\": \"high\",\n    \"promptTriggers\": {\n      \"keywords\": [\"test\", \"testing\"],\n      \"intentPatterns\": [\"write.*test\", \"create.*spec\"]\n    }\n  }\n}\n\\`\\`\\`\n\n### Disabling hooks\nRemove from \\`hooks/hooks.json\\` or rename hook file.\n\n## Performance\n\n- UserPromptSubmit: \u003c100ms per prompt\n- PostToolUse: \u003c10ms per edit\n- Stop: \u003c50ms per response\n\\`\\`\\`\n\n### Step 3: Update skills/skills-auto-activation/SKILL.md\n\nAdd reference at the top of the file:\n\n\\`\\`\\`markdown\n---\nname: skills-auto-activation\ndescription: Automatically activated via hooks/user-prompt-submit/10-skill-activator.js\n---\n\n\u003e **Note:** This skill's functionality is now implemented via the hooks system.\n\u003e The UserPromptSubmit hook automatically suggests relevant skills based on your prompts.\n\u003e See HOOKS.md for configuration details.\n\\`\\`\\`\n\n### Step 4: Test documentation examples\n\nRun each code example from the documentation:\n\n\\`\\`\\`bash\n# Test skill activator example\necho '{\"text\": \"I want to write a test for the login function\"}' | \\\\\n  node hooks/user-prompt-submit/10-skill-activator.js | \\\\\n  jq .additionalContext\n\n# Test context tracker example  \necho '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' | \\\\\n  bash hooks/post-tool-use/01-track-edits.sh\n\n# Test reminder example\necho '{\"text\": \"All done!\"}' | bash hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\nExpected: All examples work as documented\n\n### Step 5: Commit documentation\n\nRun:\n\\`\\`\\`bash\ngit add README.md HOOKS.md skills/skills-auto-activation/SKILL.md\ngit commit -m \"docs(bd-7): add comprehensive hooks documentation\n\nImplements bd-7: Update Documentation\n- Added Hooks System section to README.md\n- Created detailed HOOKS.md with examples\n- Added troubleshooting guide\n- Updated skill references\n- All examples tested and working\"\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Documentation Accuracy**:\n- All code examples MUST be tested\n- File paths must match actual implementation\n- Version requirements (Node.js) must be stated\n\n**User Experience**:\n- Start with benefits, not technical details\n- Provide clear examples before configuration\n- Troubleshooting should cover common issues\n\n**Maintenance**:\n- Documentation must be updated when hooks change\n- Include version/compatibility notes\n- Link to relevant skills and resources\n\n## Anti-patterns\n- ‚ùå Outdated code examples\n- ‚ùå Missing prerequisites (Node.js)\n- ‚ùå Complex explanations before simple examples\n- ‚ùå Documentation that contradicts implementation","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.320096-04:00","updated_at":"2025-10-30T15:41:24.506886-04:00","closed_at":"2025-10-30T15:41:24.506886-04:00","dependencies":[{"issue_id":"bd-7","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.532603-04:00","created_by":"ryan"},{"issue_id":"bd-7","depends_on_id":"bd-6","type":"blocks","created_at":"2025-10-30T13:57:16.864384-04:00","created_by":"ryan"}]}
{"id":"bd-7be","title":"Epic: Outer-Loop Architecture Skills (Decomposition + Audit)","design":"## Requirements (IMMUTABLE)\n\n1. Two new skills: volatility-decomposition (Socratic, generative) and architectural-audit (analytical, diagnostic)\n2. Decomposition skill uses L√∂wy's volatility-based decomposition: identifies independent axes of change, encapsulates each behind stable interfaces, assigns L√∂wy layers (Manager/Engine/Resource Accessor/Utility)\n3. Decomposition skill presents 2-3 alternative decompositions with tradeoffs ‚Äî NEVER a single recommendation\n4. Audit skill uses Hickey's simplicity principles: finds complection, hidden coupling, temporal coupling, layer violations, state/identity conflation\n5. Audit skill surfaces tensions WITHOUT resolving them ‚Äî presents both pulls, states assumptions that make each option correct, NO recommendations\n6. Both skills encode the architecture graph in bd: architecture epic + component nodes (type: feature, labels: arch,component), using state dimensions for stability tracking, graph links for relationships\n7. The graph is a TEMPORARY work plan (Path B) ‚Äî created, consumed by inner loop, closed when done. NOT a permanent living model\n8. Architectural decisions captured as ADRs in repo (doc/arch/adr-NNN.md) ‚Äî permanent intent that outlives the graph\n9. Both skills dispatch codebase-investigator when a codebase exists; work in pure design mode when no codebase exists (greenfield)\n10. Brainstorming skill updated to auto-detect architecture nodes and load their context (volatility axis, interface contract, relevant ADRs, adjacent nodes)\n11. Scale-agnostic: skills work at any abstraction level (modules, services, layers). Vocabulary adapts to context\n12. Fractal decomposition: oversized components get sub-decomposed by running /decompose on the component itself\n13. Skills think in components and boundaries, NOT classes and functions ‚Äî if they descend to implementation details they've crossed into inner-loop territory\n\n## Success Criteria (MUST ALL BE TRUE)\n\n- [ ] volatility-decomposition skill exists at skills/volatility-decomposition/SKILL.md with full skill structure (frontmatter, overview, process, examples, critical rules, verification checklist, integration)\n- [ ] architectural-audit skill exists at skills/architectural-audit/SKILL.md with full skill structure\n- [ ] Commands exist: commands/decompose.md, commands/audit-arch.md\n- [ ] Decomposition skill produces graph encoded in bd (epic + component nodes with labels, state dimensions, dependencies)\n- [ ] Decomposition skill creates ADRs for key decomposition decisions in doc/arch/ format\n- [ ] Audit skill produces structured tension report with the exact format: tension name, components, both pulls (gain/cost), conditional assumptions\n- [ ] Audit skill reads existing ADRs to skip already-accepted tensions\n- [ ] Audit skill detects drift between ADRs and codebase\n- [ ] Audit skill self-check step reviews output for accidental recommendations before presenting\n- [ ] Brainstorming skill updated to detect arch node references and auto-load context\n- [ ] ADR template follows Nygard format: Title, Status, Context, Decision, Consequences\n- [ ] Both skills dispatch codebase-investigator when codebase exists\n- [ ] Decomposition skill applies L√∂wy's framework: volatility axes, independence test, layer assignment, layer rules\n- [ ] Audit skill applies Hickey's framework: complection scan, interface analysis, temporal coupling, hidden dependencies, layer violations, state/identity conflation\n- [ ] All skill files follow existing hyperpowers skill structure pattern\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n\n- ‚ùå NO single recommendations in decomposition (requirement 3: always 2-3 alternatives with tradeoffs)\n- ‚ùå NO resolving tensions in audit output (requirement 5: surface tensions, present both pulls, NO 'however I think...')\n- ‚ùå NO severity rankings in audit output (implies recommendation ‚Äî use structural observations like 'affects N nodes' instead)\n- ‚ùå NO implementation-level detail in either skill (requirement 13: components and boundaries only, not classes and functions)\n- ‚ùå NO treating the graph as a permanent living model (requirement 7: graph is temporary work plan, ADRs are permanent intent)\n- ‚ùå NO maintaining accepted tradeoffs in bd notes (requirement 8: accepted decisions go in ADRs in the repo)\n- ‚ùå NO skipping codebase investigation when codebase exists (requirement 9: always dispatch codebase-investigator)\n- ‚ùå NO prescribing cycle orchestration (the architect drives the decompose‚Üîaudit cycle with judgment, not a third orchestration skill)\n- ‚ùå NO creating full task trees upfront (first task only, iterative task creation as learning happens)\n\n## Approach\n\nTwo new skills forming a slow outer loop above the existing brainstorm‚Üíplan‚Üíexecute inner loop. The decomposition skill (Socratic) helps the architect articulate volatility axes and propose component boundaries using L√∂wy's method. The audit skill (analytical) examines the resulting graph (and codebase if available) for complection using Hickey's simplicity framework.\n\nThe graph is encoded in bd as a temporary work plan: architecture epic + component feature nodes with labels, state dimensions (stability tracking), and graph links (blocks, relates_to). When nodes are stable (all tensions resolved or accepted), they're eligible for inner-loop handoff via /brainstorm.\n\nArchitectural decisions from decomposition choices and tension resolutions are captured as ADRs in the repo (doc/arch/adr-NNN.md), providing permanent intent that survives the graph's lifecycle.\n\nThe brainstorming skill is updated to auto-detect when the architect references an architecture node, loading its design context (volatility axis, interface contract, relevant ADRs, adjacent nodes) to give the inner loop a head start.\n\n## Architecture\n\n### Deliverables\n- skills/volatility-decomposition/SKILL.md ‚Äî decomposition skill\n- skills/architectural-audit/SKILL.md ‚Äî audit skill\n- commands/decompose.md ‚Äî slash command\n- commands/audit-arch.md ‚Äî slash command\n- skills/brainstorming/SKILL.md ‚Äî updated with arch node detection\n- skills/common-patterns/adr-template.md ‚Äî ADR format reference\n\n### Skill Integration Map\n```\nOUTER LOOP (occasional):\n  /decompose ‚Üê‚Üí /audit-arch ‚Üê‚Üí architect resolves\n       ‚Üì                              ‚Üì\n  graph (bd, temporary)         ADRs (repo, permanent)\n\nHANDOFF (stable node):\n  stable node ‚Üí /brainstorm (auto-loads arch context + ADRs)\n\nINNER LOOP (daily, unchanged):\n  brainstorming ‚Üí sre-refinement ‚Üí writing-plans ‚Üí executing-plans ‚Üí review\n```\n\n### bd Encoding\n- Architecture epic: type epic, labels: arch\n- Component nodes: type feature, labels: arch,component, parent: arch epic\n- State dimensions: stability (exploring|audited|accepted|stable)\n- Edges: blocks (interface dependencies), relates_to (non-blocking interactions)\n- Version evolution: supersedes link for major restructuring\n\n### Agent Usage\n- Both skills: codebase-investigator (when codebase exists)\n- Decomposition: internet-researcher (when evaluating technology options)\n- Audit: NO internet research (focuses on graph + codebase evidence)\n\n## Design Rationale\n\n### Problem\nThe architectural design phase before the inner loop is ad hoc. The user runs informal prompts ('do an architecture review through the lens of Rich Hickey') and gets valuable results, but can't systematize it because it's actually two distinct cognitive activities complected together: generative decomposition (structural, divergent) and evaluative auditing (diagnostic, convergent). Separating them enables each to be done properly.\n\n### Research Findings\n\n**Codebase (hyperpowers plugin):**\n- Skills follow consistent structure: frontmatter, overview, rigidity level, process, examples, critical rules, verification checklist, integration\n- Skills chain via bd artifacts ‚Äî epics as contracts, tasks as adaptive execution units\n- Brainstorming skill already dispatches codebase-investigator and internet-researcher\n- Existing skill integration: brainstorming ‚Üí sre-refinement ‚Üí writing-plans ‚Üí executing-plans\n- Agent types: codebase-investigator, internet-researcher, executor, reviewer, test-runner\n\n**bd/beads capabilities:**\n- Issue types: epic, task, bug, feature\n- Labels system: multi-dimensional tagging, AND/OR filtering (--label, --label-any)\n- State dimensions: bd set-state \u003cid\u003e \u003cdimension\u003e=\u003cvalue\u003e --reason '...' ‚Äî arbitrary per-issue state\n- Graph links: blocks, parent-child, relates_to (bidirectional), supersedes (version chains), duplicates, replies_to\n- Molecules: epic + children with workflow semantics (DAGs with execution ordering). Bonding connects separate graphs\n- Hierarchical IDs: bd-a3f8 ‚Üí bd-a3f8.1 ‚Üí bd-a3f8.1.1\n- Rich fields: design, notes, acceptance, description, spec-id, external-ref\n- Query: --label, --label-any, --title-contains, --desc-contains, --notes-contains, date ranges, priority ranges\n\n**L√∂wy's volatility-based decomposition (Righting Software):**\n- Identify independent axes of change, encapsulate each behind stable interface\n- Two axes: same customer over time, different customers simultaneously ‚Äî must be independent\n- Layer hierarchy: Manager (orchestration) ‚Üí Engine (business logic) ‚Üí Resource Accessor (data) ‚Üí Utility (cross-cutting)\n- Strict top-to-bottom flow: no upward dependencies\n- Key distinction: volatility (architectural) vs variability (code-level) ‚Äî only volatility drives decomposition\n- Common failure: confusing volatility with variability (over-engineering), non-independent axes (still functional decomposition)\n\n**Hickey's simplicity principles (Simple Made Easy, Are We There Yet?):**\n- Simple (objective: not braided together) ‚â† Easy (subjective: familiar/nearby)\n- Complecting: interleaving concerns that should be independent\n- Objects complect state+identity+value. Mutable state complects value+time\n- Systematic separation: What/Who/When/Where/Why/How as independent concerns\n- Types/tests insufficient: 'every bug passed the type checker.' Only simplicity enables reasoning\n- Hammock-driven development: think deeply before coding. Background mind solves non-trivial problems\n\n**ADRs (Michael Nygard, Cognitect ecosystem):**\n- Format: Title, Status (proposed/accepted/deprecated/superseded), Context, Decision ('We will...'), Consequences\n- Stored in repo: doc/arch/adr-NNN.md. Sequential numbering, never reuse numbers\n- Consequences of one ADR become context for subsequent ADRs\n- Captures 'architecturally significant' decisions affecting structure, dependencies, interfaces\n- Superseded ADRs remain for historical context\n\n### Approaches Considered\n\n#### 1. Path B: Graph as temporary work plan + ADRs ‚úì\n\n**What it is:** The architecture graph lives in bd as a temporary work plan ‚Äî created during decomposition, consumed by the inner loop, closed when done. Architectural decisions (decomposition choices, tension resolutions, tension acceptances) captured as ADRs in the repo for permanent intent.\n\n**Investigation:**\n- Analyzed how user actually works: ad hoc architecture sessions, then inner-loop execution\n- Researched bd capabilities: labels, state dimensions, graph links provide rich encoding\n- Researched ADR format: lightweight, permanent, version-controlled, well-understood\n\n**Pros:**\n- Zero maintenance burden: no model to keep in sync with reality\n- Zero drift risk: codebase is always source of truth\n- ADRs provide permanent intent without permanent model\n- Audit can detect drift: compare ADRs (declared intent) with codebase (reality)\n- Cross-cutting features don't need the graph ‚Äî just use normal inner loop\n\n**Cons:**\n- Architecture rationale distributed across ADRs rather than in one place\n- When re-decomposing later, must reconstruct context from ADRs + codebase\n\n**Chosen because:** Matches user's actual workflow. Eliminates the map-vs-territory problem entirely. ADRs preserve decisions without maintaining a model.\n\n#### 2. Path A: Graph as living model ‚ùå\n\n**What it is:** The architecture graph persists permanently in bd. Architecture nodes stay open even after implementation. Cross-cutting features reference the graph for constraints. Periodic reconciliation keeps graph aligned with codebase.\n\n**Why we looked at this:** Natural first instinct ‚Äî if you have an architecture model, keep it current.\n\n**Investigation:**\n- Analyzed maintenance burden: graph must be updated as system evolves\n- Identified drift risk: model inevitably diverges from codebase over time\n- Considered cross-cutting features: graph doesn't naturally accommodate them\n\n**Pros:**\n- Architecture visible as a whole at any time\n- Cross-cutting features get constraint guidance from graph\n\n**Cons:**\n- Maintenance burden: another artifact to keep in sync\n- Drift risk: model vs reality divergence\n- Cross-cutting features don't fit neatly into graph nodes\n\n**‚ö†Ô∏è REJECTED BECAUSE:** User's actual workflow is Path B ‚Äî graph is created for structural work, consumed, then done. Maintaining a permanent model adds overhead without proportionate value. ADRs capture intent more efficiently.\n\n**üö´ DO NOT REVISIT UNLESS:** The team grows large enough that a living architecture model becomes essential for coordination (5+ concurrent developers).\n\n#### 3. Cycle orchestrator (third skill) ‚ùå\n\n**What it is:** A thin orchestration skill that manages the decompose‚Üíaudit‚Üíresolve cycle, prompting the architect through each phase.\n\n**Why we looked at this:** The cycle could benefit from guided sequencing.\n\n**Investigation:**\n- The cycle is inherently non-linear ‚Äî architect might audit without decomposing, or decompose without auditing first\n- Adding ceremony reduces the judgment-driven nature of the outer loop\n\n**‚ö†Ô∏è REJECTED BECAUSE:** Over-engineering. The architect's judgment drives the cycle, not a process. Two skills is sufficient.\n\n**üö´ DO NOT REVISIT UNLESS:** Users consistently forget to audit after decomposing.\n\n#### 4. Single skill with modes ‚ùå\n\n**What it is:** One 'architecture' skill with decompose and audit modes that Claude switches between.\n\n**Why we looked at this:** Avoids loading two separate skills for a tightly coupled cycle.\n\n**‚ö†Ô∏è REJECTED BECAUSE:** User explicitly identified decomposition (generative) and audit (evaluative) as distinct cognitive activities that get complected when mixed. Separate skills enforce the separation.\n\n**üö´ DO NOT REVISIT UNLESS:** The skills prove so tightly coupled in practice that the separation creates friction.\n\n### Scope Boundaries\n\n**In scope:**\n- Volatility-decomposition skill (SKILL.md + command)\n- Architectural-audit skill (SKILL.md + command)\n- Brainstorming skill update (arch node auto-detection)\n- ADR template in common-patterns\n- using-hyper trigger guidance for architecture-related requests\n\n**Out of scope (deferred):**\n- Automatic ADR generation (skills guide the architect, architect writes the ADR content)\n- Molecule integration (architecture graph uses plain epic+children, not molecules)\n- Visualization tooling (bd dep tree is sufficient for now)\n- Multi-repo architecture graphs (single repo only)\n\n### Open Questions\n- Should the decomposition skill offer to draft ADR content, or only prompt the architect to create them? (Decide during implementation ‚Äî start with prompting, can add drafting later)\n- How should the brainstorming skill detect an arch node reference? By bd ID mention? By label query? By asking? (Decide during implementation)\n- Should accepted tradeoffs in ADRs flow automatically into inner-loop epic anti-patterns, or should the architect curate? (Decide during implementation ‚Äî start with manual curation)\n\n## Design Discovery (Reference Context)\n\n\u003e Detailed context from brainstorming for task creation and obstacle handling.\n\n### Key Decisions Made\n\n| Question | User Answer | Implication |\n|----------|-------------|-------------|\n| Graph persistence | Encode in bd | Use labels, state dims, graph links for rich encoding |\n| Interaction mode | Decomposition Socratic, Audit analytical | Different skill structures and processes |\n| Abstraction level | Scale-agnostic | Skills adapt vocabulary to context |\n| Handoff gate | All tensions resolved or accepted | Formal gate: audit must pass clean |\n| Resolution flow | Architect modifies graph directly | Tensions ephemeral, ADRs permanent |\n| BD encoding | Issue-per-node fits well | Architecture epic + component feature nodes |\n| Codebase access | Yes, when codebase exists | Both skills dispatch codebase-investigator |\n| Brainstorm integration | Auto-detect and pull context | Brainstorming skill update required |\n| Graph lifecycle | Path B (temporary work plan) | Graph created ‚Üí consumed ‚Üí closed |\n| Component sizing | Fractal decomposition | Big components sub-decomposed recursively |\n| Architecture intent | ADRs in repo (Nygard format) | Permanent decisions at doc/arch/adr-NNN.md |\n| Cross-cutting features | Normal inner loop | No graph needed for UX enhancements etc |\n\n### Research Deep-Dives\n\n#### bd Capabilities\n**Question explored:** What can bd actually represent for architecture graphs?\n**Sources consulted:**\n- github.com/steveyegge/beads README, CLI_REFERENCE.md, LABELS.md, MOLECULES.md, graph-links.md\n**Key findings:**\n- Labels: multi-dimensional tagging with AND/OR filtering\n- State dimensions: arbitrary per-issue state tracking with reasons\n- Graph links: blocks, parent-child, relates_to, supersedes, duplicates, replies_to\n- Molecules: execution-level DAGs (not right fit for design-level architecture)\n- Hierarchical IDs: native hierarchy support\n**Conclusion:** bd's primitives are rich enough for architecture graph encoding without custom extensions\n\n#### L√∂wy's Method\n**Question explored:** How does volatility-based decomposition work in practice?\n**Sources consulted:**\n- Righting Software references, SE Radio 407 interview, InformIT articles, InfoQ Q\u0026A\n**Key findings:**\n- Two independent axes: same customer over time, different customers simultaneously\n- Manager/Engine/Resource Accessor/Utility layering with strict top-to-bottom flow\n- Key failure mode: confusing volatility with variability\n- Volatility drives architecture AND roadmap simultaneously\n**Conclusion:** Framework provides concrete heuristics for Socratic questioning in decomposition skill\n\n#### Hickey's Framework\n**Question explored:** What specific heuristics detect complection?\n**Sources consulted:**\n- Simple Made Easy transcript, Are We There Yet? transcript, Hammock-Driven Development\n**Key findings:**\n- Six systematic analysis passes: complection scan, interface analysis, temporal coupling, hidden dependencies, layer violations, state/identity conflation\n- Simple ‚â† Easy distinction is the core diagnostic lens\n- Hammock-driven: think before coding (background mind solves hard problems)\n**Conclusion:** Framework provides concrete analysis categories for audit skill\n\n#### ADRs\n**Question explored:** How to preserve architecture intent without maintaining a living model?\n**Sources consulted:**\n- Cognitect blog (Nygard 2011), various ADR implementations\n**Key findings:**\n- Lightweight: 1-2 pages, stored in repo, version-controlled\n- Format: Title, Status, Context, Decision, Consequences\n- Consequences of one ADR become context for next\n- Superseded ADRs remain for historical context\n**Conclusion:** ADRs solve the intent preservation problem for Path B (temporary graphs)\n\n### Dead-End Paths\n\n#### Graph as living model (Path A)\n**Why explored:** Natural first instinct ‚Äî maintain architecture model permanently\n**Investigation:** Analyzed maintenance burden, drift risk, cross-cutting feature awkwardness\n**Why abandoned:** User's actual workflow is temporary graphs. Permanent model adds overhead without proportionate value.\n\n#### Cycle orchestrator skill\n**Why explored:** Could guide the decompose‚Üíaudit‚Üíresolve sequence\n**Investigation:** Cycle is non-linear, judgment-driven. Orchestrator adds ceremony without value.\n**Why abandoned:** Over-engineering. Two skills + architect judgment is sufficient.\n\n#### Molecules for architecture graph\n**Why explored:** bd's molecule feature provides DAG semantics\n**Investigation:** Molecules are execution-level (workflow ordering, parallel detection). Architecture graph is design-level.\n**Why abandoned:** Semantic mismatch. Plain epic+children with labels/state/links is better fit.\n\n### Open Concerns Raised\n\n- 'Cross-cutting features don't fit single nodes' ‚Üí Resolved: Path B ‚Äî graph is temporary work plan. Cross-cutting features use normal inner loop. Graph provides constraint context when it exists, codebase-investigator discovers structure when it doesn't.\n- 'Component too big for single epic' ‚Üí Resolved: Fractal decomposition ‚Äî run /decompose on the component itself. Sub-components via hierarchical IDs.\n- 'Graph becomes model vs looking at system' ‚Üí Resolved: Path B + ADRs. Graph is ephemeral tool. ADRs capture decisions. Codebase is truth.\n- 'Audit skill will accidentally recommend' ‚Üí Addressed: Rigid tension format with no recommendation field, anti-patterns, self-check step. Key engineering challenge during implementation.\n- 'How do accepted tradeoffs persist?' ‚Üí Resolved: ADRs in repo, not bd notes. Audit reads ADRs to skip accepted tensions.","status":"closed","priority":2,"issue_type":"epic","owner":"abugosh@gmail.com","created_at":"2026-02-14T22:54:03.636347-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T07:07:12.85604-05:00","closed_at":"2026-02-15T07:07:12.85604-05:00","close_reason":"All deliverables complete. Reviewer approved. 3 tasks across 3 commits: volatility-decomposition skill, architectural-audit skill, brainstorming update, ADR template, commands.","labels":["arch","skills"]}
{"id":"bd-7yn","title":"Task 1: Add Parallelism Map section to brainstorming skill","design":"## Goal\nModify the brainstorming skill to include a Parallelism Map section in the epic template. This is the entry point for the entire team workflow - without the Parallelism Map, wave-planning and team-executing can't identify what to parallelize.\n\n## Context\nThe brainstorming skill (skills/brainstorming/SKILL.md) creates bd epics with immutable requirements, success criteria, anti-patterns, approach, architecture, and design discovery sections. We need to add a Parallelism Map section that identifies independent work streams, file ownership boundaries, and suggested wave composition.\n\n## Effort Estimate\n2-4 hours (single file modification, 4-5 discrete insertion points)\n\n## Implementation\n\n### Step 1: Read the current brainstorming skill\n- File: skills/brainstorming/SKILL.md\n- Focus on Section 4 (Creating the bd Epic) ‚Äî the epic template starting at line 181\n- Identify exact insertion points for all changes below\n\n### Step 2: Add Parallelism Map section to the epic template\n**Insertion point:** Inside the `bd create` command block in Section 4, after the `## Architecture` section (around line 209) and before the `## Design Rationale` section (around line 211).\n\nAdd the following verbatim inside the bd create template:\n\n```markdown\n## Parallelism Map\n\n### Independent Work Streams\n1. **[Stream Name]** ([file/module scope])\n   - [What this stream delivers]\n   - Estimated complexity: [low/medium/high]\n2. **[Stream Name]** ([file/module scope])\n   - [What this stream delivers]\n   - Estimated complexity: [low/medium/high]\n\n### Stream Dependencies\n- Stream N depends on Stream M (reason: [why])\n- Streams X and Y are fully independent\n\n### Suggested Waves\n- Wave 1: [Streams that can parallelize] (independent, no shared files)\n- Wave 2: [Streams that depend on Wave 1]\n- Wave 3: [Streams that depend on Wave 2]\n\n### File Ownership Boundaries\n| Stream | Owns (exclusive) | Shared (needs coordination) |\n|--------|-------------------|-----------------------------|\n| [Name] | [paths]           | [paths + which other stream] |\n\n### Parallelism Assessment\n- Independent streams: [N]\n- Recommendation: [team execution / solo execution]\n- Rationale: [why ‚Äî e.g., \"5 independent streams with no shared files\" or \"only 2 streams, coordination overhead not worthwhile\"]\n```\n\n**Important:** Use \"Estimated complexity\" (low/medium/high) instead of hour estimates ‚Äî brainstorming happens before detailed planning, so hour estimates would be premature and inaccurate.\n\n**Important:** Include \"Shared (needs coordination)\" column in File Ownership ‚Äî some streams will share files. Rather than pretending all files can be cleanly owned, acknowledge shared files and note which streams need to coordinate. Shared files become blocking dependencies or separate coordination tasks during wave-planning.\n\n### Step 3: Add parallelism analysis guidance to Section 2 (Exploring Approaches)\n**Insertion point:** After the existing \"CAPTURE for Design Discovery\" block at lines 122-132, add a new subsection.\n\nAdd the following text:\n\n```markdown\n**CAPTURE for Parallelism Map:**\nDuring codebase research, also identify:\n- Module boundaries: Which directories/files form independent units?\n- Shared state: What files, databases, or APIs are touched by multiple features?\n- Natural work streams: Could different developers work on different parts without stepping on each other?\n- These observations inform the Parallelism Map section in the epic.\n```\n\nThis is a lightweight addition ‚Äî just 4 bullet points to prime the researcher to notice parallelism opportunities.\n\n### Step 4: Add team vs. solo decision point to Section 6 (Handoff)\n**Insertion point:** In Section 6 (SRE Refinement and Handoff, starting at line 382), after the \"After refinement approved, present handoff:\" block (around line 400), add a decision point BEFORE the existing handoff announcement.\n\nAdd the following:\n\n```markdown\n**REQUIRED: Team vs. Solo Decision**\n\nReview the epic's Parallelism Map and present a routing decision:\n\nIf 3+ independent streams with no shared files:\n‚Üí Recommend team execution path (wave-planning ‚Üí team-executing-plans)\n\nIf \u003c3 independent streams OR significant shared files:\n‚Üí Recommend solo execution path (writing-plans ‚Üí executing-plans)\n\nUse AskUserQuestion:\n```\nAskUserQuestion:\n  question: \"Based on the Parallelism Map, this epic has [N] independent streams. Which execution path should we use?\"\n  header: \"Execution\"\n  options:\n    - label: \"[Team/Solo] execution (Recommended)\"\n      description: \"[Reason based on stream count and file ownership analysis]\"\n    - label: \"[Solo/Team] execution\"\n      description: \"[Tradeoff ‚Äî e.g., 'Lower parallelism but simpler coordination' or 'More parallel but higher token cost']\"\n```\n\nThen adjust the handoff text to reflect the chosen path.\n```\n\n**Edge case:** If the Parallelism Map shows exactly 0 independent streams (everything is sequential), skip the decision point entirely and default to solo execution. Don't ask the user an obvious question.\n\n### Step 5: Update the verification checklist\n**Insertion point:** In the verification_checklist section (starting at line 836), add after the existing checklist items (before the \"Can't check all boxes?\" line):\n\nAdd these items:\n```markdown\n- [ ] Parallelism Map section present with: streams, dependencies, waves, file ownership, assessment\n- [ ] Parallelism Map assessment recommends team or solo path with rationale\n- [ ] Team vs. solo decision point presented to user (if 3+ streams)\n```\n\n### Step 6: Add a realistic example\n**Insertion point:** In the existing example section (examples block starting at line 419). Add a new example after the existing examples that demonstrates a Parallelism Map in context.\n\nThe example should:\n- Use the OAuth authentication scenario already in the skill (for consistency)\n- Show a Parallelism Map with 3 streams (enough for team recommendation)\n- Include one shared file to demonstrate the \"Shared (needs coordination)\" column\n- Show the team vs. solo AskUserQuestion flow\n- Be concise (not a full epic, just the Parallelism Map portion)\n\n## Success Criteria\n- [ ] Brainstorming skill epic template includes Parallelism Map section inside the bd create command block\n- [ ] Parallelism Map has all subsections: independent streams, stream dependencies, suggested waves, file ownership boundaries, parallelism assessment\n- [ ] File Ownership table includes \"Shared (needs coordination)\" column for shared files\n- [ ] Uses \"Estimated complexity\" (low/medium/high) not hour estimates for streams\n- [ ] Section 2 guidance added (4 bullet points after \"CAPTURE for Design Discovery\" block)\n- [ ] Section 6 handoff includes team vs. solo decision point with AskUserQuestion\n- [ ] Decision point skips AskUserQuestion when 0 independent streams (obvious solo path)\n- [ ] Verification checklist includes 3 new Parallelism Map items\n- [ ] Example demonstrates realistic Parallelism Map with shared file scenario\n- [ ] No changes to existing epic sections (requirements, success criteria, anti-patterns, approach, design rationale)\n- [ ] Existing brainstorming skill still works for single-stream projects (Parallelism Map section shows 1 stream, assessment says \"solo execution\", no team decision presented)\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO making Parallelism Map mandatory for solo-only projects (assessment should say \"solo execution\" when \u003c3 streams, not force team workflow)\n- ‚ùå NO modifying existing epic template sections (requirements, success criteria, anti-patterns, approach, architecture, design rationale) ‚Äî Parallelism Map is ADDITIVE\n- ‚ùå NO breaking the bd create command block structure (Parallelism Map goes inside the existing template, not as a separate command)\n- ‚ùå NO hour-based effort estimates in streams (brainstorming is too early for hour estimates; use complexity: low/medium/high)\n- ‚ùå NO pretending all files can be cleanly owned (shared files exist; acknowledge them in the table)\n- ‚ùå NO asking team vs solo when answer is obvious (\u003c3 streams = solo, don't waste user's time)\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n### Edge Case: Single-Stream Projects\nWhen brainstorming produces an epic with only 1 work stream (e.g., \"fix a single bug\" or \"refactor one module\"), the Parallelism Map should still be present but trivially filled: 1 stream, 0 dependencies, 1 wave, assessment says \"solo execution recommended.\" Do NOT skip the section ‚Äî its presence signals the analysis was done.\n\n### Edge Case: Shared Files Between Streams\nSome streams will share files (e.g., two features both modify routes/index.ts). The File Ownership table MUST have a \"Shared (needs coordination)\" column. During wave-planning, shared files become either: (a) a separate coordination task that blocks both streams, or (b) a reason to sequence streams into different waves. The brainstorming skill doesn't need to solve this ‚Äî just surface the information.\n\n### Edge Case: Architecture Section Overlap\nThe Architecture section already lists components. The Parallelism Map adds work stream groupings. These might seem redundant. They serve different purposes: Architecture = what the system looks like, Parallelism Map = how work can be divided. Architecture might list \"auth/, routes/, db/\" while Parallelism Map groups them as \"Stream 1: auth + routes, Stream 2: db migrations.\" Clarify this distinction in the skill if needed.\n\n### Edge Case: Epic Size and Context Compaction\nAdding the Parallelism Map makes epics larger. Keep the template concise ‚Äî each stream should be 2-3 lines max. The assessment subsection is 2-3 lines. Total Parallelism Map overhead: ~20-30 lines. This is acceptable.\n\n### Edge Case: Handoff Decision Timing\nThe team vs. solo decision happens in Section 6, AFTER the epic is created and AFTER SRE refinement. This is correct ‚Äî the decision uses the Parallelism Map that's already in the epic. The decision doesn't change the epic; it routes to either writing-plans (solo) or wave-planning (team).","status":"closed","priority":1,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-02-06T11:40:06.107666-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-06T12:56:18.540388-05:00","closed_at":"2026-02-06T12:56:18.540388-05:00","close_reason":"All 11 success criteria verified. Parallelism Map section added to epic template (streams, dependencies, waves, file ownership, assessment). Section 2 guidance added. Section 6 team vs solo decision point with AskUserQuestion. Verification checklist updated. Realistic example with shared file scenario. Integration section updated with team path.","dependencies":[{"issue_id":"bd-7yn","depends_on_id":"bd-6t7","type":"parent-child","created_at":"2026-02-06T11:40:11.550958-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-8","title":"Phase 7: Integration Testing","design":"## Goal\nTest complete hook system integration.\n\n## Effort Estimate  \n4-6 hours\n\n## Success Criteria\n- [ ] End-to-end test script created\n- [ ] All 3 hooks tested in sequence\n- [ ] 10+ test scenarios pass\n- [ ] Performance benchmarks documented\n- [ ] Error scenarios handled correctly\n- [ ] No interference between hooks\n- [ ] Clean test environment setup/teardown\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step 1: Create integration test script\n\nCreate \\`hooks/test/integration-test.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Colors for output\nRED='\\\\033[0;31m'\nGREEN='\\\\033[0;32m'\nYELLOW='\\\\033[1;33m'\nNC='\\\\033[0m' # No Color\n\n# Test environment setup\nTEST_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\"\nHOOKS_DIR=\"$(dirname \"$TEST_DIR\")\"\nCONTEXT_DIR=\"$HOOKS_DIR/context\"\nORIG_LOG=\"\"\n\n# Test counters\nTESTS_RUN=0\nTESTS_PASSED=0\nTESTS_FAILED=0\n\n# Utility functions\nsetup_test() {\n    echo -e \"${YELLOW}Setting up test environment...${NC}\"\n    # Backup existing log\n    if [ -f \"$CONTEXT_DIR/edit-log.txt\" ]; then\n        ORIG_LOG=$(cat \"$CONTEXT_DIR/edit-log.txt\")\n    fi\n    \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    export DEBUG_HOOKS=false\n}\n\nteardown_test() {\n    echo -e \"${YELLOW}Cleaning up test environment...${NC}\"\n    # Restore original log\n    if [ -n \"$ORIG_LOG\" ]; then\n        echo \"$ORIG_LOG\" \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    else\n        \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    fi\n}\n\nrun_test() {\n    local test_name=\"$1\"\n    local test_cmd=\"$2\"\n    local expected=\"$3\"\n    \n    TESTS_RUN=$((TESTS_RUN + 1))\n    echo -n \"Test $TESTS_RUN: $test_name... \"\n    \n    if eval \"$test_cmd\" 2\u003e/dev/null | grep -q \"$expected\" 2\u003e/dev/null; then\n        echo -e \"${GREEN}PASS${NC}\"\n        TESTS_PASSED=$((TESTS_PASSED + 1))\n    else\n        echo -e \"${RED}FAIL${NC}\"\n        echo \"  Expected: $expected\"\n        echo \"  Command: $test_cmd\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n}\n\n# Performance test utility\nmeasure_performance() {\n    local hook_name=\"$1\"\n    local test_input=\"$2\"\n    local hook_script=\"$3\"\n    \n    local start=$(date +%s%N)\n    echo \"$test_input\" | $hook_script \u003e /dev/null 2\u003e\u00261\n    local end=$(date +%s%N)\n    \n    local duration_ms=$(((end - start) / 1000000))\n    echo \"$duration_ms\"\n}\n\n# Main test execution\nmain() {\n    echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\n    echo \"üß™ HOOKS INTEGRATION TEST SUITE\"\n    echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\n    echo \"\"\n    \n    setup_test\n    \n    # Test 1: UserPromptSubmit - Skill activation\n    echo -e \"\\\\n${YELLOW}Testing UserPromptSubmit Hook...${NC}\"\n    \n    run_test \"TDD prompt activates skill\" \\\\\n        \"echo '{\\\"text\\\": \\\"I want to write a test for login\\\"}' | node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\" \\\\\n        \"test-driven-development\"\n    \n    run_test \"Empty prompt returns continue\" \\\\\n        \"echo '{\\\"text\\\": \\\"\\\"}' | node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\" \\\\\n        '{\"decision\":\"continue\"}'\n    \n    run_test \"Malformed JSON handled\" \\\\\n        \"echo 'not json' | node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\" \\\\\n        '{\"decision\":\"continue\"}'\n    \n    # Test 2: PostToolUse - Context tracking\n    echo -e \"\\\\n${YELLOW}Testing PostToolUse Hook...${NC}\"\n    \n    run_test \"Edit tool logs file\" \\\\\n        \"echo '{\\\"tool\\\": {\\\"name\\\": \\\"Edit\\\", \\\"input\\\": {\\\"file_path\\\": \\\"/test/file1.ts\\\"}}}' | bash $HOOKS_DIR/post-tool-use/01-track-edits.sh \u0026\u0026 tail -1 $CONTEXT_DIR/edit-log.txt\" \\\\\n        \"file1.ts\"\n    \n    run_test \"Write tool logs file\" \\\\\n        \"echo '{\\\"tool\\\": {\\\"name\\\": \\\"Write\\\", \\\"input\\\": {\\\"file_path\\\": \\\"/test/file2.py\\\"}}}' | bash $HOOKS_DIR/post-tool-use/01-track-edits.sh \u0026\u0026 tail -1 $CONTEXT_DIR/edit-log.txt\" \\\\\n        \"file2.py\"\n    \n    run_test \"Invalid tool ignored\" \\\\\n        \"echo '{\\\"tool\\\": {\\\"name\\\": \\\"Read\\\", \\\"input\\\": {\\\"file_path\\\": \\\"/test/file3.ts\\\"}}}' | bash $HOOKS_DIR/post-tool-use/01-track-edits.sh\" \\\\\n        '{\"decision\":\"continue\"}'\n    \n    # Test 3: Stop - Gentle reminders\n    echo -e \"\\\\n${YELLOW}Testing Stop Hook...${NC}\"\n    \n    # Add source file edit for TDD reminder\n    echo \"$(date +\"%Y-%m-%d %H:%M:%S\") | test | Edit | /src/main.ts\" \u003e\u003e \"$CONTEXT_DIR/edit-log.txt\"\n    \n    run_test \"TDD reminder shows\" \\\\\n        \"echo '{\\\"text\\\": \\\"Feature implemented\\\"}' | bash $HOOKS_DIR/stop/10-gentle-reminders.sh\" \\\\\n        \"TDD\"\n    \n    run_test \"Completion triggers verify\" \\\\\n        \"echo '{\\\"text\\\": \\\"All done and working!\\\"}' | bash $HOOKS_DIR/stop/10-gentle-reminders.sh\" \\\\\n        \"Run tests\"\n    \n    # Add multiple files for commit reminder\n    for i in {1..5}; do\n        echo \"$(date +\"%Y-%m-%d %H:%M:%S\") | test | Edit | /src/file$i.ts\" \u003e\u003e \"$CONTEXT_DIR/edit-log.txt\"\n    done\n    \n    run_test \"Many edits triggers commit\" \\\\\n        \"echo '{\\\"text\\\": \\\"Refactoring\\\"}' | bash $HOOKS_DIR/stop/10-gentle-reminders.sh\" \\\\\n        \"commit\"\n    \n    # Test 4: End-to-end workflow\n    echo -e \"\\\\n${YELLOW}Testing End-to-End Workflow...${NC}\"\n    \n    # Clear log for clean test\n    \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    \n    # Simulate full workflow\n    echo \"Step 1: User prompt with TDD intent\"\n    result1=$(echo '{\"text\": \"I need to implement authentication with tests\"}' | \\\\\n              node \"$HOOKS_DIR/user-prompt-submit/10-skill-activator.js\")\n    \n    if echo \"$result1\" | grep -q \"test-driven-development\"; then\n        echo -e \"  ${GREEN}‚úì Skill activated${NC}\"\n    else\n        echo -e \"  ${RED}‚úó Skill not activated${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    echo \"Step 2: Edit files (triggers context tracking)\"\n    echo '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/src/auth.ts\"}}}' | \\\\\n        bash \"$HOOKS_DIR/post-tool-use/01-track-edits.sh\" \u003e /dev/null\n    \n    if grep -q \"auth.ts\" \"$CONTEXT_DIR/edit-log.txt\"; then\n        echo -e \"  ${GREEN}‚úì Edit tracked${NC}\"\n    else\n        echo -e \"  ${RED}‚úó Edit not tracked${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    echo \"Step 3: Response triggers reminder\"\n    result3=$(echo '{\"text\": \"Authentication implemented successfully!\"}' | \\\\\n              bash \"$HOOKS_DIR/stop/10-gentle-reminders.sh\")\n    \n    if echo \"$result3\" | grep -q \"TDD\\\\|test\"; then\n        echo -e \"  ${GREEN}‚úì Reminder shown${NC}\"\n    else\n        echo -e \"  ${RED}‚úó No reminder${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    # Test 5: Performance benchmarks\n    echo -e \"\\\\n${YELLOW}Performance Benchmarks...${NC}\"\n    \n    perf1=$(measure_performance \"UserPromptSubmit\" \\\\\n            '{\"text\": \"I want to write tests\"}' \\\\\n            \"node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\")\n    \n    perf2=$(measure_performance \"PostToolUse\" \\\\\n            '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' \\\\\n            \"bash $HOOKS_DIR/post-tool-use/01-track-edits.sh\")\n    \n    perf3=$(measure_performance \"Stop\" \\\\\n            '{\"text\": \"Done\"}' \\\\\n            \"bash $HOOKS_DIR/stop/10-gentle-reminders.sh\")\n    \n    echo \"UserPromptSubmit: ${perf1}ms (target: \u003c100ms)\"\n    echo \"PostToolUse: ${perf2}ms (target: \u003c10ms)\"\n    echo \"Stop: ${perf3}ms (target: \u003c50ms)\"\n    \n    # Check performance targets\n    if [ \"$perf1\" -lt 100 ] \u0026\u0026 [ \"$perf2\" -lt 10 ] \u0026\u0026 [ \"$perf3\" -lt 50 ]; then\n        echo -e \"${GREEN}‚úì All performance targets met${NC}\"\n        TESTS_PASSED=$((TESTS_PASSED + 1))\n    else\n        echo -e \"${RED}‚úó Performance targets not met${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    teardown_test\n    \n    # Summary\n    echo \"\"\n    echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\n    echo \"üìä TEST RESULTS\"\n    echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\n    echo \"Total: $TESTS_RUN\"\n    echo -e \"Passed: ${GREEN}$TESTS_PASSED${NC}\"\n    echo -e \"Failed: ${RED}$TESTS_FAILED${NC}\"\n    \n    if [ \"$TESTS_FAILED\" -eq 0 ]; then\n        echo -e \"\\\\n${GREEN}‚úÖ ALL TESTS PASSED!${NC}\"\n        exit 0\n    else\n        echo -e \"\\\\n${RED}‚ùå SOME TESTS FAILED${NC}\"\n        exit 1\n    fi\n}\n\n# Run tests\nmain\n\\`\\`\\`\n\n### Step 2: Make test executable and run\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/test/integration-test.sh\nbash hooks/test/integration-test.sh\n\\`\\`\\`\n\nExpected output:\n- All tests pass (green checkmarks)\n- Performance within targets\n- No errors or warnings\n\n### Step 3: Create error scenario tests\n\nCreate \\`hooks/test/error-test.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\nset -e\n\necho \"=== Testing Error Scenarios ===\"\n\n# Test 1: Missing skill-rules.json\necho \"Test 1: Missing skill-rules.json\"\nmv hooks/skill-rules.json hooks/skill-rules.json.bak 2\u003e/dev/null || true\nresult=$(echo '{\"text\": \"test\"}' | node hooks/user-prompt-submit/10-skill-activator.js 2\u003e/dev/null)\n[ \"$result\" = '{\"decision\":\"continue\"}' ] \u0026\u0026 echo \"‚úì Handled gracefully\" || echo \"‚úó Failed\"\nmv hooks/skill-rules.json.bak hooks/skill-rules.json 2\u003e/dev/null || true\n\n# Test 2: Corrupted edit-log.txt\necho \"Test 2: Corrupted log file\"\necho \"invalid|data|format\" \u003e hooks/context/edit-log.txt\nbash hooks/stop/10-gentle-reminders.sh \u003c/dev/null \u003e/dev/null 2\u003e\u00261 \u0026\u0026 echo \"‚úì Handled gracefully\" || echo \"‚úó Crashed\"\n\n# Test 3: Permission denied on log\necho \"Test 3: Permission denied\"\nchmod 000 hooks/context/edit-log.txt 2\u003e/dev/null || true\necho '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' | \\\\\n  bash hooks/post-tool-use/01-track-edits.sh \u003e/dev/null 2\u003e\u00261\n[ $? -eq 0 ] \u0026\u0026 echo \"‚úì Continued despite error\" || echo \"‚úó Failed\"\nchmod 644 hooks/context/edit-log.txt 2\u003e/dev/null || true\n\n# Test 4: Concurrent access\necho \"Test 4: Concurrent writes\"\nfor i in {1..10}; do\n    echo '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test'$i'.ts\"}}}' | \\\\\n      bash hooks/post-tool-use/01-track-edits.sh \u0026\ndone\nwait\nlines=$(wc -l \u003c hooks/context/edit-log.txt)\n[ \"$lines\" -ge 8 ] \u0026\u0026 echo \"‚úì Most writes succeeded\" || echo \"‚úó Lost writes\"\n\necho \"=== Error Tests Complete ===\"\n\\`\\`\\`\n\n### Step 4: Run error tests\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/test/error-test.sh\nbash hooks/test/error-test.sh\n\\`\\`\\`\n\nExpected: All error scenarios handled gracefully\n\n### Step 5: Create performance stress test\n\nCreate \\`hooks/test/stress-test.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\necho \"=== Performance Stress Test ===\"\n\n# Test with very long prompt (10KB)\nlong_prompt=$(python3 -c \"print('test ' * 2000)\")\ntime echo \"{\\\"text\\\": \\\"$long_prompt\\\"}\" | node hooks/user-prompt-submit/10-skill-activator.js \u003e /dev/null\n\n# Test with 100 rapid edits\ntime for i in {1..100}; do\n    echo '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test'$i'.ts\"}}}' | \\\\\n      bash hooks/post-tool-use/01-track-edits.sh\ndone\n\necho \"Stress test complete\"\n\\`\\`\\`\n\n### Step 6: Document test results\n\nCreate \\`hooks/test/TEST-RESULTS.md\\`:\n\n\\`\\`\\`markdown\n# Hook System Test Results\n\nDate: [Current Date]\nVersion: 1.0.0\n\n## Integration Tests\n- ‚úÖ 10/10 scenarios pass\n- ‚úÖ End-to-end workflow verified\n- ‚úÖ Performance targets met\n\n## Error Handling\n- ‚úÖ Missing files handled\n- ‚úÖ Corrupted data handled\n- ‚úÖ Permission errors handled\n- ‚úÖ Concurrent access safe\n\n## Performance\n| Hook | Target | Actual | Status |\n|------|--------|--------|--------|\n| UserPromptSubmit | \u003c100ms | XXms | ‚úÖ |\n| PostToolUse | \u003c10ms | XXms | ‚úÖ |\n| Stop | \u003c50ms | XXms | ‚úÖ |\n\n## Stress Test\n- 10KB prompt: XXXms\n- 100 rapid edits: XXXms total\n\\`\\`\\`\n\n### Step 7: Commit tests\n\nRun:\n\\`\\`\\`bash\ngit add hooks/test/*.sh hooks/test/TEST-RESULTS.md\ngit commit -m \"test(bd-8): comprehensive integration tests\n\nImplements bd-8: Integration Testing\n- End-to-end workflow tests\n- Error scenario handling\n- Performance benchmarks\n- Stress testing\n- All tests passing\"\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Test Coverage**:\n- Happy path (normal operation)\n- Error cases (missing files, bad data)\n- Edge cases (empty input, huge input)\n- Concurrent access\n- Performance under load\n\n**Test Isolation**:\n- Save/restore original state\n- Clean environment for each test\n- No side effects between tests\n\n**Realistic Scenarios**:\n- Test actual user workflows\n- Include timing/performance checks\n- Verify hook interaction\n\n**Maintenance**:\n- Tests must be repeatable\n- Clear failure messages\n- Easy to add new test cases\n\n## Anti-patterns\n- ‚ùå Only testing happy path\n- ‚ùå Tests that depend on external state\n- ‚ùå No performance validation\n- ‚ùå Unclear failure messages\n- ‚ùå Tests that can't be run repeatedly","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.330003-04:00","updated_at":"2025-10-30T15:43:58.539522-04:00","closed_at":"2025-10-30T15:43:58.539522-04:00","dependencies":[{"issue_id":"bd-8","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.547958-04:00","created_by":"ryan"},{"issue_id":"bd-8","depends_on_id":"bd-7","type":"blocks","created_at":"2025-10-30T13:57:16.875377-04:00","created_by":"ryan"}]}
{"id":"bd-8o4","title":"Task 1: Add data coupling dispatch to volatility-decomposition Step 0","description":"Add Step 0b to volatility-decomposition skill ‚Äî a second codebase-investigator dispatch that gathers data coupling evidence at module level, using Step 0a structural results to target questions.","design":"## Goal\nAdd a second investigator dispatch (Step 0b) to the volatility-decomposition skill that gathers data coupling evidence across module boundaries discovered in Step 0a.\n\n## Effort Estimate\n2-4 hours\n\n## Implementation\n\n1. Study existing Step 0 in skills/volatility-decomposition/SKILL.md\n   - Lines 57-65: REVISION MODE (loads existing graph)\n   - Lines 67-78: INCEPTION MODE (codebase investigator dispatch)\n   - Line 79: Greenfield case (no codebase ‚Äî pure design mode)\n   - Lines 81-86: ADR check (unchanged)\n   - Step 1 (Socratic questioning) starts at line 90\n   - Step 2 (Structure proposal) starts at line 285\n\n2. Add Step 0b AFTER the codebase detection block (after line 79), BEFORE the ADR check (line 81)\n   - GATING CONDITION: Only dispatch Step 0b when codebase exists (same condition as Step 0a)\n   - In greenfield mode, skip Step 0b entirely ‚Äî no data to analyze\n   - Second dispatch to codebase-investigator, parameterized by Step 0a structural results\n\n3. Step 0b prompt (included in skill as template text Claude parameterizes at runtime):\n\n   INCEPTION MODE prompt:\n   'Based on these structural findings: [include Step 0a results ‚Äî modules, dependencies, boundaries]\n   For each pair of modules that share a dependency edge:\n   1. What data shapes cross this boundary? (types, structures, DTOs at module level)\n   2. Which entry points produce data that flows across this boundary?\n   3. Are there modules that share data shapes despite no direct import? (hidden coupling through intermediaries)\n   Report at module level. For each coupling: source module, destination module, data shape description, triggering entry points.'\n\n   REVISION MODE prompt:\n   'Based on these structural findings: [include Step 0a results]\n   And this existing architecture graph: [include graph nodes and edges from bd]\n   For each boundary in the graph:\n   1. What data shapes cross this boundary? Does actual data coupling match the declared edge?\n   2. Are there data flows between graph nodes with no declared edge? (hidden coupling)\n   3. Which entry points produce data that flows across each boundary?\n   Report at module level. Reference graph node names.'\n\n4. Weave coupling evidence into Step 1 (Socratic questioning, line 90+)\n   - Add instruction after line 93 (REQUIRED: Use AskUserQuestion): include data coupling evidence as input to questions\n   - When probing isolation ('If you replace X, what else changes?'), reference coupling evidence: 'Codebase investigation found modules A and B share User data across their boundary.'\n   - When probing rate-of-change, note which boundaries have heavy data coupling vs light\n   - For REVISION MODE: reference where actual coupling differs from declared graph edges\n\n5. Weave coupling evidence into Step 2 (Structure proposal, line 285+)\n   - Add instruction in proposal format (around line 290): each proposed boundary must note data coupling cost\n   - Edge list format gains coupling annotation:\n     Current: '- [Node A] blocks [Node B] (interface: [what flows between them])'\n     New: '- [Node A] blocks [Node B] (interface: [what flows between them], coupling: [N shared data shapes, triggered by M entry points])'\n   - Tradeoff analysis should reference coupling: 'This boundary splits modules with 4 shared data shapes ‚Äî interface cost is real'\n\n## Implementation Checklist\n- [ ] Step 0b section added after line 79 (codebase detection), before line 81 (ADR check)\n- [ ] Step 0b gated on codebase existence (same condition as Step 0a ‚Äî skipped in greenfield)\n- [ ] INCEPTION MODE dispatch prompt present with parameterization reference\n- [ ] REVISION MODE dispatch prompt present with graph context reference\n- [ ] Step 1 instructions include coupling evidence usage (after line 93)\n- [ ] Step 2 proposal format includes coupling annotation on edges (around line 290)\n- [ ] Step 2 tradeoff analysis references coupling evidence\n- [ ] No changes to Step 0a structural dispatch (lines 71-78 unchanged)\n- [ ] No changes to ADR creation process (Step 4 unchanged)\n- [ ] No changes to greenfield mode (line 79 still skips investigation)\n- [ ] Module-level resolution maintained in prompt text\n- [ ] Quick reference table (line 17) updated: Step 0 deliverable updated to include data coupling\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå Do NOT modify the existing Step 0a dispatch prompt (lines 71-78)\n- ‚ùå Do NOT make Step 0b fire in greenfield mode (no codebase = no data to analyze)\n- ‚ùå Do NOT change the Socratic questioning format in Step 1 (AskUserQuestion tool usage, question families)\n- ‚ùå Do NOT change the ADR template or ADR creation process in Step 4\n- ‚ùå Do NOT modify the codebase-investigator agent prompt\n- ‚ùå Do NOT add function/class-level detail to the dispatch prompt (stay module-level)\n- ‚ùå Do NOT make coupling evidence replace structural evidence (additive only)\n\n## Key Considerations (SRE REVIEW)\n\n**Edge Case: Minimal Structural Results**\nIf Step 0a returns few modules or boundaries (small codebase), Step 0b coupling analysis will also be thin. This is acceptable ‚Äî thin input produces thin output. Do not add complexity to handle this; the Socratic questioning in Step 1 fills gaps through dialogue.\n\n**Edge Case: Revision Mode with Stale Graph**\nIn revision mode, the graph may not match current codebase. Step 0b compares actual data coupling against declared edges. Discrepancies (data flows between nodes with no declared edge) are valuable evidence for the revision ‚Äî they surface where the graph has drifted from reality.\n\n**Edge Case: Step 0b Returns No Coupling**\nIf modules are truly independent (no shared data shapes), Step 0b returns empty coupling evidence. This is a positive signal ‚Äî proposed boundaries that split these modules have low interface cost. Do not treat absence of coupling as an error.\n\n**Mechanism: Prompt Parameterization**\nThe skill file contains template text. At runtime, Claude substitutes Step 0a results into the prompt ‚Äî same mechanism used for the existing Step 0a dispatch. The results are in Claude's context from the first dispatch; the second dispatch references them.\n\n## Success Criteria\n- [ ] Step 0b section present between codebase detection and ADR check\n- [ ] Step 0b has explicit gating condition: only fires when codebase exists\n- [ ] Step 0b has separate prompts for INCEPTION and REVISION modes\n- [ ] REVISION mode prompt references graph node names from bd\n- [ ] Step 1 contains instruction to use coupling evidence in Socratic questions\n- [ ] Step 2 edge format includes coupling annotation\n- [ ] Step 2 tradeoff section references coupling evidence\n- [ ] Existing Step 0a dispatch unchanged (diff shows no modifications to lines 71-78)\n- [ ] Quick reference table reflects Step 0 change\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"feature","owner":"abugosh@gmail.com","created_at":"2026-02-15T09:04:53.893908-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T09:21:32.85428-05:00","closed_at":"2026-02-15T09:21:32.85428-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-8o4","depends_on_id":"bd-tu6","type":"parent-child","created_at":"2026-02-15T09:04:57.318452-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-9","title":"Bug: Hooks using invalid 'continue' decision instead of 'approve' or 'deny'","design":"## Root Cause Analysis\n\nThe hooks implementation used 'continue' as a decision value, which was incorrect. The fix changed it to 'approve', but that's ALSO incorrect!\n\nAccording to Claude Code official documentation:\n\n**Valid decision values by hook type:**\n- **PreToolUse**: 'allow', 'deny', 'ask'\n- **PostToolUse, UserPromptSubmit, Stop, SubagentStop**: 'block' OR undefined (no decision field)\n- **SessionStart/SessionEnd**: No decision field; use additionalContext only\n\n**Our hooks and their issues:**\n\n1. **SessionStart hook** (hooks/session-start.sh:25-32)\n   - ‚úÖ CORRECT: Returns hookSpecificOutput with additionalContext, no decision field\n   \n2. **Stop hook** (hooks/stop/10-gentle-reminders.sh:85-86)\n   - ‚úÖ CORRECT: Returns nothing (just exit 0), which is valid for non-blocking reminders\n   \n3. **PostToolUse hook** (hooks/post-tool-use/01-track-edits.sh:73,79,98,119)\n   - ‚ùå INCORRECT: Returns {\"decision\": \"approve\"} \n   - Should: Omit decision field entirely (just tracking edits, not blocking)\n   - Correct format: {} or {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\"}}\n   \n4. **UserPromptSubmit hook** (hooks/user-prompt-submit/10-skill-activator.js:159,167,182,190,197)\n   - ‚ùå INCORRECT: Returns {\"decision\": \"approve\", \"additionalContext\": \"...\"}\n   - Should: Omit decision field (adding context, not blocking prompts)\n   - Correct format: {\"additionalContext\": \"...\"} or {\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"...\"}}\n\n**Why 'approve' is wrong:**\n- 'approve' is a deprecated legacy value that mapped to 'allow' for PreToolUse\n- For PostToolUse and UserPromptSubmit, 'approve' is not a valid decision\n- These hooks should either omit the decision field OR use 'block' if they want to halt execution\n\n**Evidence:**\n- Official docs: https://docs.claude.com/en/docs/claude-code/hooks\n- Research from hyperpowers:internet-researcher agent (detailed analysis)\n- Git history shows 'continue' was changed to 'approve' in 6aaceca, but both are incorrect\n\n## Solution Approach\n\n1. Remove decision field from PostToolUse hook (4 locations in hooks/post-tool-use/01-track-edits.sh)\n2. Remove decision field from UserPromptSubmit hook (5 locations in hooks/user-prompt-submit/10-skill-activator.js)  \n3. Update all documentation/examples to reflect correct response structure\n4. Keep SessionStart and Stop hooks as-is (already correct)","notes":"## Summary\n\nFixed hooks to use correct decision values per Claude Code specification.\n\n## Changes Made\n\n### 1. PostToolUse Hook (hooks/post-tool-use/01-track-edits.sh)\n- Removed invalid 'decision': 'approve' field (4 locations)\n- Now returns '{}' (empty object) - correct for non-blocking logging hooks\n\n### 2. UserPromptSubmit Hook (hooks/user-prompt-submit/10-skill-activator.js)\n- Removed invalid 'decision': 'approve' field (5 locations)\n- Now returns '{}' or '{\"additionalContext\": \"...\"}' - correct for context injection\n\n### 3. Test Files Updated\n- hooks/post-tool-use/test-hook.sh: Check for no decision field\n- hooks/user-prompt-submit/test-hook.sh: Check for no decision field\n- hooks/test/integration-test.sh: Updated expectations\n\n### 4. Documentation Updated\n- HOOKS.md: Updated output examples\n- skills/building-hooks/resources/hook-examples.md: Fixed all examples\n- skills/building-hooks/resources/hook-patterns.md: Fixed all patterns\n- skills/skills-auto-activation/resources/hook-implementation.md: Fixed expected output\n\n## Verification\n\nAll integration tests passing (13/13).","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-30T16:08:29.942365-04:00","updated_at":"2025-10-30T16:16:30.423079-04:00","closed_at":"2025-10-30T16:16:30.423079-04:00"}
{"id":"bd-94d","title":"Create reviewer agent definition","design":"## Goal\nCreate agents/reviewer.md ‚Äî the agent prompt that defines how the reviewer agent behaves when dispatched by the lead to verify implementation against the epic spec. Returns a verdict-only output (APPROVED or GAPS FOUND) without flooding the lead context.\n\n## Why Next\nThe reviewer agent is the second Wave 1 deliverable (independent of executor agent). Both agent definitions must exist before the lead skill rewrite (Wave 2) can reference them. The executor agent (bd-1y1) is complete, so the reviewer is the natural next step.\n\n## Context from Completed Work\nbd-1y1 established the agent definition pattern:\n- Frontmatter: name, description (with XML examples), model, permissionMode, memory, skills\n- Structured sections: Role, Startup Protocol, Execution steps, Message Protocol, Rules\n- The executor uses permissionMode: bypassPermissions, model: sonnet, memory: project\n\n## Implementation\n\n### 1. Study the review-implementation skill for behavior to port\nRead skills/review-implementation/SKILL.md and extract:\n- The 4-step review process (Load epic ‚Üí Review each task ‚Üí Report findings ‚Üí Gate decision)\n- Evidence-based review with confidence scores (0.0-1.0)\n- Automated code completeness checks (TODOs, stubs, unwrap, ignored tests)\n- Dead code and refactoring remnants audit\n- Quality gates via test-runner agent\n- Test quality audit (tautological test detection)\n- Google Fellow-level code quality review\n- Success criteria verification with evidence\n- Anti-pattern checking\n- APPROVED vs GAPS FOUND verdict format\n\n### 2. Study existing agent patterns\nRead agents/executor.md (just completed) for the frontmatter and structure pattern.\nRead agents/code-reviewer.md for the existing code review agent pattern.\nRead agents/test-effectiveness-analyst.md for another review-oriented agent.\n\n### 3. Write the reviewer agent definition\nCreate agents/reviewer.md with these sections:\n\n**Frontmatter:**\n- name: reviewer\n- description: with XML examples showing lead dispatching reviewer for epic verification\n- model: sonnet\n- permissionMode: bypassPermissions (needs to run tests, read files freely)\n- memory: project\n- skills: testing-anti-patterns, verification-before-completion\n\n**Prompt body ‚Äî Section a: Role**\n- You are a reviewer agent dispatched by the lead to verify implementation against the epic spec\n- You apply Google Fellow-level SRE scrutiny\n- You return a structured verdict (APPROVED or GAPS FOUND) ‚Äî nothing else\n- You do NOT fix issues ‚Äî you identify them for the executor to fix\n\n**Prompt body ‚Äî Section b: Startup Protocol**\n1. Receive epic ID in dispatch prompt\n2. Read the epic: bd show \u003cepic-id\u003e\n3. List all tasks: bd list --parent \u003cepic-id\u003e\n4. Extract: Requirements, Success Criteria, Anti-Patterns\n\n**Prompt body ‚Äî Section c: Review Process**\nFor each closed task under the epic:\n1. Read task spec: bd show \u003ctask-id\u003e\n2. Run automated checks (TODOs, stubs, unsafe patterns, ignored tests)\n3. Run dead code audit (fallback patterns, unused code, deprecation, orphaned tests)\n4. Run quality gates via test-runner agent (tests, format, lint)\n5. Read actual implementation files with Read tool (NOT just git diff)\n6. Code quality review (error handling, safety, clarity, production readiness)\n7. Audit new tests for meaningfulness (tautological test detection)\n8. Verify each success criterion with evidence\n9. Check each anti-pattern (search for prohibited patterns)\n10. Record findings with evidence and confidence scores\n\n**Prompt body ‚Äî Section d: Verdict Format**\nAPPROVED verdict format:\n```\n## Implementation Review: APPROVED\n\n### Tasks Reviewed\n- \u003ctask-id\u003e: \u003ctitle\u003e ‚Äî PASS\n...\n\n### Evidence Summary\n| Criterion | Status | Confidence | Evidence |\n|-----------|--------|------------|----------|\n...\n\n### Quality Gates\n- Tests: PASS (N passed, 0 failed)\n- Format: PASS\n- Lint: PASS\n\n### Test Quality Audit\n- Meaningful tests: N\n- Tautological tests: 0\n- Weak tests: 0\n\nRecommendation: Ready for manual validation.\n```\n\nGAPS FOUND verdict format:\n```\n## Implementation Review: GAPS FOUND\n\n### Critical Gaps\n1. [gap description with evidence]\n...\n\n### Important Gaps\n1. [gap description with evidence]\n...\n\n### Tasks with Issues\n- \u003ctask-id\u003e: \u003ctitle\u003e ‚Äî [specific gap]\n...\n\nRecommendation: Fix gaps before proceeding.\n```\n\n**Prompt body ‚Äî Section e: Rules (No Exceptions)**\n1. Read actual files, not just git diff\n2. Every claim requires evidence (file:line, command output, test name)\n3. Findings below 0.8 confidence must be investigated further\n4. Tautological tests = GAPS FOUND (not coverage credit)\n5. Never approve with unresolved gaps ‚Äî even small ones\n6. Never fix issues ‚Äî only identify them\n7. Always use test-runner agent for quality gates (context preservation)\n8. Report verdict to lead via SendMessage, not direct output\n\n### 4. Verify\nRead agents/reviewer.md back and confirm:\n- [ ] Frontmatter has all fields (name, description with examples, model, permissionMode, memory, skills)\n- [ ] Startup protocol specifies exact bd commands\n- [ ] Review process covers all 10 steps from review-implementation skill\n- [ ] Both verdict formats complete (APPROVED and GAPS FOUND)\n- [ ] Evidence table format defined with confidence scores\n- [ ] Test quality audit section included\n- [ ] Dead code audit section included\n- [ ] All rules listed\n- [ ] No placeholder text\n- [ ] Pre-commit hooks passing\n\n## Success Criteria\n- [ ] agents/reviewer.md exists with complete frontmatter (name, description, model, permissionMode, memory, skills)\n- [ ] Startup protocol specifies exact bd commands for epic and task loading\n- [ ] Review process covers all steps from review-implementation skill (automated checks, dead code audit, quality gates, file reading, code quality, test audit, criteria verification, anti-pattern checking)\n- [ ] APPROVED verdict format defined with evidence table and confidence scores\n- [ ] GAPS FOUND verdict format defined with categorized gaps and evidence\n- [ ] Test quality audit integrated (tautological test detection)\n- [ ] Dead code audit integrated (fallback patterns, unused code, deprecation)\n- [ ] Rules section covers all key constraints\n- [ ] No placeholder text in any section\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n- NO vague review instructions ('review the code' without specifying what to check)\n- NO placeholder evidence formats ('[evidence here]' without defining structure)\n- NO skipping test quality audit (tautological tests are a critical check)\n- NO skipping dead code audit (refactoring remnants must be caught)\n- NO approval without confidence scores (every finding needs quantified confidence)\n- NO fix instructions in the reviewer (reviewer identifies, executor fixes)","notes":"## Key Considerations (SRE Review)\n\n**Edge Case: Reviewer dispatched as subagent vs teammate**\n- Epic open question: 'Whether reviewer agent should be a teammate or a subagent (subagent likely sufficient for one-shot analysis)'\n- Decision: Use subagent (Task tool), NOT teammate. Reviewer is one-shot analysis ‚Äî dispatched, returns verdict, done. No ongoing conversation needed.\n- Implication for agent definition: The reviewer sends its verdict as its final output (returned to lead via Task tool result), NOT via SendMessage. Adjust Section e Rule 8 accordingly.\n- The description in the frontmatter must include examples showing Task tool dispatch, not TeamCreate.\n\n**Edge Case: Projects without test suites**\n- Some projects (like this plugin repo) have no automated tests\n- Reviewer must adapt automated checks to what's available\n- If no test suite: quality gates section should note 'No automated tests detected' rather than failing\n- If project is markdown-only: skip code-specific checks (unwrap, stubs) and focus on content quality\n\n**Edge Case: Documentation-only tasks**\n- Some tasks produce only markdown files (like this task itself)\n- Reviewer should still verify: no placeholder text, sections complete, content matches spec\n- Don't skip review because 'it's just docs' ‚Äî docs ARE the deliverable in a plugin project\n\n**Edge Case: bd show returns error for a task**\n- A task listed under the epic might have been deleted or have corrupted data\n- Reviewer should note the error and continue with remaining tasks\n- Include error in findings as 'UNABLE TO REVIEW: \u003ctask-id\u003e ‚Äî bd show returned error'\n\n**Edge Case: Context exhaustion during large epic review**\n- Epic with 10+ tasks may exhaust reviewer context\n- Reviewer should prioritize: review tasks in dependency order, critical tasks first\n- If approaching context limits: send partial verdict with what was reviewed and what remains\n\n**Edge Case: No files changed on branch**\n- If git diff shows no changes, reviewer should flag this as a gap\n- Implementation claims without code changes = GAPS FOUND\n\n**Effort Estimate: 4-6 hours**\n\n**Subagent dispatch pattern (how lead will use this):**\nThe lead dispatches the reviewer like this:\n```\nTask tool with subagent_type='general-purpose':\n  prompt: 'You are the reviewer agent. Review epic bd-t4i. Follow agents/reviewer.md exactly.'\n```\nThe reviewer's output is returned directly to the lead ‚Äî no SendMessage needed.","status":"closed","priority":2,"issue_type":"feature","owner":"abugosh@gmail.com","created_at":"2026-02-14T11:45:46.353308-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T11:50:29.265058-05:00","closed_at":"2026-02-14T11:50:29.265058-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-94d","depends_on_id":"bd-t4i","type":"parent-child","created_at":"2026-02-14T11:45:50.573828-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-9gk","title":"Feature: Replace pre-commit with universal validation system","design":"## Requirements (IMMUTABLE)\n- Test-runner agent supports explicit commands (e.g., 'Run: npm test') - unchanged behavior\n- Test-runner agent supports 'Run: validate' magic command that auto-detects project tooling\n- Auto-detection prioritizes project scripts (npm run lint) over direct tool invocation (eslint .)\n- Validation order: Format check ‚Üí Lint ‚Üí Typecheck ‚Üí Test (fast to slow)\n- Missing validations are skipped gracefully with clear reporting\n- Validation stops on first failure category (don't run tests if lint fails)\n- All pre-commit framework references removed from agent and skills\n\n## Success Criteria (MUST ALL BE TRUE)\n- [ ] 'Run: validate' auto-detects JS/TS projects (package.json) and runs appropriate validations\n- [ ] 'Run: validate' auto-detects Rust projects (Cargo.toml) and runs cargo fmt/clippy/test\n- [ ] 'Run: validate' auto-detects Python projects (pyproject.toml) and runs ruff/mypy/pytest\n- [ ] 'Run: validate' auto-detects Go projects (go.mod) and runs go vet/test\n- [ ] 'Run: validate' falls back to Makefile targets if no language-specific config found\n- [ ] Report format shows each validation category with pass/fail/skip status\n- [ ] Skipped validations clearly reported (e.g., 'no lint script found')\n- [ ] No pre-commit references remain in agents/test-runner.md\n- [ ] No pre-commit references remain in skills that call test-runner\n- [ ] skill-rules.json updated with 'validate', 'lint', 'typecheck' keywords\n- [ ] All existing explicit command functionality preserved ('Run: npm test' still works)\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO pre-commit framework references (universality: not all projects use pre-commit)\n- ‚ùå NO direct tool invocation when project script exists (consistency: respect project config)\n- ‚ùå NO continuing validation after failure (efficiency: stop early, report clearly)\n- ‚ùå NO silent skipping of validations (transparency: always report what was skipped and why)\n- ‚ùå NO hardcoded tool paths (portability: use npx/cargo/etc. for tool resolution)\n- ‚ùå NO running format with --fix during validation (safety: validation is read-only, use --check)\n\n## Approach\nReplace all pre-commit hook references in test-runner agent with a universal validation system. The agent will support two modes:\n\n1. **Explicit commands** (existing) - 'Run: npm test' executes exactly as specified\n2. **Magic validate command** (new) - 'Run: validate' auto-detects project type and runs Format‚ÜíLint‚ÜíTypecheck‚ÜíTest\n\nAuto-detection uses file presence: package.json (JS/TS), Cargo.toml (Rust), pyproject.toml (Python), go.mod (Go), Makefile (generic). For JS/TS, parse package.json scripts object to find lint/format/test scripts.\n\n## Architecture\n### Detection Flow\n1. Check for package.json ‚Üí JS/TS ecosystem\n2. Check for Cargo.toml ‚Üí Rust ecosystem  \n3. Check for pyproject.toml ‚Üí Python ecosystem\n4. Check for go.mod ‚Üí Go ecosystem\n5. Check for Makefile ‚Üí Generic targets\n6. No config found ‚Üí Report error, suggest explicit commands\n\n### Validation Commands by Ecosystem\n**JS/TS:** npm run format:check, npm run lint, npm run type-check OR npx tsc --noEmit, npm test\n**Rust:** cargo fmt -- --check, cargo clippy -- -D warnings, cargo test\n**Python:** ruff format --check ., ruff check ., mypy ., pytest\n**Go:** gofmt -l . (check via output), go vet ./..., go test ./...\n**Makefile:** make format-check, make lint, make typecheck, make test\n\n### Files Changed\n- agents/test-runner.md (major rewrite)\n- skills/verification-before-completion/SKILL.md\n- skills/review-implementation/SKILL.md\n- skills/finishing-a-development-branch/SKILL.md\n- skills/fixing-bugs/SKILL.md\n- skills/brainstorming/SKILL.md\n- skills/common-patterns/bd-commands.md\n- hooks/skill-rules.json\n- README.md\n- HOOKS.md\n- hooks/post-tool-use/04-block-pre-existing-checks.py\n\n## Design Rationale\n### Problem\nTest-runner agent assumes projects use pre-commit framework. Many projects run linters, typecheckers, and tests directly without pre-commit. This causes the agent to look for hooks that don't exist, creating inconsistent behavior.\n\n### Research Findings\n**Ecosystem Detection:**\n- package.json scripts object contains project-specific commands\n- Cargo.toml projects use built-in cargo fmt/clippy/test\n- pyproject.toml contains [tool.ruff], [tool.mypy], [tool.pytest] sections\n- go.mod projects use go vet/test/fmt built-ins\n- Makefile projects typically have lint/test/check targets\n\n**Script Naming Conventions:**\n- JS/TS: lint, format:check, type-check, test\n- Python: ruff check, mypy, pytest (direct tools, not scripts)\n- Rust: cargo commands are standardized\n- Go: go commands are standardized\n\n### Approaches Considered\n\n#### 1. Universal validation with auto-detection ‚úì\n**What it is:** Replace pre-commit references with ecosystem-aware auto-detection that runs Format‚ÜíLint‚ÜíTypecheck‚ÜíTest using project-native tooling.\n\n**Pros:**\n- Works for all projects regardless of pre-commit usage\n- Respects project-specific configuration\n- Clear, predictable validation order\n\n**Cons:**\n- More complex detection logic\n- Must maintain ecosystem mappings\n\n**Chosen because:** Universal solution that works for all projects, not just pre-commit users.\n\n#### 2. Keep pre-commit as fallback ‚ùå\n**What it is:** Add universal validation but keep pre-commit as option if .pre-commit-config.yaml exists.\n\n**Why explored:** Backwards compatibility for pre-commit users.\n\n**Rejected because:** Adds complexity, maintains two code paths. Pre-commit users can still use explicit 'Run: pre-commit run' if needed.\n\n**üö´ DO NOT REVISIT UNLESS:** Significant user demand for pre-commit integration.\n\n### Scope Boundaries\n**In scope:**\n- Auto-detection for JS/TS, Rust, Python, Go, Makefile projects\n- 'Run: validate' magic command\n- Updated report format with category breakdown\n- Updating all skills that reference pre-commit\n\n**Out of scope:**\n- Adding new ecosystems (Java, Ruby, etc.) - can add later\n- Custom validation config file (.claude-validate.json) - YAGNI\n- Parallel validation execution - sequential is simpler\n\n### Open Questions\n- Should 'Run: validate' accept flags like 'Run: validate --skip-format'? (defer to implementation - start simple)\n\n## Design Discovery (Reference Context)\n\n### Key Decisions Made\n\n| Question | User Answer | Implication |\n|----------|-------------|-------------|\n| Script priority? | Prefer project scripts | Use 'npm run lint' over 'eslint .' |\n| Validation categories? | Format + Lint + Typecheck + Test | Four categories, run in order |\n| Missing tools handling? | Skip missing, run what exists | Report skipped, don't fail |\n| Pre-commit fate? | Remove completely | No pre-commit references anywhere |\n| Trigger phrase? | 'Run: validate' | Short, clear magic command |\n\n### Research Deep-Dives\n\n#### Ecosystem Detection Patterns\n**Question explored:** How to detect project type and find validation commands?\n**Sources consulted:**\n- npm package.json scripts conventions\n- Cargo book for fmt/clippy/test\n- Ruff/mypy/pytest documentation\n- Go tooling documentation\n- GNU Makefile standards\n\n**Findings:**\n- JS/TS: Parse package.json scripts, look for lint/format:check/type-check/test\n- Rust: Commands standardized (cargo fmt/clippy/test)\n- Python: Tools invoked directly (ruff/mypy/pytest), config in pyproject.toml\n- Go: Built-in commands (go vet/test/fmt)\n- Makefile: Convention-based targets (lint/test/check)\n\n**Conclusion:** File presence detection + ecosystem-specific command mapping\n\n### Dead-End Paths\n\n#### Pre-commit as fallback option\n**Why explored:** User might want backwards compatibility\n**Investigation:** Discussed with user - adds complexity for little benefit\n**Why abandoned:** User chose 'Remove completely' - simpler single approach\n\n### Open Concerns Raised\n- 'What about projects with custom validation?' ‚Üí Explicit commands still work ('Run: ./custom-validate.sh')\n- 'What if detection is wrong?' ‚Üí Report what was detected, user can use explicit commands","status":"closed","priority":2,"issue_type":"epic","owner":"abugosh@jellyvision.com","created_at":"2026-01-22T11:23:58.780109-05:00","created_by":"Alex Bugosh","updated_at":"2026-01-22T12:45:03.225436-05:00","closed_at":"2026-01-22T12:45:03.225436-05:00","close_reason":"Closed"}
{"id":"bd-a5p","title":"Task 3: Add data flow context to brainstorming architecture node detection","description":"When brainstorming auto-detects an architecture node, dispatch a codebase-investigator to derive fresh inbound/outbound/transform/request-path context scoped to that component, presented alongside existing architectural context before Socratic questioning.","design":"## Goal\nWhen brainstorming auto-detects an architecture node, add a codebase-investigator dispatch that derives fresh data flow context (inbound, outbound, transforms, request paths) scoped to that component. Present this alongside the existing architectural context before Socratic questioning.\n\n## Effort Estimate\n2-3 hours\n\n## Implementation\n\n1. Study existing architecture node detection in skills/brainstorming/SKILL.md\n   - Lines 52-104: architecture node auto-detection and context loading\n   - Lines 70-80: loading node design context (bd show, bd dep tree) and ADRs\n   - Lines 83-95: existing context presentation block\n   - Lines 99-104: edge cases section\n\n2. Add codebase existence gate in the node detection path\n   - Lines 52-104 currently don't check for codebase ‚Äî need to add gate\n   - If no codebase exists, skip the flow dispatch entirely\n   - The graph can exist without a codebase (design phase) ‚Äî handle gracefully\n\n3. Add codebase-investigator dispatch AFTER loading node context (after ADR loading, around line 80), BEFORE context presentation (line 83)\n   - Dispatch to codebase-investigator with component-scoped prompt:\n     'For component [node name] with these boundaries: [adjacent nodes from bd deps]\n\n     1. What data enters this component? (from which upstream modules, what shape at module level?)\n     2. What data exits this component? (to which downstream modules, what shape?)\n     3. What data transformations happen inside? (what shape goes in vs what comes out?)\n     4. What are the primary request paths that flow through this component?\n\n     Reference the component declared interface contract: [from node design]'\n   - This prompt is COMPONENT-SCOPED (unlike system-wide for decomposition or graph-wide for audit)\n\n4. Add flow context to the existing context presentation block (lines 83-95)\n   - Add as a new section WITHIN the existing block, not a separate announcement:\n     'Data flow context for [node name]:\n     - Inbound: [data shapes from upstream modules]\n     - Outbound: [data shapes to downstream modules]\n     - Transforms: [shape changes inside component]\n     - Request paths: [entry points flowing through]'\n   - Place after the architectural context (volatility axis, layer, interface contract, ADRs)\n\n5. Add edge case to edge cases section (lines 99-104)\n   - 'No codebase but graph exists: skip flow dispatch, present architectural context only'\n   - Handle multiple-node case: dispatch per node is acceptable given rarity\n\n## Implementation Checklist\n- [ ] Codebase existence gate added in node detection path\n- [ ] Codebase-investigator dispatch added after node context loading, before presentation\n- [ ] Dispatch prompt is component-scoped (references node name, adjacent nodes, interface contract)\n- [ ] Flow context section added within existing presentation block\n- [ ] Flow context includes all four categories: inbound, outbound, transforms, request paths\n- [ ] Edge case documented: no codebase but graph exists\n- [ ] Greenfield mode skips flow dispatch entirely\n- [ ] No changes to Socratic questioning format\n- [ ] No changes to epic creation process\n- [ ] No changes to ADR handling\n- [ ] Module-level resolution maintained\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå Do NOT present flow context as a separate announcement (must be within existing context block)\n- ‚ùå Do NOT change the Socratic questioning process\n- ‚ùå Do NOT change the epic creation or anti-pattern format\n- ‚ùå Do NOT modify the codebase-investigator agent prompt\n- ‚ùå Do NOT add function/class-level detail (stay module-level)\n- ‚ùå Do NOT persist flow context as an artifact (derive fresh each time)\n\n## Key Considerations (SRE REVIEW)\n\n**Component-Scoped vs System-Wide**\nUnlike decomposition (system-wide coupling) and audit (graph-wide paths), the brainstorming dispatch is COMPONENT-SCOPED. The prompt asks about ONE component's inbound/outbound/transforms, not the entire system. This keeps the investigation focused and fast.\n\n**Edge Case: Greenfield with Graph**\nArchitecture graphs can exist before code does (design phase). In this case, the node detection finds the graph, but there's no codebase to investigate. Must skip flow dispatch and present only architectural context.\n\n**Edge Case: Multiple Nodes**\nIf brainstorming is invoked for multiple nodes (rare), dispatching per node is acceptable. The investigator scales adaptively.\n\n**Derive Fresh Principle**\nThis dispatch happens at inner-loop handoff time. Code may have changed since the outer-loop decomposition. Fresh derivation catches drift without stale artifacts ‚Äî this is WHY we don't carry flow context forward from the outer loop.\n\n## Success Criteria\n- [ ] Flow dispatch fires when architecture node detected AND codebase exists\n- [ ] Flow dispatch skipped when no codebase (greenfield)\n- [ ] Dispatch prompt is component-scoped (references specific node, not entire system)\n- [ ] Flow context presented within existing context block (not separate)\n- [ ] All four categories present: inbound, outbound, transforms, request paths\n- [ ] Edge cases documented in edge cases section\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"feature","owner":"abugosh@gmail.com","created_at":"2026-02-15T13:28:52.887089-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T13:32:34.473406-05:00","closed_at":"2026-02-15T13:32:34.473406-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-a5p","depends_on_id":"bd-tu6","type":"parent-child","created_at":"2026-02-15T13:28:53.483797-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-awr","title":"Task 2: Add request path and flow dispatch to architectural-audit Step 1, weave into passes 1/3/4","description":"Add Step 1b (second investigator dispatch for request paths, undeclared data flows, implicit ordering) and enrich audit passes 1 (Complection), 3 (Temporal Coupling), and 4 (Hidden Dependencies) with flow evidence.","design":"## Goal\nAdd a second investigator dispatch (Step 1b) to the architectural-audit skill that gathers request path and undeclared data flow evidence at module level, using Step 1a structural findings AND the bd architecture graph. Then weave flow evidence into passes 1, 3, and 4.\n\n## Effort Estimate\n3-5 hours\n\n## Implementation\n\n1. Study existing Step 1 in skills/architectural-audit/SKILL.md\n   - Find the current 6-bucket investigator dispatch (Step 1a)\n   - Find where Step 2 (analysis passes) begins\n   - Find the greenfield gating condition\n   - Study passes 1, 3, 4 structure (Graph evidence / Codebase evidence subsections)\n\n2. Add Step 1b AFTER Step 1a evidence gathering, BEFORE Step 2 analysis passes\n   - GATING CONDITION: Only dispatch Step 1b when codebase exists (same condition as Step 1a)\n   - In greenfield mode, skip Step 1b entirely\n   - Second dispatch to codebase-investigator, parameterized by Step 1a results AND bd graph\n\n3. Step 1b dispatch prompt:\n   'Based on these structural findings: [include Step 1a results]\n   And this architecture graph: [include graph nodes and edges from bd]\n\n   1. REQUEST PATHS: For each entry point (HTTP handlers, CLI commands, event consumers), trace at module level which graph nodes the request touches and what data it carries between them.\n   2. UNDECLARED DATA FLOWS: Identify data that flows between graph nodes that have NO declared edge (relates_to, blocks) in the graph.\n   3. IMPLICIT ORDERING: Where data flows create ordering that must happen sequentially, but no blocks edge declares this dependency.\n\n   Report at module level. Reference specific graph node names for each finding.'\n\n4. Weave flow evidence into Pass 1 (Complection Scan)\n   - Add 'Flow evidence:' subsection alongside existing evidence subsections\n   - Content: module participation in request paths as complection signal\n   - Example: 'Module X appears on N distinct request paths ‚Äî suggests tangled concerns'\n   - CRITICAL: Use neutral analytical tone (no recommendations, no severity)\n\n5. Weave flow evidence into Pass 3 (Temporal Coupling)\n   - Add 'Flow evidence:' subsection\n   - Content: flow-derived ordering as temporal coupling signal\n   - Example: 'Data from A must exist before B processes it, but no blocks edge declares this'\n   - CRITICAL: Neutral tone ‚Äî observe, don't recommend\n\n6. Weave flow evidence into Pass 4 (Hidden Dependencies)\n   - Add 'Flow evidence:' subsection\n   - Content: undeclared flows as hidden dependency signal\n   - Example: 'Data flows from X to Y through Z, but graph shows no edge between X and Y'\n   - CRITICAL: Neutral tone\n\n7. Update quick reference table to reflect Step 1 change\n\n8. Check if verification checklist needs update to note flow evidence as additional source\n\n## Implementation Checklist\n- [ ] Step 1b section added between Step 1a evidence gathering and Step 2 analysis passes\n- [ ] Step 1b gated on codebase existence (same condition as Step 1a)\n- [ ] Step 1b dispatch prompt references BOTH structural findings AND bd architecture graph\n- [ ] Pass 1 (Complection) has 'Flow evidence:' subsection with request path participation\n- [ ] Pass 3 (Temporal Coupling) has 'Flow evidence:' subsection with implicit ordering\n- [ ] Pass 4 (Hidden Dependencies) has 'Flow evidence:' subsection with undeclared flows\n- [ ] All flow evidence wording passes audit self-check: no recommendations, no severity, no ordering language\n- [ ] Passes 2, 5, 6 unchanged\n- [ ] No changes to Step 1a (6-bucket structural evidence unchanged)\n- [ ] Module-level resolution maintained\n- [ ] Quick reference table updated\n- [ ] Verification checklist updated if needed\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå Do NOT modify the existing Step 1a dispatch prompt (6-bucket evidence unchanged)\n- ‚ùå Do NOT add a 7th analysis pass (flow evidence weaves into existing passes)\n- ‚ùå Do NOT use recommendation language in any flow evidence wording (audit is analytical, not prescriptive)\n- ‚ùå Do NOT use severity language (no 'critical', 'high', 'medium', 'low')\n- ‚ùå Do NOT suggest ordering of findings (no 'most important', 'primary concern')\n- ‚ùå Do NOT change passes 2, 5, or 6\n- ‚ùå Do NOT modify the codebase-investigator agent prompt\n- ‚ùå Do NOT add function/class-level detail (stay module-level)\n\n## Key Considerations (SRE REVIEW)\n\n**Audit Tone Constraint**\nThe architectural-audit skill has a mandatory self-check that prohibits recommendation language, severity language, and ordering language. ALL flow evidence wording must pass this self-check. Use observational language: 'X appears on N paths' not 'X is problematically on too many paths'.\n\n**Graph Context in Dispatch**\nUnlike the decomposition dispatch (which only uses structural findings), the audit dispatch MUST include the bd architecture graph (nodes and edges). This is what makes the audit dispatch unique ‚Äî it compares actual data flows against declared graph structure.\n\n**Edge Case: No Graph Exists**\nIf the audit is run without an architecture graph in bd, Step 1b should still fire using only structural findings. The 'undeclared data flows' bucket becomes 'all observed data flows' since there are no declared edges to compare against.\n\n**Edge Case: Greenfield (No Codebase)**\nStep 1b must not fire in greenfield mode ‚Äî same gating as Step 1a.\n\n## Success Criteria\n- [ ] Step 1b section present between Step 1a and Step 2\n- [ ] Step 1b gated on codebase existence\n- [ ] Step 1b prompt references both structural findings and bd graph\n- [ ] Pass 1 includes flow evidence (request path participation)\n- [ ] Pass 3 includes flow evidence (implicit ordering)\n- [ ] Pass 4 includes flow evidence (undeclared flows)\n- [ ] All flow evidence wording passes audit self-check (no recommendations/severity/ordering)\n- [ ] Quick reference table updated\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"feature","owner":"abugosh@gmail.com","created_at":"2026-02-15T09:25:07.834163-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T09:26:47.453953-05:00","closed_at":"2026-02-15T09:26:47.453953-05:00","close_reason":"Duplicate ‚Äî original executor completed this work as bd-tu6.1","dependencies":[{"issue_id":"bd-awr","depends_on_id":"bd-tu6","type":"parent-child","created_at":"2026-02-15T09:25:08.305639-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-b07","title":"Update integration points and documentation for delegation model","design":"## Goal\nUpdate all files that reference the old executing-plans solo model to reflect the new agent teams delegation model. This includes skill handoff sections, workflow descriptions, and project documentation.\n\n## Context\nWaves 1-2 complete:\n- agents/executor.md ‚Äî Executor agent (teammate, TDD, structured messages)\n- agents/reviewer.md ‚Äî Reviewer agent (subagent, verdict-only)\n- skills/executing-plans/SKILL.md ‚Äî Rewritten as lead orchestration workflow\n\nThe old model: solo execution with STOP checkpoints and manual /clear cycling.\nThe new model: lead orchestrates, executor teammate implements, reviewer subagent verifies.\n\n## Effort Estimate\n3-4 hours\n\n## Files to Update\n\n### 1. skills/brainstorming/SKILL.md\nLines referencing executing-plans handoff (lines 22-23, 36, 376, 406-408, 821, 838, 852, 861-862, 866):\n- Update handoff description: no longer 'iterative implementation' ‚Äî now 'lead orchestrates executor teammate'\n- Update the handoff presentation (lines 406-408): describe that executing-plans will create a team, spawn executor, and orchestrate\n- Update integration section (lines 861-862, 866): reflect new workflow chain\n\n### 2. skills/using-hyper/SKILL.md\nLines referencing executing-plans (lines 101, 176-178, 322, 339, 383):\n- Line 101: update description of what executing-plans does\n- Lines 176-178: update example of executing-plans being loaded\n- Line 322: update rigidity description ‚Äî still LOW FREEDOM but about orchestration\n- Line 339: update workflow chain brainstorming ‚Üí writing-plans ‚Üí executing-plans\n- Line 383: update the workflow description\n\n### 3. CLAUDE.md\nLines referencing executing-plans (lines 128, 171):\n- Line 128: update Tasks description\n- Line 171: update Executing Plans workflow step ‚Äî now describes delegation model\n- Update Core Workflows section to reflect lead/executor/reviewer pattern\n- Update Key Architecture Concepts to mention executor and reviewer agents\n\n### 4. README.md\nCheck for references to executing-plans or solo execution model.\nUpdate any workflow descriptions to reflect delegation.\n\n## Implementation Steps\n1. Read each file's relevant sections\n2. Make targeted edits to update references\n3. Preserve the meaning and intent ‚Äî just update the mechanics description\n4. Do NOT rewrite entire files ‚Äî only change sections that reference old model\n5. Verify no stale references remain with grep\n\n## Success Criteria\n- [ ] skills/brainstorming/SKILL.md handoff section describes delegation model (not solo execution)\n- [ ] skills/using-hyper/SKILL.md workflow descriptions updated for delegation\n- [ ] CLAUDE.md Core Workflows and Architecture sections updated\n- [ ] README.md updated if it contains executing-plans references\n- [ ] No remaining references to 'STOP checkpoint', 'manual /clear', 'solo execution' in updated files (unless in historical context)\n- [ ] Pre-commit hooks passing\n- [ ] All changes are targeted edits, not full rewrites\n\n## Anti-Patterns (FORBIDDEN)\n- NO rewriting entire files ‚Äî only change sections referencing old model\n- NO changing skill behavior ‚Äî only update descriptions/documentation of executing-plans\n- NO removing brainstorming handoff ‚Äî just update what it says about executing-plans\n- NO placeholder updates ('[updated]', '[new model]') ‚Äî write actual descriptions","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@gmail.com","created_at":"2026-02-14T12:19:39.605106-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T12:25:01.146156-05:00","closed_at":"2026-02-14T12:25:01.146156-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-b07","depends_on_id":"bd-t4i","type":"parent-child","created_at":"2026-02-14T12:19:44.391629-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-b5u","title":"Task 2: Create wave-planning skill","design":"## Goal\nCreate skills/wave-planning/SKILL.md ‚Äî a new skill that analyzes the Parallelism Map from a bd epic and creates batches of parallelizable tasks (waves), sets beads dependencies between them, and runs SRE refinement on each wave batch.\n\n## Context\nCompleted bd-7yn: The brainstorming skill now produces epics with a Parallelism Map section containing independent work streams, stream dependencies, suggested waves, file ownership boundaries, and a parallelism assessment. The wave-planning skill consumes this Parallelism Map to create actionable task batches.\n\nThis skill sits between brainstorming and team-executing-plans in the workflow:\n```\nbrainstorming ‚Üí sre-task-refinement ‚Üí wave-planning ‚Üí team-executing-plans\n```\n\n## Implementation\n\n### Step 1: Study existing skill patterns\n- Read skills/writing-plans/SKILL.md ‚Äî the solo equivalent of wave-planning (creates tasks from epics)\n- Read skills/executing-plans/SKILL.md ‚Äî understand the STOP checkpoint pattern\n- Read skills/sre-task-refinement/SKILL.md ‚Äî understand SRE integration\n- Note the standard skill structure: frontmatter, skill_overview, rigidity_level, quick_reference, when_to_use, the_process, examples, critical_rules, verification_checklist, integration, resources\n\n### Step 2: Create the skill file\nCreate skills/wave-planning/SKILL.md with the standard skill structure.\n\n**Frontmatter:**\n```yaml\n---\nname: wave-planning\ndescription: Use after brainstorming when Parallelism Map shows 3+ independent streams - creates waves of parallelizable tasks with beads dependencies for team execution\n---\n```\n\n**Core Process (the_process section):**\n\n1. **Load Epic and Parallelism Map**\n   - `bd show \u003cepic-id\u003e` to load epic\n   - Extract Parallelism Map section\n   - Verify 3+ independent streams exist (error if not ‚Äî should have taken solo path)\n\n2. **Validate File Ownership Boundaries**\n   - Check that no two streams in the same wave share exclusive files\n   - Shared files in the \"Shared (needs coordination)\" column: either create a separate coordination task or sequence the streams into different waves\n   - Flag any ambiguities for user resolution\n\n3. **Create Wave 1 Tasks**\n   - ONLY create Wave 1 tasks (not all waves ‚Äî iterative, matching executing-plans philosophy)\n   - For each independent stream in Wave 1, create a bd task:\n     - Title: \"Wave 1: [Stream Name]\"\n     - Design: Goal, file ownership boundaries, implementation steps, success criteria, anti-patterns from epic\n     - Include teammate context: which files this task owns, which files it must NOT touch\n   - Set beads dependencies: all Wave 1 tasks depend on epic (parent-child), no blocking deps between Wave 1 tasks (they're independent)\n\n4. **Run SRE Refinement on Wave Batch**\n   - Run hyperpowers:sre-task-refinement on each Wave 1 task\n   - This strengthens criteria, adds edge cases, ensures each task is teammate-ready\n\n5. **Present Wave Summary and STOP**\n   - Show: wave composition, task list, file ownership matrix, dependency graph\n   - STOP for user review before team-executing-plans spawns agents\n\n**Key Design Decisions:**\n- Only create one wave at a time (matches epic anti-pattern: NO creating full task trees upfront)\n- Each wave task includes file ownership boundaries in its design (teammates need to know what NOT to touch)\n- Wave tasks reference epic requirements and anti-patterns (teammates need the contract)\n\n### Step 3: Add wave sizing heuristics\nThe skill should include guidance for wave sizing:\n- Maximum tasks per wave: 4-5 (more becomes hard to coordinate)\n- Minimum tasks per wave: 2 (below this, use solo execution)\n- If a stream has high complexity + shared files: consider making it solo (its own wave)\n- If all streams are low complexity with no shared files: can batch more\n\n### Step 4: Add examples\nInclude 2 examples:\n1. **Good example:** 5 streams, 2 waves (infra wave + parallel features wave)\n2. **Bad example:** Developer creates all waves upfront instead of iteratively\n\n### Step 5: Add integration section\nDocument the call chain:\n- Called by: brainstorming (team path handoff)\n- Calls: sre-task-refinement (for each wave task), team-executing-plans (handoff after wave approved)\n- Uses: bd commands (create, dep add, show, ready)\n\n## Success Criteria\n- [ ] skills/wave-planning/SKILL.md exists with standard skill structure (frontmatter, overview, rigidity, quick_reference, when_to_use, the_process, examples, critical_rules, verification_checklist, integration, resources)\n- [ ] Skill reads Parallelism Map from epic and validates 3+ independent streams\n- [ ] Skill validates file ownership boundaries (no exclusive file conflicts within a wave)\n- [ ] Skill creates ONLY Wave 1 tasks (not all waves ‚Äî iterative creation)\n- [ ] Each wave task includes: goal, file ownership (owns + must-not-touch), implementation steps, success criteria, anti-patterns from epic\n- [ ] Skill runs SRE refinement on each wave task before STOP\n- [ ] Skill presents wave summary with file ownership matrix and dependency graph\n- [ ] Wave sizing heuristics documented (2-5 tasks per wave, complexity considerations)\n- [ ] Two examples included (good wave planning + bad upfront wave creation)\n- [ ] Integration section documents full call chain\n- [ ] STOP checkpoint after wave presentation (mandatory before team execution begins)\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO creating all waves upfront (only Wave 1 ‚Äî subsequent waves created after Wave 1 results, matching epic anti-pattern)\n- ‚ùå NO skipping SRE refinement on wave tasks (each task needs corner-case analysis)\n- ‚ùå NO allowing exclusive file conflicts within a wave (two tasks claiming same exclusive file = merge conflict)\n- ‚ùå NO skipping file ownership in task designs (teammates need to know their boundaries)\n- ‚ùå NO skipping STOP checkpoint (user must approve wave before team execution)\n- ‚ùå NO creating tasks without epic reference (each task must reference epic requirements and anti-patterns)\n\n## Key Considerations (FROM SRE REVIEW OF TASK 1)\n\n### Edge Case: Shared Files Between Streams\nThe Parallelism Map has a \"Shared (needs coordination)\" column. Wave-planning must handle this:\n- Option A: Create a separate coordination task that runs BEFORE the streams needing the shared file (becomes a Wave 0/1 dependency)\n- Option B: Sequence the conflicting streams into different waves (one edits shared file in Wave N, other uses it in Wave N+1)\n- Present both options to user when shared files detected\n\n### Edge Case: Streams with Different Complexity\nSome streams may be low complexity (1 hour) while others are high (8 hours). Wave-planning should note this:\n- Short tasks finish early, leaving agents idle\n- Consider grouping low-complexity streams together or combining them\n- Document this in wave sizing heuristics\n\n### Reference: Epic Anti-Pattern\nEpic bd-6t7 explicitly forbids: \"NO creating full task trees upfront (waves are created iteratively based on learnings from previous waves).\" The wave-planning skill must enforce this by creating ONLY the current wave's tasks.","status":"closed","priority":1,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-02-06T13:05:20.306819-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-06T13:19:00.969986-05:00","closed_at":"2026-02-06T13:19:00.969986-05:00","close_reason":"All 11 success criteria verified. Wave-planning skill created with standard structure (frontmatter, overview, rigidity, quick_reference, when_to_use, the_process, examples, critical_rules, verification_checklist, integration, resources). Reads Parallelism Map and validates 3+ streams. Validates file ownership boundaries with Option A/B conflict resolution. Creates ONLY current wave tasks (not all waves). Each task includes epic context, file ownership (owns + must-not-touch), implementation steps, success criteria, anti-patterns. Runs SRE refinement on every wave task. Presents wave summary with composition table, file ownership matrix, dependency graph. Wave sizing heuristics documented (2-5 tasks). Two examples included (correct planning + bad upfront creation). Integration section documents full call chain. Mandatory STOP checkpoint before team execution.","dependencies":[{"issue_id":"bd-b5u","depends_on_id":"bd-6t7","type":"parent-child","created_at":"2026-02-06T13:05:25.922503-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-dxf","title":"Feature: Enforce executor commits before task closure","design":"## Requirements (IMMUTABLE)\n- Executor MUST commit all work before running bd close on any task\n- One consolidated commit per task (not per deliverable within TDD cycle)\n- Commit hash(es) MUST be included in the executor's task completion message to the lead\n- Lead MUST verify commit hashes exist in completion message before approving next task proposal\n- If commit hashes missing from completion message, lead redirects executor to commit first\n\n## Success Criteria (MUST ALL BE TRUE)\n- [ ] Executor prompt (agents/executor.md) restructured: commit moved from per-deliverable to per-task, positioned between verify-completeness and bd-close\n- [ ] Executor prompt contains explicit anti-skip language making commit a prerequisite to bd close\n- [ ] Task completion message format in executor prompt includes ### Commits section with hash and message\n- [ ] Task completion message format in executing-plans skill matches executor's format (includes ### Commits)\n- [ ] Lead validation in executing-plans includes Step 0: verify commit hashes exist before evaluating proposal\n- [ ] Lead has redirect instruction for when commits are missing\n- [ ] All pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO adding hooks for enforcement (scope: prompt and lead gate only, per design decision)\n- ‚ùå NO changing TDD cycle itself (RED-GREEN-REFACTOR stays the same, only commit timing changes)\n- ‚ùå NO adding commit to both per-deliverable AND per-task (one commit per task only)\n- ‚ùå NO requiring the lead to run git log (lead checks message format only, not git state)\n\n## Approach\nStrengthen executor prompt and add lead validation gate. Two files change: agents/executor.md and skills/executing-plans/SKILL.md.\n\nIn executor.md: Remove commit from inside the TDD cycle (currently Step 6 after Refactor). Add commit as a new step between 'Verify completeness' and 'Close the task'. Add explicit language that committing is a prerequisite to bd close. Update the task completion message format to include a Commits section.\n\nIn executing-plans SKILL.md: Update the Task Completion Message format to include Commits section. Add Step 0 to lead validation: check for commit hashes before evaluating proposal. Add redirect instruction for missing commits.\n\n## Architecture\n- agents/executor.md ‚Äî Executor agent prompt (commit flow restructure)\n- skills/executing-plans/SKILL.md ‚Äî Lead orchestration skill (validation gate)\n\n## Design Rationale\n### Problem\nThe executor has instructions to commit after each RED-GREEN-REFACTOR cycle, but in practice it often skips commits entirely. Work accumulates uncommitted across multiple tasks and only gets committed during finish-branch. This loses the benefit of atomic per-task commits and risks losing work.\n\n### Research Findings\n**Codebase:**\n- agents/executor.md:83-91 ‚Äî Current commit step is Step 6 in TDD cycle, after Refactor\n- agents/executor.md:93-104 ‚Äî Verify completeness and Close task steps follow commit\n- skills/executing-plans/SKILL.md:137-143 ‚Äî Task completion message format has no Commits section\n- skills/executing-plans/SKILL.md:145-187 ‚Äî Lead validation process has no commit verification\n\n**External:**\n- N/A ‚Äî this is an internal plugin workflow change\n\n### Approaches Considered\n\n#### 1. Prompt reinforcement + lead gate ‚úì\n\n**What it is:** Strengthen executor prompt to make commit mandatory before bd close. Add commit hashes to task completion message. Lead validates hashes exist before approving.\n\n**Investigation:**\n- Reviewed executor.md ‚Äî commit is Step 6 but positioned as part of TDD cycle, easy to skip\n- Reviewed executing-plans SKILL.md ‚Äî lead has no commit verification whatsoever\n- Identified two enforcement points: executor self-enforcement + lead gate\n\n**Pros:**\n- Catches failure at two points (executor + lead)\n- Minimal changes (two files)\n- No new infrastructure (hooks, state tracking)\n\n**Cons:**\n- Still relies on prompt compliance at the executor level\n\n**Chosen because:** Addresses the problem at both enforcement points with targeted, minimal changes\n\n#### 2. Full restructure of executor flow ‚ùå\n\n**What it is:** Completely reorganize executor steps to separate TDD from commit/close gate.\n\n**Why we looked at this:** Cleaner separation of concerns\n\n**Investigation:**\n- Would require rewriting most of executor.md\n- Risk of introducing new issues in a well-established flow\n\n**Pros:**\n- Cleaner conceptual separation\n\n**Cons:**\n- More invasive than needed\n- Risk of breaking working parts of the flow\n\n**‚ö†Ô∏è REJECTED BECAUSE:** Scope creep ‚Äî the commit enforcement can be achieved with targeted changes, not a full rewrite.\n\n**üö´ DO NOT REVISIT UNLESS:** Executor.md needs a full rewrite for other reasons.\n\n#### 3. Prompt + PostToolUse hook ‚ùå\n\n**What it is:** Add a hook that detects bd close without preceding git commit.\n\n**Why we looked at this:** Mechanical enforcement can't be rationalized away\n\n**Investigation:**\n- Would need session state tracking (when was last commit?)\n- Hook detection is tricky ‚Äî timing, false positives\n- Adds infrastructure complexity for a prompt compliance issue\n\n**Pros:**\n- Can't be skipped by the executor\n\n**Cons:**\n- Hard to implement correctly (session state)\n- False positives possible\n- Adds maintenance burden\n\n**‚ö†Ô∏è REJECTED BECAUSE:** Over-engineering. Prompt + lead gate is sufficient enforcement without new infrastructure.\n\n**üö´ DO NOT REVISIT UNLESS:** Prompt + lead gate proves insufficient after deployment.\n\n### Scope Boundaries\n**In scope:**\n- Executor prompt changes (commit timing, anti-skip language, message format)\n- Executing-plans lead validation (commit hash check, redirect instruction)\n\n**Out of scope (deferred/never):**\n- Hook-based enforcement ‚Äî deferred unless prompt+gate insufficient\n- Changes to TDD cycle itself ‚Äî never, TDD stays as-is\n- Changes to test-runner agent ‚Äî not needed\n- Changes to finish-branch skill ‚Äî not affected\n\n### Open Questions\n- None ‚Äî design is straightforward\n\n## Design Discovery (Reference Context)\n\n\u003e Detailed context from brainstorming for task creation and obstacle handling.\n\n### Key Decisions Made\n\n| Question | User Answer | Implication |\n|----------|-------------|-------------|\n| What gap is the executor exhibiting? | Executor skips commits in practice | Need enforcement, not new capability |\n| What enforcement mechanism? | Strengthen prompt + lead checks | Two-point enforcement, no hooks |\n| Commit timing relative to bd close? | Before bd close (prerequisite) | Commit gates closure |\n| How should lead verify? | Executor reports commit hashes | Message format change, not git log |\n| Commit granularity? | One per task | Remove per-deliverable commits, consolidate |\n\n### Research Deep-Dives\n\n#### Current Executor Commit Flow\n**Question explored:** How does the executor currently handle commits?\n**Sources consulted:**\n- agents/executor.md:83-91 ‚Äî Step 6 Commit in TDD cycle\n- agents/executor.md:93-104 ‚Äî Verify completeness and Close steps\n\n**Findings:**\n- Commit is Step 6 after Refactor, per deliverable\n- Position makes it feel optional ‚Äî it's inside the TDD loop, not a gate before closure\n- No enforcement or verification that commit actually happened\n\n**Conclusion:** Reposition commit as a gate before bd close, not part of TDD cycle\n\n#### Lead Validation Gap\n**Question explored:** Does the lead check for commits?\n**Sources consulted:**\n- skills/executing-plans/SKILL.md:137-187 ‚Äî Task completion format and lead validation\n\n**Findings:**\n- Task completion message has no Commits section\n- Lead validation checks requirements, anti-patterns, Design Discovery ‚Äî but not commits\n- Zero enforcement on the lead side\n\n**Conclusion:** Add Commits to message format and Step 0 validation to lead\n\n### Dead-End Paths\nNone ‚Äî straightforward design with clear approach.\n\n### Open Concerns Raised\nNone ‚Äî user confirmed all design decisions.","status":"open","priority":2,"issue_type":"epic","owner":"abugosh@gmail.com","created_at":"2026-02-15T22:57:25.504358-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T22:57:25.504358-05:00"}
{"id":"bd-f6p","title":"Task 5: Add team vs solo routing to using-hyper skill","design":"## Goal\nUpdate skills/using-hyper/SKILL.md to include a decision point that routes to the team execution path (wave-planning ‚Üí team-executing-plans) when 3+ independent streams exist, and the solo path (writing-plans ‚Üí executing-plans) otherwise.\n\n## Context\nEpic bd-6t7 criterion #6: \"using-hyper routes to team path when 3+ independent streams exist, solo path otherwise.\"\n\nCurrently using-hyper has NO mention of team, wave, solo, or parallel execution. The brainstorming skill's Section 6 already includes the team vs. solo decision, but using-hyper's mandatory workflows section doesn't reference the team path at all.\n\n## Implementation\n\n### Step 1: Read current using-hyper skill\nFile: skills/using-hyper/SKILL.md\nUnderstand the structure and find the mandatory workflows section (Section 4).\n\n### Step 2: Update Section 4 (Follow Mandatory Workflows)\nIn the section that establishes mandatory workflows, add the team execution path alongside the existing solo path.\n\nCurrent text references:\n- hyperpowers:brainstorming (before writing code)\n- hyperpowers:test-driven-development (during implementation)\n- hyperpowers:verification-before-completion (before claiming done)\n\nAdd after brainstorming reference:\n- After brainstorming, if epic has 3+ independent streams ‚Üí use hyperpowers:wave-planning then hyperpowers:team-executing-plans\n- After brainstorming, if \u003c3 independent streams ‚Üí use hyperpowers:writing-plans then hyperpowers:executing-plans (existing solo path)\n\n### Step 3: Update the workflow description\nAdd a brief decision point explanation showing both paths:\n```\nbrainstorming ‚Üí sre-task-refinement\n  ‚Üí 3+ independent streams? ‚Üí wave-planning ‚Üí team-executing-plans\n  ‚Üí \u003c3 streams? ‚Üí writing-plans ‚Üí executing-plans (solo)\n```\n\n### Step 4: Add team skills to skill references\nEnsure wave-planning, team-executing-plans, and execute-wave command are mentioned where appropriate.\n\n### Step 5: Verify no regressions\n- Existing solo workflow references unchanged\n- using-hyper still works for all task types\n- Team path is ADDITIVE, not replacing anything\n\n## Success Criteria\n- [ ] using-hyper mentions team execution path (wave-planning, team-executing-plans)\n- [ ] Decision point documented: 3+ streams ‚Üí team, \u003c3 ‚Üí solo\n- [ ] Existing solo workflow references preserved (no regressions)\n- [ ] New skills referenced in appropriate sections\n\n## Anti-Patterns\n- DO NOT remove or modify existing solo path references\n- DO NOT make team path the default ‚Äî it's conditional on 3+ streams\n- DO NOT add excessive detail ‚Äî using-hyper is a meta-skill, keep it concise","status":"closed","priority":1,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-02-06T14:28:35.933374-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-06T14:32:42.569915-05:00","closed_at":"2026-02-06T14:32:42.569915-05:00","close_reason":"Added team vs solo routing decision point to using-hyper Section 4, updated rigidity/integration/workflow sections. All success criteria met.","dependencies":[{"issue_id":"bd-f6p","depends_on_id":"bd-6t7","type":"parent-child","created_at":"2026-02-06T14:28:49.134677-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-gm9","title":"Task 1: Rewrite test-runner agent with universal validation","design":"## Goal\nRewrite agents/test-runner.md to remove all pre-commit references and add universal validation with 'Run: validate' auto-detection.\n\n## Effort Estimate\n4-6 hours\n\n## Implementation\n\n### 1. Study existing agent structure\n- Read agents/test-runner.md (350 lines currently)\n- Identify all pre-commit specific sections to remove:\n  - Line ~3: description mentioning pre-commit\n  - Line ~7: 'pre-commit hooks' in mission\n  - Lines ~23-24: 'Pre-commit hooks: pre-commit run' command type\n  - Lines ~138-177: '### pre-commit hooks' section\n  - Lines ~186-220: 'git commit triggers pre-commit' logic\n  - Line ~257: 'Pre-commit Hook Assumption' section\n  - Lines ~296-306: Example 2: Pre-commit Hooks\n\n### 2. Remove pre-commit sections\nRemove all sections identified above. Use grep to verify removal:\n```bash\ngrep -n 'pre-commit' agents/test-runner.md  # Should return nothing after\n```\n\n### 3. Add Project Detection section (NEW)\nAdd after 'Execution Process' section:\n\n```markdown\n## Project Detection (for 'Run: validate')\n\nWhen 'Run: validate' is received, detect project type by file presence:\n\n### Detection Order (first match wins)\n1. package.json ‚Üí JavaScript/TypeScript\n2. Cargo.toml ‚Üí Rust\n3. pyproject.toml ‚Üí Python\n4. go.mod ‚Üí Go\n5. Makefile ‚Üí Generic\n\n### Validation Commands by Ecosystem\n\n**JavaScript/TypeScript (package.json)**\nParse scripts object for these keys (in order):\n- Format: format:check, fmt:check ‚Üí run if found\n- Lint: lint ‚Üí run if found\n- Typecheck: type-check, typecheck, tsc ‚Üí run if found, else try 'npx tsc --noEmit'\n- Test: test ‚Üí run if found\n\nExample: `npm run format:check \u0026\u0026 npm run lint \u0026\u0026 npm run type-check \u0026\u0026 npm test`\n\n**Rust (Cargo.toml)**\n- Format: cargo fmt -- --check\n- Lint: cargo clippy -- -D warnings\n- Typecheck: (included in clippy)\n- Test: cargo test\n\n**Python (pyproject.toml)**\n- Format: ruff format --check .\n- Lint: ruff check .\n- Typecheck: mypy . (skip if mypy not installed)\n- Test: pytest\n\n**Go (go.mod)**\n- Format: gofmt -l . (fail if output non-empty)\n- Lint: go vet ./...\n- Typecheck: (built into compiler)\n- Test: go test ./...\n\n**Makefile (fallback)**\nCheck for targets: format-check, lint, typecheck, test\nRun each that exists in Makefile\n```\n\n### 4. Add 'Run: validate' handling to Execution Process\nUpdate step 2 'Identify Command Type' to add:\n```markdown\n- Validate all: 'Run: validate' (triggers auto-detection)\n```\n\nAdd new step after 'Identify Command Type':\n```markdown\n3. **If 'Run: validate' received**:\n   - Detect project type using detection order above\n   - Run validations in order: Format ‚Üí Lint ‚Üí Typecheck ‚Üí Test\n   - Stop on first failure (don't continue to later categories)\n   - Skip any validation category where no command found\n   - Report what was skipped and why\n```\n\n### 5. Update report formats\nReplace pre-commit report formats with these exact templates:\n\n**Validation Passed:**\n```\n‚úì Validation passed\n- Format: ‚úì (npm run format:check)\n- Lint: ‚úì (npm run lint)\n- Typecheck: ‚úì (npx tsc --noEmit)\n- Test: ‚úì 47 passed (npm test)\n- Exit code: 0\n```\n\n**Validation Passed with Skips:**\n```\n‚úì Validation passed (2 skipped)\n- Format: ‚äò skipped (no format:check script found)\n- Lint: ‚úì (npm run lint)\n- Typecheck: ‚äò skipped (no type-check script found)\n- Test: ‚úì 47 passed (npm test)\n- Exit code: 0\n```\n\n**Validation Failed:**\n```\n‚úó Validation failed at lint\n- Format: ‚úì (npm run format:check)\n- Lint: ‚úó 3 errors (npm run lint)\n- Typecheck: (not run - lint failed)\n- Test: (not run - lint failed)\n- Exit code: 1\n\nFAILURES:\n\nlint (npm run lint):\n  src/utils.ts:15:1 - error: 'foo' is defined but never used\n  [COMPLETE output - not truncated]\n```\n\n**No Project Detected:**\n```\n‚ö† No project configuration found\n- Searched for: package.json, Cargo.toml, pyproject.toml, go.mod, Makefile\n- None found in current directory\n\nUse explicit commands instead:\n  Run: npm test\n  Run: cargo test\n  Run: pytest\n```\n\n### 6. Update examples\nReplace Example 2 (pre-commit) with:\n\n**Example 2: Run Validate (JS/TS Project)**\n```\nUser request: 'Run: validate'\n\nYou do:\n1. Detect package.json ‚Üí JS/TS project\n2. Parse scripts: { 'lint': 'eslint .', 'test': 'vitest' }\n3. Run npm run lint (pass)\n4. Skip format:check (not found)\n5. Skip type-check (not found)\n6. Run npm test (45 passed)\n7. Return validation report\n\nUser sees: Category breakdown with 2 skipped\n```\n\n**Example 3: Validation with Skipped Categories**\n```\nUser request: 'Run: validate'\n\nYou do:\n1. Detect pyproject.toml ‚Üí Python project\n2. Run ruff format --check . (pass)\n3. Run ruff check . (pass)\n4. Run mypy . (command not found - skip)\n5. Run pytest (23 passed)\n6. Return report showing mypy skipped\n\nUser sees: Validation passed with typecheck skipped\n```\n\n## Success Criteria\n- [ ] `grep -c 'pre-commit' agents/test-runner.md` returns 0\n- [ ] 'Run: validate' magic command documented with detection logic\n- [ ] All 5 ecosystems documented with exact commands:\n  - JS/TS: npm run format:check, npm run lint, npx tsc --noEmit, npm test\n  - Rust: cargo fmt --check, cargo clippy, cargo test\n  - Python: ruff format --check, ruff check, mypy, pytest\n  - Go: gofmt -l, go vet, go test\n  - Makefile: make format-check, make lint, make typecheck, make test\n- [ ] Report format templates include all 4 variants (pass, pass+skip, fail, no-project)\n- [ ] Explicit command handling preserved (existing 'Run: npm test' examples unchanged)\n- [ ] 3 new examples added showing 'Run: validate' flow\n- [ ] Agent description updated (line ~3) to remove pre-commit mention\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO breaking explicit command syntax ('Run: npm test' must still work exactly as before)\n- ‚ùå NO hardcoded file paths (use relative paths, let agent discover)\n- ‚ùå NO running format with --fix during validation (validation is read-only, use --check variants)\n- ‚ùå NO continuing after failure category (stop early, report clearly)\n- ‚ùå NO silent skipping (always report what was skipped and why)\n- ‚ùå NO assuming tools are installed (handle 'command not found' gracefully)\n\n## Key Considerations (SRE Review)\n\n**Edge Case: Multiple Config Files**\n- If both package.json AND Cargo.toml exist, first match wins (package.json)\n- Document this behavior explicitly: 'Detection order is strict - first match used'\n\n**Edge Case: No Config Files Found**\n- Report error with helpful message listing what was searched\n- Suggest explicit commands as alternative\n- Do NOT fail silently\n\n**Edge Case: Script/Command Not Found**\n- For JS/TS: If package.json exists but no 'lint' script, skip lint category\n- For Python: If mypy not installed, skip typecheck category\n- Always report skip with reason: '‚äò skipped (no lint script found)'\n\n**Edge Case: Partial Failures**\n- If format passes but lint fails, stop there\n- Report format as passed, lint as failed, remaining as 'not run'\n- Include full lint output in FAILURES section\n\n**Reference: Current Agent Structure**\nStudy existing report formats at lines 39-109 for consistent styling.\nStudy existing example format at lines 284-330 for consistent structure.\n\n## Verification Commands\nAfter completing rewrite, verify with:\n```bash\n# No pre-commit references\ngrep -c 'pre-commit' agents/test-runner.md  # Must be 0\n\n# Has 'Run: validate' documentation\ngrep -c 'Run: validate' agents/test-runner.md  # Should be 5+\n\n# Has all ecosystems\ngrep -c 'package.json' agents/test-runner.md  # Should be 2+\ngrep -c 'Cargo.toml' agents/test-runner.md    # Should be 2+\ngrep -c 'pyproject.toml' agents/test-runner.md # Should be 2+\ngrep -c 'go.mod' agents/test-runner.md        # Should be 2+\n\n# Has new report formats\ngrep -c 'Validation passed' agents/test-runner.md  # Should be 3+\ngrep -c 'skipped' agents/test-runner.md            # Should be 4+\n```","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-01-22T11:58:24.139544-05:00","created_by":"Alex Bugosh","updated_at":"2026-01-22T12:25:10.666679-05:00","closed_at":"2026-01-22T12:25:10.666679-05:00","close_reason":"Completed test-runner agent rewrite with universal validation system","dependencies":[{"issue_id":"bd-gm9","depends_on_id":"bd-9gk","type":"blocks","created_at":"2026-01-22T11:58:31.700712-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-lwy","title":"Create volatility-decomposition skill (SKILL.md + command)","design":"## Goal\nCreate the volatility-decomposition skill that guides architects through L√∂wy's volatility-based decomposition via Socratic dialogue, producing 2-3 alternative graph structures encoded in bd, with key decisions captured as ADRs.\n\n## Effort Estimate\n6-10 hours (documentation-heavy: ~400 line SKILL.md + examples + ADR template + command file)\n\n## Implementation\n\n### 1. Study existing skill patterns\nRead these files to internalize the structure and conventions:\n- skills/brainstorming/SKILL.md ‚Äî closest analog (Socratic, generative, produces bd artifacts). This is the primary reference.\n- skills/writing-plans/SKILL.md ‚Äî another skill that creates bd artifacts with detailed implementation steps\n- commands/brainstorm.md ‚Äî command file pattern (frontmatter + one-line instruction)\n- skills/common-patterns/bd-commands.md ‚Äî standard bd command examples to reference\n- skills/common-patterns/common-anti-patterns.md ‚Äî shared anti-patterns to reference\n- skills/common-patterns/common-rationalizations.md ‚Äî shared rationalizations to reference\n\n### 2. Create skills/volatility-decomposition/SKILL.md\n\nFollow the standard skill structure exactly:\n\n```yaml\n---\nname: volatility-decomposition\ndescription: L√∂wy volatility-based decomposition producing architecture graph in bd with ADRs\n---\n```\n\nRequired sections (in order):\n1. `\u003cskill_overview\u003e` ‚Äî 1-2 sentences: what and why\n2. `\u003crigidity_level\u003e` ‚Äî HIGH FREEDOM (Socratic questions adapt to domain, but output structure is rigid: always 2-3 alternatives, always bd encoding, always ADRs)\n3. `\u003cquick_reference\u003e` ‚Äî table mapping steps to actions and deliverables\n4. `\u003cwhen_to_use\u003e` ‚Äî triggers: project inception, major inflection points, when structure fights you, fractal sub-decomposition of large components. NOT for: inner-loop feature work, bug fixes, refactoring\n5. `\u003cthe_process\u003e` ‚Äî Steps 0-5 detailed below\n6. `\u003cexamples\u003e` ‚Äî 4 examples detailed below\n7. `\u003ccritical_rules\u003e` ‚Äî behavioral constraints\n8. `\u003cverification_checklist\u003e` ‚Äî evidence-based completion check\n9. `\u003cintegration\u003e` ‚Äî caller/callee relationships and agents\n10. `\u003cresources\u003e` ‚Äî links to common patterns, L√∂wy references, ADR template\n\n### 3. The Process ‚Äî Step-by-step content\n\n**Step 0 ‚Äî Context detection:**\n```bash\n# Check for existing architecture epic\nbd list --label arch --type epic --status open --json\n\n# If found: load it + all component nodes (REVISION MODE)\nbd show \u003cepic-id\u003e --json\nbd list --label arch,component --parent \u003cepic-id\u003e --json\n\n# If not found: INCEPTION MODE (starting fresh)\n```\n- If codebase exists: dispatch codebase-investigator with prompt: 'Map the current module/package structure, dependency graph between top-level modules, and any existing architectural boundaries. Stay at module level, not class/function level.'\n- If no codebase: pure design mode ‚Äî all evidence comes from Socratic dialogue\n\n**Step 1 ‚Äî Socratic questioning (L√∂wy framework):**\nUse AskUserQuestion tool for ALL questions. Do not print questions and wait.\n\nQuestion families (adapt to domain, but these are the core probes):\n\nForces discovery:\n- 'What are the 3-5 major forces acting on this system? What pushes it to change?'\n- 'Which of these forces are correlated (change together) vs independent?'\n\nVolatility identification (per force):\n- 'If you had to replace [X], what else would have to change?' (isolation test)\n- 'How often does [X] change? Monthly? Yearly? Never?'\n- 'Is this volatility (needs architectural encapsulation) or variability (handled with code)?'\n\nCustomer axis (L√∂wy's second dimension):\n- 'Do different customers/user types need different [X]?'\n- 'Will new customer segments require new behaviors here?'\n\nLayer assignment:\n- 'Is [component] orchestrating workflow (Manager), computing business logic (Engine), accessing data/external systems (Resource Accessor), or providing cross-cutting capability (Utility)?'\n- Challenge: 'You said this is an Engine, but it accesses the database directly ‚Äî should that be separated into a Resource Accessor?'\n\nFor REVISION MODE, shift to:\n- 'What about the current structure feels wrong? Where is it fighting you?'\n- 'If you restructure [X], what happens to its interfaces with [Y] and [Z]?'\n- 'Does splitting [X] create genuinely independent axes, or will the halves still change together?'\n\n**Step 2 ‚Äî Structure proposal:**\nPresent 2-3 alternative decompositions. NEVER present just one.\n\nEach proposal must include:\n- Node list: name, responsibility (1 sentence), volatility axis (what it encapsulates), L√∂wy layer\n- Edge list: which nodes have interface dependencies (blocks), which interact but don't block (relates_to)\n- What this decomposition optimizes for (e.g., 'maximizes isolation of payment volatility')\n- What it trades off (e.g., 'more components = more interfaces to maintain')\n\nFormat:\n```\n### Proposal A: [Name ‚Äî what it optimizes for]\n\n| Node | Responsibility | Volatility Axis | Layer |\n|------|---------------|-----------------|-------|\n| ... | ... | ... | Manager/Engine/RA/Utility |\n\nEdges:\n- [Node A] blocks [Node B] (interface: ...)\n- [Node C] relates_to [Node D] (interaction: ...)\n\nOptimizes for: [what]\nTrades off: [what]\n\n### Proposal B: [Name ‚Äî what it optimizes for]\n...\n```\n\nAfter presenting, ask: 'Which structure best matches your understanding of the system's volatility? You can also combine elements.'\n\n**Step 3 ‚Äî Encode in bd:**\nAfter architect chooses:\n\n```bash\n# Create architecture epic\nbd create '[System Name] Architecture' --type epic --label arch \\\n  --design '## System Purpose\n[1-2 sentences from Socratic dialogue]\n\n## L√∂wy Layer Map\n- Manager: [components]\n- Engine: [components]\n- Resource Accessor: [components]\n- Utility: [components]\n\n## Global Constraints\n[From Socratic dialogue ‚Äî cross-cutting rules]'\n\n# Create component nodes (one per component)\nbd create '[Component Name]' --type feature --label arch,component \\\n  --parent \u003cepic-id\u003e \\\n  --design '## Volatility Axis\n[What this component encapsulates ‚Äî which force/change it isolates]\n\n## Layer: [Manager|Engine|Resource Accessor|Utility]\n[Why this layer ‚Äî what it does and doesn't do]\n\n## Interface Contract\n- IN: [operations this component exposes]\n- OUT: [operations this component calls on others]\n\n## Responsibility\n[1-2 sentences ‚Äî what it does, what it does NOT do]'\n\n# Set initial stability state\nbd set-state \u003ccomponent-id\u003e stability=exploring \\\n  --reason 'initial decomposition, not yet audited'\n\n# Create edges\nbd dep add \u003cdownstream\u003e \u003cupstream\u003e --type blocks  # interface dependency\nbd relate \u003cnode-a\u003e \u003cnode-b\u003e                        # non-blocking interaction\n```\n\n**Step 4 ‚Äî Create ADRs:**\nFor each significant decomposition decision, guide the architect through creating an ADR.\n\nThe skill prompts the architect with a draft and asks for validation:\n```\nI'll draft an ADR for this decision. Review and I'll create the file:\n\n# ADR-NNN: [Decision Title]\n\n## Status\nAccepted\n\n## Context\n[Forces from Socratic dialogue, neutral language]\n\n## Decision\nWe will [active voice, full sentences].\n\n## Consequences\n- [Positive consequence]\n- [Negative consequence / tradeoff]\n- [What this enables or constrains for future work]\n```\n\nAfter architect approves, create the file using Write tool:\n- Location: doc/arch/adr-NNN.md (create doc/arch/ directory if needed)\n- Number sequentially (check existing ADRs first)\n- ADRs to create: one per major boundary decision, one per significant tradeoff accepted\n\n**Step 5 ‚Äî Handoff guidance:**\n```\n## Graph Summary\n[Table of nodes with stability status]\n\n## Recommended Next Steps\n- Run /audit-arch to stress-test this decomposition for hidden complection\n- [List nodes that might already be stable candidates if simple/obvious]\n- After audit: resolve or accept tensions, then stable nodes feed /brainstorm\n```\n\n### 4. Create commands/decompose.md\n```markdown\n---\ndescription: L√∂wy volatility-based decomposition producing architecture graph in bd with ADRs\n---\n\nUse the hyperpowers:volatility-decomposition skill exactly as written\n```\n\n### 5. Create skills/common-patterns/adr-template.md\nContent should include:\n- Nygard format explanation (Title, Status, Context, Decision, Consequences)\n- Status values: proposed, accepted, deprecated, superseded\n- Three example ADRs:\n  1. Decomposition decision: 'We will isolate [X] because [volatility axis]'\n  2. Tension resolution: 'We will [structural change] to resolve [tension]'\n  3. Tension acceptance: 'We accept [tension] because [reasoning]. Revisit if [condition].'\n- Guidance: consequences of one ADR become context for subsequent ADRs\n- File naming: doc/arch/adr-NNN.md, sequential, never reuse numbers\n\n## Examples to Write (4 required)\n\n### Example 1: Good decomposition with clear volatility axes\n- Scenario: Developer decomposes an order processing system\n- Shows: proper Socratic questioning, 2-3 proposals, architect chooses, bd encoding, ADR creation\n- Demonstrates: each node names its volatility axis, layer rules respected, interfaces explicit\n\n### Example 2: BAD ‚Äî Single recommendation instead of alternatives\n- Scenario: Developer proposes one decomposition and says 'this is the right structure'\n- Shows: why_it_fails (architect denied agency, missed better options, no tradeoff analysis)\n- Correction: present 2-3 alternatives with tradeoffs, let architect choose\n\n### Example 3: BAD ‚Äî Non-independent volatility axes (functional decomposition in disguise)\n- Scenario: Developer creates 'UserService', 'OrderService', 'ProductService' ‚Äî organized by business function, not volatility\n- Shows: why_it_fails (these are functional buckets, not volatility encapsulation ‚Äî User and Order both change when 'adding subscription support')\n- Correction: identify the actual independent axes (payment volatility, fulfillment volatility, pricing rules volatility) and encapsulate those\n\n### Example 4: Good revision of an existing graph\n- Scenario: After audit found tension, architect re-invokes decompose to restructure\n- Shows: loading existing graph, targeted Socratic questions about the restructuring, proposing 2-3 revision options, updating bd nodes, creating ADR for the structural change\n\n## Key Behavioral Constraints to Encode in Critical Rules\n- ALWAYS present 2-3 alternatives, NEVER single recommendations\n- Every node MUST name its volatility axis explicitly ('this encapsulates changes in [X]')\n- Challenge when two nodes change for the same reason (independence violation)\n- Challenge when interfaces carry more than one concern (leaky abstraction)\n- Enforce L√∂wy layer rules: no upward deps, Managers have no business logic, Engines don't access resources directly\n- Scale-agnostic vocabulary: adapt 'component/module/service' to context\n- Think in components and boundaries, NOT classes and functions\n- Distinguish volatility (architectural) from variability (code-level) ‚Äî only volatility drives decomposition\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Edge Case: Pure Greenfield (no codebase, no existing graph)**\n- Step 0 finds nothing ‚Äî no epic, no codebase\n- Skill must work entirely from Socratic dialogue\n- All evidence comes from architect's domain knowledge\n- Questions should be more exploratory: 'Tell me about this system. What does it do? Who uses it?'\n- MUST NOT skip Step 0 and assume greenfield ‚Äî always check first\n\n**Edge Case: Revision Mode (existing graph)**\n- Step 0 loads existing epic + nodes\n- Socratic questions shift to: 'What feels wrong? Where is the structure fighting you?'\n- Proposals are revisions, not replacements ‚Äî may affect only 2-3 nodes\n- Must update existing nodes, not create duplicates\n- Use bd supersede if a node is being replaced, not just edited\n- Create ADR for the structural change explaining why the revision was needed\n\n**Edge Case: Architect Wants to Skip to Encoding**\n- Architect says 'I already know the decomposition, just encode it'\n- Skill should still ask key validation questions:\n  - 'Can you name the volatility axis for each component?' (if they can't, the decomposition isn't volatility-based)\n  - 'Are any two of these components likely to change for the same reason?' (independence check)\n- If answers are solid, proceed to encoding. If not, push back gently.\n\n**Edge Case: Architect Gives Minimal Answers**\n- Some architects answer with one word or 'yes/no'\n- Skill should provide concrete follow-up options via AskUserQuestion\n- Never print open-ended questions and wait ‚Äî always provide multiple-choice with an 'Other' option\n\n**Edge Case: bd set-state Not Available**\n- bd is evolving fast ‚Äî set-state may not exist in all versions\n- Fallback: use labels for stability tracking (label: arch:exploring, arch:stable)\n- Document the fallback in the skill\n\n**Edge Case: Fractal Sub-Decomposition**\n- Architect runs /decompose on a component that's already in an existing architecture graph\n- Must create sub-architecture within the existing node\n- Sub-components are children of the component node (hierarchical IDs: bd-a3f8.1)\n- Architecture of the sub-decomposition follows same rules (layers, volatility axes, ADRs)\n\n## Anti-Patterns for This Task\n- ‚ùå NO writing the skill from memory ‚Äî must study brainstorming/SKILL.md first to match structure\n- ‚ùå NO skipping examples ‚Äî all 4 examples are required (skills without examples get ignored)\n- ‚ùå NO vague example corrections ‚Äî corrections must show exact corrected output\n- ‚ùå NO placeholder text in any section ('[detailed above]', '[will be added]')\n- ‚ùå NO writing the ADR template without concrete examples (abstract templates are useless)\n\n## Success Criteria\n- [ ] skills/volatility-decomposition/SKILL.md exists with complete skill structure (all 10 sections listed in Implementation step 2)\n- [ ] commands/decompose.md exists with frontmatter + single-line invocation (matching commands/brainstorm.md pattern)\n- [ ] skills/common-patterns/adr-template.md exists with Nygard format + 3 concrete example ADRs\n- [ ] Process includes all 6 steps (0: context detection, 1: Socratic questioning, 2: structure proposal, 3: bd encoding, 4: ADR creation, 5: handoff guidance)\n- [ ] Step 1 uses AskUserQuestion tool exclusively (never prints questions and waits)\n- [ ] Step 2 presents exactly 2-3 alternatives with tradeoffs table format, NEVER a single recommendation\n- [ ] Step 3 shows exact bd create commands with all flags (--type, --label, --parent, --design)\n- [ ] Step 4 shows ADR drafting + Write tool file creation pattern\n- [ ] All 4 examples written with scenario/code/why_it_fails/correction structure\n- [ ] Example 3 specifically demonstrates functional decomposition anti-pattern (organized by business function, not volatility)\n- [ ] Critical rules section encodes all 8 behavioral constraints listed above\n- [ ] Verification checklist includes: 'every node names its volatility axis', 'all alternatives presented', 'ADRs created for key decisions'\n- [ ] Edge cases documented: greenfield, revision mode, skip-to-encoding, minimal answers, bd fallback, fractal sub-decomposition\n- [ ] Skill tested with subagent: give subagent scenario 'decompose a notification system for a SaaS product', verify it produces 2-3 alternatives (not 1), encodes in bd format, and drafts an ADR\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@gmail.com","created_at":"2026-02-14T22:57:04.743356-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T23:24:20.489796-05:00","closed_at":"2026-02-14T23:24:20.489796-05:00","close_reason":"Closed","labels":["arch","skills"],"dependencies":[{"issue_id":"bd-lwy","depends_on_id":"bd-7be","type":"parent-child","created_at":"2026-02-14T22:57:08.67418-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-n8o","title":"Task 1: Restructure executor commit flow and message format","design":"## Goal\nModify agents/executor.md to move commit from per-deliverable (inside TDD cycle) to per-task (gate before bd close), and update the task completion message format to include commit hashes.\n\n## Effort Estimate\n1-2 hours (markdown-only edits to a single file)\n\n## Implementation\n\n### 1. Study existing code\n- agents/executor.md:58-91 ‚Äî TDD cycle section (\"2. Execute with TDD\") containing Steps 1-6\n- agents/executor.md:83-91 ‚Äî Step 6 (Commit) inside TDD cycle ‚Äî THIS IS WHAT WE REMOVE\n- agents/executor.md:93-98 ‚Äî Section \"3. Verify completeness\"\n- agents/executor.md:100-106 ‚Äî Section \"4. Close the task\" ‚Äî commit gate goes BEFORE this\n- agents/executor.md:131-159 ‚Äî Message Protocol \u003e Task Completion Message ‚Äî add Commits section here\n- agents/executor.md:242-261 ‚Äî \"Rules (No Exceptions)\" section ‚Äî add anti-skip rule here\n\n### 2. Remove commit from TDD cycle\nIn the \"2. Execute with TDD\" section (line 56), remove Step 6 (Commit) at lines 83-91. The TDD cycle becomes Steps 1-5 only:\n- Step 1 ‚Äî Write failing test (RED) (line 60)\n- Step 2 ‚Äî Run test, confirm FAIL (line 63)\n- Step 3 ‚Äî Implement minimal code (GREEN) (line 70)\n- Step 4 ‚Äî Run test, confirm PASS (line 73)\n- Step 5 ‚Äî Refactor (line 80)\n\nNOTE: These are TDD steps nested inside Execution Loop section \"2. Execute with TDD\". Do NOT confuse with Execution Loop top-level sections (1. Plan substeps, 2. Execute with TDD, 3. Verify completeness, etc.).\n\nAlso update the introductory text at line 13 which says \"red-green-refactor-commit cycle\" ‚Äî change to \"red-green-refactor cycle\" since commit is no longer per-deliverable.\n\n### 3. Add commit as gate before bd close\nBetween section \"3. Verify completeness\" (lines 93-98) and section \"4. Close the task\" (lines 100-106), insert a new section. Renumber: current \"4. Close the task\" becomes \"5. Close the task\", current \"5. Propose next task\" becomes \"6. Propose next task\".\n\nNew section to insert:\n\n### 4. Commit\n\nCommit all work for this task. This is MANDATORY ‚Äî NEVER run bd close without committing first.\n\n```bash\ngit add \u003cspecific files changed in this task\u003e\ngit commit -m \"\u003cdescriptive message summarizing all task work\u003e\n\nbd: \u003ctask-id\u003e\"\n```\n\n**CRITICAL: Committing is a prerequisite to task closure. If you skip the commit, work is not saved and may be lost. NEVER rationalize skipping ‚Äî not \"I'll commit later\", not \"finish-branch will handle it\", not \"it's just a small change\".**\n\n### 4. Update task completion message format\nIn the Message Protocol section (lines 131-159), update the Task Completion Message format to include a Commits section between Done and Learned:\n\n```\n## Task \u003cid\u003e Complete\n\n### Done\n- [1-3 bullet summary of what was implemented]\n- [Key files created or modified]\n\n### Commits\n- [short hash]: [commit message summary]\n\n### Learned\n- [Discoveries that affect future tasks]\n- [Things that differed from assumptions]\n- [Or \"None ‚Äî executed as planned\"]\n\n### Changed from plan\n- [What deviated from the task description and why]\n- [Or \"None ‚Äî executed as planned\"]\n\n### Proposed next task\nTitle: [task title]\nGoal: [what it delivers ‚Äî one clear outcome]\nApproach: [how to implement, informed by learnings from this task]\nSRE refined: yes\nKey considerations: [corner cases identified by SRE refinement]\n```\n\n### 5. Add anti-skip rule\nIn the \"Rules (No Exceptions)\" section starting at line 242, add a new numbered rule:\n\n10. **Always commit before closing a task.** Run git add and git commit before bd close. NEVER defer commits to \"later\" or \"finish-branch\". Each task's work must be committed before closure. Include the commit hash(es) in your task completion message to the lead.\n\n## Anti-Patterns (Task-Specific)\n- ‚ùå Do NOT change TDD cycle behavior (RED-GREEN-REFACTOR stays exactly the same)\n- ‚ùå Do NOT change startup protocol, escalation triggers, completion protocol, or any behavior other than commit timing\n- ‚ùå Do NOT add commit back into the TDD cycle ‚Äî it goes ONLY before bd close\n- ‚ùå Do NOT use generic commit messages ‚Äî message must describe all task work\n\n## Success Criteria\n- [ ] Step 6 (Commit) at lines 83-91 removed from TDD cycle section\n- [ ] Line 13 intro text updated from \"red-green-refactor-commit\" to \"red-green-refactor\"\n- [ ] New section \"4. Commit\" added between Verify completeness and Close task\n- [ ] Sections after the new Commit section renumbered (Close=5, Propose=6)\n- [ ] Commit step has explicit anti-skip language with specific rationalizations called out\n- [ ] Task completion message format (lines 137-159) includes ### Commits section between Done and Learned\n- [ ] New rule #10 added to \"Rules (No Exceptions)\" section about mandatory commit before close\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@gmail.com","created_at":"2026-02-15T22:57:47.668858-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T23:04:23.833294-05:00","closed_at":"2026-02-15T23:04:23.833294-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-n8o","depends_on_id":"bd-dxf","type":"parent-child","created_at":"2026-02-15T22:57:51.01894-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-qdj","title":"Update brainstorming skill with architecture node auto-detection","design":"## Goal\nUpdate skills/brainstorming/SKILL.md to auto-detect architecture node references and load their context (volatility axis, interface contract, relevant ADRs, adjacent nodes) during Step 1, presenting this as context for the architect to curate during the brainstorm.\n\n## Effort Estimate\n2-4 hours (targeted update to existing file, not new skill creation)\n\n## Implementation\n\n### 1. Read current brainstorming skill\n- skills/brainstorming/SKILL.md ‚Äî the file to modify\n- Identify insertion point: Step 1 (Understanding the Idea), after 'Check current state'\n\n### 2. Add architecture node detection sub-section to Step 1\n\nAfter the existing 'Check current state' block, add architecture node detection:\n\na) Check for architecture graph:\n   bd list --label arch --type epic --status open\n\nb) If graph exists, check if user's request references an architecture node:\n   - By bd ID mention (user says 'bd-xxx')\n   - By component name mention (user mentions a name matching a node title)\n   - By explicit mention ('the payment component', 'the pricing engine')\n\nc) If arch node detected, load context:\n   - bd show \u003cnode-id\u003e ‚Äî get volatility axis, layer, interface contract, responsibility\n   - bd dep tree \u003cnode-id\u003e ‚Äî get adjacent nodes (blocks, relates_to)\n   - ls doc/arch/adr-*.md ‚Äî find related ADRs\n   - Read ADRs that mention the node or its volatility axis\n\nd) Present loaded context (NOT auto-insert as anti-patterns):\n   ```\n   Architecture context loaded for [node name]:\n   - Volatility axis: [from node design]\n   - Layer: [from node design]\n   - Interface contract: [from node design]\n   - Adjacent nodes: [from bd deps]\n   - Relevant ADRs:\n     - ADR-NNN: [title] ‚Äî [key decision and consequences]\n\n   These ADRs represent architectural decisions that may inform\n   anti-patterns for this epic.\n   ```\n\ne) Continue with normal brainstorming flow. Architect curates which\n   tradeoffs become anti-patterns during the Socratic dialogue.\n\n### 3. Handle edge cases\n\n- No architecture graph exists: detection finds nothing, proceed normally\n- Multiple nodes referenced: load context for all\n- Node is closed/stable: still load context (historical design decisions)\n- Node has no ADRs: note 'No ADRs found for this component'\n- User doesn't reference any node: skip detection, proceed normally\n\n### 4. Update integration section\n\nAdd reference to volatility-decomposition and architectural-audit skills\nin the integration section of brainstorming.\n\n## Success Criteria\n- [ ] Step 1 includes architecture node detection sub-section\n- [ ] Detection checks for bd ID, component name, and explicit mention\n- [ ] Context loading includes: volatility axis, layer, interface contract, adjacent nodes, ADRs\n- [ ] ADRs presented as context, NOT auto-inserted as anti-patterns\n- [ ] Edge cases handled (no graph, multiple nodes, closed nodes, no ADRs)\n- [ ] Integration section references outer-loop skills\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns\n- NO auto-inserting ADR tradeoffs as epic anti-patterns (architect curates)\n- NO modifying the existing brainstorming process steps (add, don't change)\n- NO breaking existing brainstorming functionality","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@gmail.com","created_at":"2026-02-14T23:34:50.069565-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T23:36:03.088094-05:00","closed_at":"2026-02-14T23:36:03.088094-05:00","close_reason":"Closed","labels":["arch","skills"],"dependencies":[{"issue_id":"bd-qdj","depends_on_id":"bd-7be","type":"parent-child","created_at":"2026-02-14T23:34:55.192929-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-qsc","title":"Revert wave/team execution system","design":"## Requirements (IMMUTABLE)\n- Remove all wave-planning and team-executing-plans skill files\n- Remove execute-wave command\n- Remove Parallelism Map from brainstorming epic template and all wave-related content\n- Restore simple brainstorming ‚Üí writing-plans ‚Üí executing-plans flow in using-hyper\n- Keep agent definition improvements (memory, permissionMode, disallowedTools) from commit 1460ce5\n- Bump version to 2.10.0\n\n## Success Criteria (MUST ALL BE TRUE)\n- [ ] skills/wave-planning/ directory deleted\n- [ ] skills/team-executing-plans/ directory deleted\n- [ ] commands/execute-wave.md deleted\n- [ ] brainstorming/SKILL.md has no Parallelism Map, no team vs solo decision, no team path handoff\n- [ ] using-hyper/SKILL.md has simple linear flow (brainstorming ‚Üí writing-plans ‚Üí executing-plans)\n- [ ] Agent files (code-reviewer, codebase-investigator, internet-researcher, test-runner) retain their memory/permissionMode/disallowedTools improvements\n- [ ] plugin.json version is 2.10.0\n- [ ] No references to wave-planning, team-executing-plans, or Parallelism Map remain in modified files\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n- NO reverting agent definition improvements (they are independently useful and unrelated to waves)\n- NO git revert or git reset (surgical edits are cleaner than mechanical reverts for mixed commits)\n- NO leaving dangling references to waves/Parallelism Map in brainstorming or using-hyper\n- NO modifying skills that weren't touched by the wave commits (writing-plans, executing-plans, etc.)\n\n## Approach\nSurgically remove wave-related content while preserving the independently valuable agent improvements. Delete 3 files entirely, edit brainstorming and using-hyper to restore pre-wave state, bump version.\n\n## Architecture\n- Delete: skills/wave-planning/, skills/team-executing-plans/, commands/execute-wave.md\n- Edit: skills/brainstorming/SKILL.md (remove ~172 lines of wave content)\n- Edit: skills/using-hyper/SKILL.md (restore ~24 lines to pre-wave routing)\n- Edit: .claude-plugin/plugin.json (version 2.9.0 -\u003e 2.10.0)\n- Keep: agents/*.md (all improvements retained)\n\n## Design Rationale\n### Problem\nThe wave/team execution system (5 commits, v2.9.0) does not match actual usage patterns. Work is mostly sequential, rarely has 3+ independent streams. When team execution is attempted, multiple agents struggle to work on the same repo simultaneously. The added ceremony (Parallelism Map, wave-planning, team-executing-plans) provides no value for the dominant use case.\n\n### Approaches Considered\n\n#### 1. Surgical revert (keep agent improvements) - CHOSEN\nSurgical editing is cleaner than git revert for commits that bundled unrelated changes. Agent improvements are independently valuable.\n\n#### 2. Full git revert of 5 commits - REJECTED\nWould also revert agent definition improvements. Creates 5 revert commits with noisy history.\n\n#### 3. Fail forward with simplified parallelism - REJECTED\nUser work is mostly sequential. The dispatching-parallel-agents skill already handles the rare case of independent failures.\n\n### Scope Boundaries\nIn scope: Remove wave system, restore simple flow, bump version\nOut of scope: Modifying writing-plans, executing-plans, or any other skills not touched by wave commits","status":"closed","priority":2,"issue_type":"epic","owner":"abugosh@gmail.com","created_at":"2026-02-14T07:42:13.195012-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T07:52:48.02669-05:00","closed_at":"2026-02-14T07:52:48.02669-05:00","close_reason":"Wave system reverted - all wave files deleted, brainstorming and using-hyper restored to simple flow, agent improvements preserved, version bumped to 2.10.0"}
{"id":"bd-t4i","title":"Evolve executing-plans to agent teams delegation model","design":"## Requirements (IMMUTABLE)\n\n1. Lead (main conversation context) orchestrates execution, never implements directly\n2. Single executor agent does all implementation work with TDD discipline\n3. Executor sends structured summaries to lead after each task completion\n4. Executor runs SRE refinement on proposed next tasks before sending to lead\n5. Executor escalates obstacles to lead when they might violate epic anti-patterns\n6. Lead validates proposed tasks against epic requirements/anti-patterns before approving\n7. Reviewer agent dispatched by lead for final verification (returns verdict only)\n8. bd remains source of truth for all task state (epic, tasks, dependencies)\n9. Same /execute-plan command triggers the new workflow (no new commands)\n10. No manual /clear cycling required during execution\n\n## Success Criteria (MUST ALL BE TRUE)\n\n- [ ] Lead context accumulates cross-task learnings without implementation verbosity\n- [ ] Executor follows TDD (red-green-refactor-commit) for all implementation\n- [ ] Structured message protocol works for task completion and escalation\n- [ ] Reviewer agent returns APPROVED/GAPS verdict without flooding lead context\n- [ ] Brainstorming handoff connects seamlessly to new execution model\n- [ ] Executor can read epic from bd and operate with full context\n- [ ] Obstacle escalation path works (executor ‚Üí lead ‚Üí Design Discovery check ‚Üí decision)\n- [ ] Lead can approve, reject, or modify proposed next tasks\n- [ ] All existing skill integrations preserved (TDD, verification, SRE refinement)\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n\n- ‚ùå NO solo execution in lead context (lead orchestrates, doesn't implement ‚Äî that's the whole point)\n- ‚ùå NO unstructured messages from executor (must follow defined protocol for summaries and escalations)\n- ‚ùå NO skipping SRE refinement on proposed tasks (executor refines before proposing)\n- ‚ùå NO automatic approval of proposed tasks (lead must validate against epic)\n- ‚ùå NO implementation details in lead context (only structured summaries ‚Äî context preservation is the goal)\n- ‚ùå NO parallel executors (single executor model ‚Äî this is delegation, not parallelism)\n- ‚ùå NO new commands (evolve /execute-plan, don't add /delegate-execution)\n- ‚ùå NO keeping old solo execution mode (hard commit to teams model)\n\n## Approach\n\nRewrite the executing-plans skill to use Claude Code's agent teams API. When invoked, the skill creates a team with one executor teammate. The lead stays in the main conversation context (where brainstorming happened), holding the epic vision, design decisions, and accumulated cross-task learnings. The executor agent works continuously through tasks with TDD, sending structured summaries back to the lead after each task.\n\nThe executor proposes next tasks (with SRE refinement already applied), and the lead validates against epic requirements and anti-patterns before approving. When obstacles arise, the executor escalates to the lead, who checks Design Discovery and decides.\n\nWhen the executor reports all success criteria met, the lead dispatches a reviewer agent (review-implementation as an agent) that returns APPROVED or GAPS FOUND. If gaps, lead sends executor to fix. If approved, lead shuts down executor and presents to user for manual validation.\n\n## Architecture\n\n### Artifacts\n- skills/executing-plans/SKILL.md ‚Äî REWRITE: lead orchestration workflow\n- agents/executor.md ‚Äî NEW: executor agent behavior (TDD, summaries, proposals, escalations)\n- agents/reviewer.md ‚Äî NEW: review-implementation as agent (verdict-only output)\n- skills/brainstorming/SKILL.md ‚Äî UPDATE: handoff section for new model\n- skills/using-hyper/SKILL.md ‚Äî UPDATE: workflow chain description\n\n### Data Flow\n```\nLead (main context)\n  ‚îÇ\n  ‚îú‚îÄ TeamCreate ‚Üí team with shared task list\n  ‚îú‚îÄ Task(executor) ‚Üí spawns executor with epic context\n  ‚îÇ   ‚îÇ\n  ‚îÇ   ‚îú‚îÄ Executor reads epic from bd\n  ‚îÇ   ‚îú‚îÄ Executor executes task (TDD)\n  ‚îÇ   ‚îú‚îÄ Executor ‚Üí SendMessage(lead, structured summary)\n  ‚îÇ   ‚îú‚îÄ Lead validates ‚Üí SendMessage(executor, approval/redirect)\n  ‚îÇ   ‚îú‚îÄ Executor creates bd task, continues\n  ‚îÇ   ‚îî‚îÄ ...repeats...\n  ‚îÇ\n  ‚îú‚îÄ Executor reports \"criteria met\"\n  ‚îú‚îÄ Task(reviewer) ‚Üí dispatches reviewer with epic ID\n  ‚îÇ   ‚îî‚îÄ Returns APPROVED or GAPS FOUND\n  ‚îÇ\n  ‚îú‚îÄ If GAPS ‚Üí SendMessage(executor, fix instructions)\n  ‚îú‚îÄ If APPROVED ‚Üí shutdown executor, cleanup team\n  ‚îî‚îÄ Present to user ‚Üí finish-branch\n```\n\n### Message Protocol\nExecutor ‚Üí Lead (task completion):\n  - What: summary of implementation\n  - Learned: discoveries affecting future tasks\n  - Changed: deviations from plan with reasoning\n  - Proposed next: title, goal, approach (SRE refined)\n\nExecutor ‚Üí Lead (escalation):\n  - Problem: what's blocking\n  - Options: approaches with tradeoffs\n  - Epic context needed: which anti-pattern/design decision is relevant\n\nLead ‚Üí Executor:\n  - Approval: proceed with proposed task\n  - Redirect: modified task or different direction\n  - Fix: specific gaps to address (from reviewer)\n\n## Parallelism Map\n\n### Independent Work Streams\n1. **Executor agent definition** (agents/executor.md)\n   - Agent prompt with TDD behavior, message protocol, escalation rules\n   - Estimated complexity: medium\n2. **Reviewer agent definition** (agents/reviewer.md)\n   - Agent prompt for review-implementation as verdict-only agent\n   - Estimated complexity: medium\n3. **Lead skill rewrite** (skills/executing-plans/SKILL.md)\n   - Complete rewrite of orchestration workflow using agent teams API\n   - Estimated complexity: high\n4. **Integration updates** (skills/brainstorming/SKILL.md, skills/using-hyper/SKILL.md)\n   - Handoff and workflow chain updates\n   - Estimated complexity: low\n\n### Stream Dependencies\n- Stream 3 depends on Streams 1 and 2 (lead skill references agent definitions)\n- Stream 4 depends on Stream 3 (integration references lead skill)\n- Streams 1 and 2 are fully independent\n\n### Suggested Waves\n- Wave 1: Streams 1, 2 (agent definitions ‚Äî independent, no shared files)\n- Wave 2: Stream 3 (lead skill ‚Äî references agent definitions)\n- Wave 3: Stream 4 (integration updates)\n\n### File Ownership Boundaries\n| Stream | Owns (exclusive) | Shared (needs coordination) |\n|--------|-------------------|-----------------------------|\n| Executor agent | agents/executor.md | ‚Äî |\n| Reviewer agent | agents/reviewer.md | ‚Äî |\n| Lead skill | skills/executing-plans/SKILL.md | ‚Äî |\n| Integration | skills/brainstorming/SKILL.md, skills/using-hyper/SKILL.md | ‚Äî |\n\n### Parallelism Assessment\n- Independent streams: 2 (agent definitions)\n- Recommendation: solo execution\n- Rationale: Only 2 independent streams in Wave 1, and Waves 2-3 are sequential. Coordination overhead not worthwhile.\n\n## Design Rationale\n\n### Problem\nThe current executing-plans workflow requires manual /clear cycling between tasks. Each /clear loses both the original design context from brainstorming and the accumulated cross-task learnings. The user is already acting as a manual \"team lead\" ‚Äî clearing context, re-invoking /execute-plan, reviewing, clearing again. This can be automated using Claude Code's agent teams feature.\n\n### Research Findings\n\n**Codebase:**\n- skills/executing-plans/SKILL.md ‚Äî Current solo execution with mandatory STOP checkpoints\n- Commit aa7d145 ‚Äî Old wave/team system removed because subagents couldn't coordinate\n- skills/brainstorming/SKILL.md ‚Äî Handoff currently says \"run /execute-plan\"\n- agents/ directory ‚Äî Existing agents (code-reviewer, codebase-investigator, internet-researcher, test-runner)\n\n**External:**\n- Claude Code agent teams API ‚Äî TeamCreate, TaskCreate, SendMessage, shared task lists\n- Teammates get persistent context (unlike old subagents)\n- Lead maintains independent macro context while teammates work\n- Direct messaging between agents (not just report-back)\n- Shared task list with file locking for coordination\n- One team per session, no nested teams\n\n### Approaches Considered\n\n#### 1. Evolve executing-plans with agent teams delegation ‚úì\n\n**What it is:** Rewrite executing-plans to spawn a single executor agent. Lead orchestrates from main context. Same /execute-plan command, new mechanics.\n\n**Investigation:**\n- Reviewed current executing-plans ‚Äî STOP checkpoints exist for context exhaustion\n- Reviewed agent teams API ‚Äî persistent teammate context solves this\n- User confirmed their manual workflow already mirrors this pattern\n\n**Pros:**\n- Solves context exhaustion (the core problem)\n- No UX change (same commands)\n- Lead preserves both design context and cross-task learnings\n- Clean separation of concerns (orchestration vs implementation)\n\n**Cons:**\n- Higher token cost (two concurrent sessions)\n- Agent teams still experimental\n\n**Chosen because:** Directly solves the stated problem, matches user's existing manual pattern, no UX disruption\n\n#### 2. New delegated-execution skill alongside executing-plans ‚ùå\n\n**What it is:** Create a separate skill and command (/delegate-execution) as an alternative mode.\n\n**Why we looked at this:** Conservative approach ‚Äî keep working system, add new option.\n\n**Investigation:**\n- User pushed back: \"Should we just hard commit?\"\n- Two execution paths = decision fatigue and maintenance burden\n- If delegation solves the problem, keeping the workaround is a crutch\n\n**‚ö†Ô∏è REJECTED BECAUSE:** Maintaining two execution paths contradicts the \"hard commit\" decision. The solo mode exists because of context exhaustion, which delegation solves.\n\n**üö´ DO NOT REVISIT UNLESS:** Agent teams API is removed or fundamentally broken.\n\n#### 3. Bring back wave parallelism with agent teams ‚ùå\n\n**What it is:** Resurrect the old wave/team system using agent teams API for parallel execution.\n\n**Why we looked at this:** Agent teams could solve the coordination problems that killed the old system.\n\n**Investigation:**\n- User clarified: \"single executor agent\" ‚Äî this is about delegation, not parallelism\n- Parallelism adds file conflict complexity\n- Single executor is simpler and solves the stated problem\n\n**‚ö†Ô∏è REJECTED BECAUSE:** User explicitly chose single executor model. The problem is context exhaustion, not execution speed.\n\n**üö´ DO NOT REVISIT UNLESS:** User explicitly requests parallel execution as a separate feature.\n\n### Scope Boundaries\n\n**In scope:**\n- Rewriting executing-plans skill for agent teams delegation\n- New executor agent definition\n- New reviewer agent definition\n- Brainstorming handoff update\n- using-hyper workflow chain update\n\n**Out of scope (deferred/never):**\n- Parallel execution with multiple agents (different feature, different epic)\n- Changes to brainstorming itself (only handoff message)\n- Changes to SRE refinement skill (executor uses it as-is)\n- Changes to TDD skill (executor follows it as-is)\n- Changes to finish-branch skill (runs in lead context as before)\n\n### Open Questions\n- Exact agent teams API usage patterns (TeamCreate params, spawn prompt format) ‚Äî resolve during implementation\n- How to handle executor context exhaustion on very large tasks ‚Äî may need executor-level task splitting\n- Whether reviewer agent should be a teammate or a subagent (subagent likely sufficient for one-shot analysis)\n\n## Design Discovery (Reference Context)\n\n### Key Decisions Made\n\n| Question | User Answer | Implication |\n|----------|-------------|-------------|\n| Single executor or wave parallelism? | Single executor | No parallel agents, delegation model only |\n| Review cadence? | Continuous with lead monitoring | No mandatory STOP checkpoints, lead monitors |\n| What context gets exhausted? | Both epic design and cross-task learnings | Lead must accumulate structured summaries |\n| Who decides on obstacles? | Executor escalates to lead | Lead has Design Discovery context for decisions |\n| Who creates next task? | Executor creates, lead approves | Executor runs SRE refinement before proposing |\n| Learnings flow? | Structured summaries via messages | Defined message protocol, not ad-hoc |\n| Alternative or replacement? | Hard commit ‚Äî replace executing-plans | No fallback solo mode |\n| Review-implementation as agent? | Yes | Reviewer agent returns verdict only |\n| SRE refinement during execution? | Executor runs it | Lead gets already-refined proposals |\n| Other agents needed? | No ‚Äî executor + reviewer covers it | Keep scope focused |\n| New command or evolve existing? | Evolve /execute-plan | Same command, new mechanics |\n\n### Research Deep-Dives\n\n#### Agent Teams API Capabilities\n**Question explored:** Does Claude Code agent teams solve the problems that killed the old wave system?\n**Sources consulted:**\n- https://code.claude.com/docs/en/agent-teams\n- Commit aa7d145 (removal of old system)\n\n**Findings:**\n- Old system used subagents (fire-and-forget, no persistence)\n- Agent teams gives teammates persistent context, messaging, shared task lists\n- Lead maintains independent macro context (key differentiator)\n- File locking prevents coordination conflicts\n- One team per session, no nested teams (constraint)\n\n**Conclusion:** Agent teams fundamentally different from old subagent approach. Solves coordination problems.\n\n#### Current Execution Pain Points\n**Question explored:** Why does the current workflow require /clear cycling?\n**Sources consulted:**\n- skills/executing-plans/SKILL.md\n- User workflow description\n\n**Findings:**\n- STOP checkpoints exist because context exhaustion makes execution unreliable\n- After 3-4 tasks, original design context gets compressed/lost\n- Cross-task learnings from early tasks are gone by later tasks\n- User manually acts as \"team lead\" ‚Äî clearing, reviewing, re-invoking\n\n**Conclusion:** Context exhaustion is the root cause. Delegation to a separate agent context solves it.\n\n### Dead-End Paths\n\n#### Alternative Mode (Both Solo and Delegated)\n**Why explored:** Conservative approach ‚Äî don't break what works\n**Investigation:** User pushed back (\"Should we just hard commit?\"), pointed out solo mode is a workaround\n\n**Why abandoned:** If delegation solves context exhaustion, keeping the workaround adds maintenance burden without value\n\n### Open Concerns Raised\n\n- \"Does this approach actually make sense?\" ‚Üí Yes, user's current workflow already mirrors this pattern manually\n- Token cost of two concurrent sessions ‚Üí Optimization concern, not design concern\n- Agent teams is experimental ‚Üí Temporary limitation, not design constraint","notes":"Documentation updates added to scope per user request. Update CLAUDE.md (Core Workflows section, Key Architecture Concepts), RECOMMENDATIONS.md, and README if it exists, to reflect the new delegated execution model replacing solo execution.","status":"closed","priority":2,"issue_type":"epic","owner":"abugosh@gmail.com","created_at":"2026-02-14T10:22:44.371663-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T12:37:24.039339-05:00","closed_at":"2026-02-14T12:37:24.039339-05:00","close_reason":"Closed"}
{"id":"bd-ttl","title":"Task 4: Upgrade agent definitions with new subagent features","design":"## Goal\nUpgrade the 4 agent definition files (test-runner, code-reviewer, codebase-investigator, internet-researcher) with new Claude Code subagent features: persistent memory, skills injection, permission modes, hooks, and disallowedTools.\n\n## Context\nCompleted bd-0i8: team-executing-plans skill references these agents.\nCompleted bd-7yn: Brainstorming skill updated with Parallelism Map.\nCompleted bd-b5u: wave-planning skill created.\n\nAgent definitions need upgrades per epic Architecture section:\n- agents/test-runner.md: Add permissionMode: dontAsk, disallowedTools: Edit, Write\n- agents/code-reviewer.md: Add memory: project, skills: [testing-anti-patterns]\n- agents/codebase-investigator.md: Add memory: project, permissionMode: plan\n- agents/internet-researcher.md: Add memory: user\n\n## Effort Estimate\n1-2 hours (4 small frontmatter edits with verification)\n\n## Implementation\n\n### Step 1: Study current agent frontmatter format\nRead all 4 agent files. Current frontmatter fields are: name, description, model.\nConfirm YAML delimiter format (--- on opening and closing lines).\n\n### Step 2: Update agents/test-runner.md\nAdd to frontmatter after model field:\n```yaml\npermissionMode: dontAsk\ndisallowedTools:\n  - Edit\n  - Write\n```\nRationale: test-runner only runs commands and reports results; it should never modify files (Edit, Write) and should auto-deny permission prompts (dontAsk).\n\n### Step 3: Update agents/code-reviewer.md\nAdd to frontmatter after model field:\n```yaml\nmemory: project\nskills:\n  - testing-anti-patterns\n```\nRationale: code-reviewer benefits from remembering codebase patterns across sessions (project memory) and needs testing anti-pattern knowledge preloaded.\n\n### Step 4: Update agents/codebase-investigator.md\nAdd to frontmatter after model field:\n```yaml\nmemory: project\npermissionMode: plan\n```\nRationale: codebase-investigator is read-only exploration (plan mode) and benefits from remembering codebase structure across sessions (project memory).\n\n### Step 5: Update agents/internet-researcher.md\nAdd to frontmatter after model field:\n```yaml\nmemory: user\n```\nRationale: internet-researcher benefits from remembering user technology preferences and research context across sessions (user-scoped memory).\n\n### Step 6: Verify all agents\nFor each file:\n1. Read the file back\n2. Confirm YAML frontmatter is syntactically valid (proper --- delimiters, correct indentation, proper list syntax)\n3. Confirm body content is completely unchanged (no accidental edits)\n4. Confirm existing fields (name, description, model) are unchanged\n5. Run git diff to verify only frontmatter sections were modified\n\n## Success Criteria\n- [ ] test-runner.md has permissionMode: dontAsk and disallowedTools list with Edit, Write\n- [ ] code-reviewer.md has memory: project and skills list with testing-anti-patterns\n- [ ] codebase-investigator.md has memory: project and permissionMode: plan\n- [ ] internet-researcher.md has memory: user\n- [ ] All agent frontmatter uses valid YAML syntax (proper list format with - prefix, correct indentation)\n- [ ] Existing agent body content (everything below closing ---) is byte-identical to before\n- [ ] Existing frontmatter fields (name, description, model) unchanged in all 4 files\n\n## Anti-Patterns\n- DO NOT modify agent body content (only frontmatter changes)\n- DO NOT change existing frontmatter fields (name, description, model)\n- DO NOT add features not specified in epic Architecture section\n- DO NOT use inline YAML array syntax [a, b] for lists ‚Äî use multi-line format for readability\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n### YAML Syntax\n- disallowedTools must use YAML list format (- Edit on separate line, - Write on separate line)\n- skills must use YAML list format (- testing-anti-patterns on separate line)\n- memory and permissionMode are scalar values (not lists)\n- Maintain consistent indentation (2 spaces) with existing frontmatter\n\n### Verification Method\n- This is a documentation-only project with no build system; verification is manual\n- Read each file back and confirm syntax plus unchanged body content\n- Use git diff to verify only frontmatter sections were modified\n\n### Feature Availability\n- These frontmatter fields are read by Claude Code plugin/agent system at runtime\n- If a field is not recognized by the runtime, it is silently ignored (no breakage)\n- Adding new fields is safe even if user Claude Code version is older","status":"closed","priority":1,"issue_type":"task","owner":"abugosh@jellyvision.com","created_at":"2026-02-06T13:30:55.7313-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-06T14:20:59.503288-05:00","closed_at":"2026-02-06T14:20:59.503288-05:00","close_reason":"All 4 agent definitions upgraded with new subagent features. Verified YAML syntax, unchanged body content, and correct frontmatter fields.","dependencies":[{"issue_id":"bd-ttl","depends_on_id":"bd-6t7","type":"parent-child","created_at":"2026-02-06T13:31:02.313855-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-tu6","title":"Feature: Data Flow Grounding for Outer Loop Architecture Skills","description":"The outer-loop architecture skills (volatility-decomposition, architectural-audit) gather structural evidence but miss how data actually flows through the system. This creates blind spots: decomposition boundaries that ignore data coupling, audit passes that miss flow-derived hidden dependencies and temporal coupling, and inner-loop handoffs without flow context. Adding a layered second investigator dispatch to three skills grounds architecture decisions in data reality.","design":"## Requirements (IMMUTABLE)\n1. Volatility-decomposition skill adds Step 0b: a second investigator dispatch that gathers data coupling evidence at module level, using Step 0a structural findings to target questions\n2. Architectural-audit skill adds Step 1b: a second investigator dispatch that gathers request path and undeclared data flow evidence, using Step 1a structural findings AND the bd architecture graph\n3. Audit passes 1 (Complection), 3 (Temporal Coupling), and 4 (Hidden Dependencies) weave flow evidence into existing analysis\n4. Brainstorming skill derives fresh data flow context when auto-detecting architecture nodes, presented alongside existing architectural context before Socratic questioning\n5. All flow derivation is ephemeral ‚Äî derived fresh each time, never persisted as artifacts\n6. Module-level resolution for all flow analysis (consistent with existing investigator resolution)\n7. Layered derivation: structural evidence gathered first (unchanged), then targeted flow questions using structural results\n\n## Success Criteria (MUST ALL BE TRUE)\n- [ ] Decomposition Step 0b dispatch prompt gathers data coupling evidence (shared data shapes, entry points crossing boundaries, hidden coupling through intermediaries)\n- [ ] Decomposition Steps 1-2 use coupling evidence (Socratic questions surface coupling costs, structure proposals annotate boundaries with data coupling)\n- [ ] Audit Step 1b dispatch prompt gathers request paths, undeclared data flows, and implicit ordering\n- [ ] Audit Pass 1 uses flow evidence (module participation in request paths as complection signal)\n- [ ] Audit Pass 3 uses flow evidence (flow-derived ordering as temporal coupling signal)\n- [ ] Audit Pass 4 uses flow evidence (undeclared flows as hidden dependency signal)\n- [ ] Brainstorming presents inbound/outbound/transform/request-path context when architecture node detected\n- [ ] No new files created ‚Äî only modifications to existing skill files\n- [ ] Existing skill processes unchanged outside of added steps\n- [ ] All tests passing (pre-commit hooks passing)\n\n## Anti-Patterns (FORBIDDEN)\n- ‚ùå NO persistent flow artifacts (ephemeral principle: data flows change as you build, stale graphs give false confidence)\n- ‚ùå NO modifications to ADR template (ADRs capture intent and consequences, not system state snapshots)\n- ‚ùå NO changes to codebase-investigator agent prompt (constraint is in what skills ASK for, not what the agent can do ‚Äî agent is already general-purpose)\n- ‚ùå NO 7th audit pass (data flow is evidence TYPE feeding existing passes, not a separate analytical concern)\n- ‚ùå NO function/class-level flow analysis (module level provides boundary-decision signal without noise)\n- ‚ùå NO single-dispatch approach (layered: structural first provides targeting context for flow questions ‚Äî without it, flow questions are unfocused)\n- ‚ùå NO flow evidence replacing structural evidence (additive ‚Äî flow evidence supplements, never replaces, existing structural evidence)\n- ‚ùå NO shared flow derivation template or common pattern file (each skill's prompt differs because consumers need different things ‚Äî coupling vs paths vs component scope ‚Äî extract pattern only if prompts converge over time)\n\n## Approach\nAdd a second investigator dispatch to three skills (decomposition, audit, brainstorming). Each dispatch uses structural findings from the first dispatch to ask targeted data flow questions. Prompts are skill-specific because consumers need different evidence: decomposition needs data coupling across boundaries, audit needs request paths and undeclared flows, brainstorming needs component-level inbound/outbound/transform context. Evidence weaves into existing processes ‚Äî no new steps, passes, or formats beyond the added dispatch.\n\n## Architecture\nThree skill files modified, zero new files, zero agent changes:\n\n### volatility-decomposition/SKILL.md\n- Step 0a: unchanged (structural investigation)\n- Step 0b (NEW): second dispatch ‚Äî 'Given these modules and boundaries, what data coupling exists across them?'\n- Steps 1-2: weave coupling evidence into Socratic questions and structure proposals\n\n### architectural-audit/SKILL.md\n- Step 1a: unchanged (6-bucket structural evidence)\n- Step 1b (NEW): second dispatch ‚Äî 'Given this graph, trace request paths and find undeclared flows'\n- Passes 1, 3, 4: weave flow evidence into existing analysis framework\n\n### brainstorming/SKILL.md\n- Architecture node detection: unchanged\n- Flow derivation (NEW): dispatch after loading node context ‚Äî 'What data enters, exits, and transforms in this component?'\n- Context presentation: add flow context alongside architectural context\n\n## Design Rationale\n### Problem\nThe outer-loop architecture skills (decomposition, audit) gather structural evidence ‚Äî imports, dependencies, co-change patterns ‚Äî which are proxies for how data actually moves through the system. Two components might look independent in module structure but be coupled in practice because the same data flows through both. Decomposition boundaries that ignore data coupling create interfaces that fight reality. Audit passes that lack flow evidence miss hidden dependencies and implicit ordering.\n\n### Research Findings\n**Codebase:**\n- skills/volatility-decomposition/SKILL.md ‚Äî Step 0 dispatches investigator for module structure/deps/boundaries only\n- skills/architectural-audit/SKILL.md ‚Äî Step 1 dispatches with 6 buckets (module structure, imports, co-change, call patterns, interfaces, shared state) ‚Äî none explicitly about data flows\n- agents/codebase-investigator.md ‚Äî general-purpose agent, already follows traces from entry points, can answer flow questions if asked\n- skills/brainstorming/SKILL.md ‚Äî auto-detects architecture nodes, loads volatility axis/layer/interface/ADRs but no flow context\n\n**Key insight:** The investigator CAN answer data flow questions ‚Äî the constraint is that no skill currently ASKS for them.\n\n### Approaches Considered\n\n#### 1. Skill-specific second dispatch prompts ‚úì\n**What it is:** Each skill adds its own second investigator dispatch with a tailored prompt. Decomposition asks about coupling. Audit asks about request paths. Brainstorming asks about component flows.\n\n**Investigation:**\n- Reviewed all three skill dispatch prompts ‚Äî each needs different flow evidence\n- Verified investigator agent handles focused questions well (adaptive scaling by scope)\n- Confirmed module-level resolution sufficient for boundary decisions\n\n**Pros:**\n- Minimal change (3 files modified, 0 new)\n- Each skill tailors prompt to its specific needs\n- No new abstractions or shared state\n\n**Cons:**\n- Flow prompting logic in 3 places (not DRY)\n\n**Chosen because:** Prompts genuinely differ between skills. Two consumers don't justify abstraction. YAGNI ‚Äî extract pattern if prompts converge later.\n\n#### 2. Common flow derivation template ‚ùå\n**What it is:** Shared pattern in skills/common-patterns/data-flow-derivation.md referenced by all three skills with parameters.\n\n**Why we looked at this:** DRY principle ‚Äî centralizing 'how to ask about flows' seems cleaner.\n\n**Investigation:**\n- Compared the three prompt needs ‚Äî coupling, request paths, component scope ‚Äî they differ significantly\n- Markdown template parameterization is awkward\n\n**‚ö†Ô∏è REJECTED BECAUSE:** Prompts differ enough that a shared template adds indirection without real reuse. Two consumers don't justify the abstraction.\n\n**üö´ DO NOT REVISIT UNLESS:** A fourth skill needs flow evidence AND its prompt converges with existing ones.\n\n#### 3. Investigator agent enhancement ‚ùå\n**What it is:** Add flow analysis mode to the codebase-investigator agent prompt. Skills dispatch with a mode flag.\n\n**Why we looked at this:** Most centralized approach ‚Äî teach the agent once, use everywhere.\n\n**Investigation:**\n- Agent is already general-purpose and handles focused questions well\n- Adding a 'mode' creates agent complexity for marginal benefit\n\n**‚ö†Ô∏è REJECTED BECAUSE:** The constraint is in what skills ASK, not what the agent CAN do. Agent is already capable.\n\n**üö´ DO NOT REVISIT UNLESS:** The investigator is being redesigned for other reasons AND flow analysis is a common request.\n\n### Scope Boundaries\n**In scope:**\n- Second dispatch prompts for decomposition, audit, brainstorming\n- Weaving flow evidence into existing processes (Steps 1-2, Passes 1/3/4, context presentation)\n\n**Out of scope (deferred/never):**\n- ADR template changes (decided: ADRs stay pure)\n- Investigator agent changes (decided: skills ask differently, agent stays general)\n- Function-level flow analysis (decided: module level sufficient)\n- Persistent flow artifacts (decided: ephemeral principle)\n- Inner-loop execution changes (brainstorming loads context, execution unchanged)\n\n### Open Questions\n- Exact wording of Step 0b/1b prompts will be refined during implementation as we see what the investigator produces\n- Whether brainstorming flow context should be presented as a separate block or integrated into existing context block (decide during implementation)\n\n## Design Discovery (Reference Context)\n\n### Key Decisions Made\n\n| Question | User Answer | Implication |\n|----------|-------------|-------------|\n| What kind of data flows matter? | Both coupling and request paths | Decomposition uses coupling, audit uses paths ‚Äî different prompts per skill |\n| What resolution for flow analysis? | Module level (same as now) | No function/class-level analysis needed ‚Äî boundary decisions don't need data shapes |\n| How to gather flow evidence? | Layered: structural first, then flow | Second dispatch uses first dispatch results to target questions precisely |\n| Weave into passes or add 7th? | Weave into existing passes | Flow is evidence type, not separate concern ‚Äî passes 1, 3, 4 enriched |\n| ADR flow state at decision time? | No, ADRs stay as-is | ADRs capture intent, not system state ‚Äî consistent with ephemeral principle |\n| Inner loop handoff? | Derive fresh at handoff time | Brainstorming dispatches focused query scoped to component ‚Äî no carry-forward |\n\n### Research Deep-Dives\n\n#### Current Evidence Gathering\n**Question explored:** What does each skill currently ask the investigator for?\n**Sources consulted:**\n- skills/volatility-decomposition/SKILL.md Step 0 ‚Äî module structure, deps, boundaries\n- skills/architectural-audit/SKILL.md Step 1 ‚Äî 6 buckets (structure, imports, co-change, calls, interfaces, state)\n- agents/codebase-investigator.md ‚Äî general-purpose, entry point tracing, adaptive scaling\n\n**Conclusion:** Gap is specific: no skill asks about data coupling or request path tracing. Investigator already capable.\n\n### Dead-End Paths\n\n#### Shared Flow Template\n**Why explored:** DRY principle suggested centralizing flow derivation logic\n**Investigation:** Compared three prompt needs ‚Äî they differ significantly (coupling vs paths vs component scope)\n**Why abandoned:** Template adds indirection without real reuse, prompts need to stay different\n\n#### Agent Enhancement\n**Why explored:** Most centralized approach\n**Investigation:** Agent already handles focused questions ‚Äî constraint is in what's asked, not capability\n**Why abandoned:** Unnecessary complexity in shared infrastructure\n\n### Open Concerns Raised\n- 'Flow prompting logic in 3 places isn't DRY' ‚Üí Acceptable because prompts genuinely differ; extract pattern if they converge later\n- 'Can investigator reliably trace data flows?' ‚Üí It traces from entry points already; module-level flow questions are within its capability\n- 'Second dispatch adds latency' ‚Üí Sequential but targeted; structural results make flow questions precise rather than exhaustive","status":"closed","priority":2,"issue_type":"epic","owner":"abugosh@gmail.com","created_at":"2026-02-15T09:04:27.664743-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T13:41:47.306217-05:00","closed_at":"2026-02-15T13:41:47.306217-05:00","close_reason":"All 3 tasks complete, reviewer approved, version bumped to 2.12.0"}
{"id":"bd-tu6.1","title":"Task 2: Add request path and flow dispatch to architectural-audit Step 1, weave into passes 1/3/4","design":"## Goal\nAdd Step 1b (second investigator dispatch for request paths, undeclared data flows, implicit ordering) to architectural-audit skill and enrich audit passes 1 (Complection), 3 (Temporal Coupling), and 4 (Hidden Dependencies) with flow evidence.\n\n## Effort Estimate\n2-4 hours\n\n## Implementation\n\n1. Read skills/architectural-audit/SKILL.md to confirm insertion points\n2. Add Step 1b after Step 1 evidence recording (line 145), before Step 2 (line 149)\n   - GATING CONDITION: Only dispatch when codebase exists (same as Step 1a -- line 143 already handles greenfield skip)\n   - Second dispatch to codebase-investigator, parameterized by Step 1a structural results AND bd architecture graph\n   - Prompt asks for: request paths through module boundaries, undeclared data flows between graph nodes, implicit ordering\n\n3. Step 1b dispatch prompt:\n   Based on these structural findings: [include Step 1a results -- module structure, imports, co-change, call patterns, interfaces, shared state]\n   And this architecture graph: [include graph nodes, edges, layers, volatility axes from Step 0]\n\n   Trace data flows at module level:\n   1. For each entry point in the codebase, trace the request path through modules. Which modules participate in each request path?\n   2. Identify data flows between modules that have no declared edge in the architecture graph (undeclared flows).\n   3. Identify implicit ordering: which modules must process data before others, and is this ordering captured in the graph edges?\n\n   Report at module level. Reference architecture graph node names where modules map to nodes.\n\n4. Weave flow evidence into Pass 1 (Complection, line 155+)\n   - Add \"Flow evidence:\" subsection alongside existing \"Graph evidence:\" and \"Codebase evidence:\"\n   - Content: Modules that participate in many unrelated request paths as complection signal (module braids concerns if it appears in request paths for independent features)\n\n5. Weave flow evidence into Pass 3 (Temporal Coupling, line 187+)\n   - Add \"Flow evidence:\" subsection\n   - Content: Flow-derived ordering as temporal coupling signal (modules that must process data in sequence but have no blocks edge)\n\n6. Weave flow evidence into Pass 4 (Hidden Dependencies, line 203+)\n   - Add \"Flow evidence:\" subsection\n   - Content: Undeclared data flows between graph nodes as hidden dependency signal (data flows between modules with no declared graph edge)\n\n7. Update quick reference table (line 18): Step 1 deliverable updated to include flow evidence\n\n## Implementation Checklist\n- [ ] Step 1b section added after line 145 (evidence recording), before line 149 (Step 2)\n- [ ] Step 1b gated on codebase existence (inherits greenfield skip from line 143)\n- [ ] Step 1b dispatch prompt references both structural findings AND bd architecture graph\n- [ ] Pass 1 has Flow evidence subsection (request path participation as complection signal)\n- [ ] Pass 3 has Flow evidence subsection (flow-derived ordering as temporal coupling signal)\n- [ ] Pass 4 has Flow evidence subsection (undeclared flows as hidden dependency signal)\n- [ ] All flow evidence wording uses neutral analytical language (passes self-check: no recommendations, no severity, no ordering)\n- [ ] No changes to Step 1a dispatch prompt (lines 106-141 unchanged)\n- [ ] No changes to passes 2, 5, or 6\n- [ ] No changes to self-check procedure (Step 3)\n- [ ] Quick reference table updated\n- [ ] Module-level resolution maintained in prompt text\n- [ ] Pre-commit hooks passing\n\n## Anti-Patterns (FORBIDDEN)\n- Do NOT modify the existing Step 1a dispatch prompt (lines 106-141)\n- Do NOT add a 7th audit pass (flow is evidence TYPE, not separate concern)\n- Do NOT change the codebase-investigator agent prompt\n- Do NOT add function/class-level detail (stay module-level)\n- Do NOT make flow evidence replace structural evidence (additive only)\n- Do NOT use recommendation, severity, or ordering language in any added text\n\n## Key Considerations (SRE REVIEW)\n\n**Hard Constraint: Neutral Analytical Tone**\nThe audit skill is RIGID about no recommendations. All flow evidence wording must pass the self-check in Step 3 (no \"should\", \"recommend\", \"better\", \"prefer\", \"consider changing\", no severity words, no ordering). Use pattern: \"Modules that participate in N request paths\" not \"Modules that participate in too many request paths\".\n\n**Edge Case: Greenfield Skip**\nStep 1b inherits the greenfield gating from line 143. When no codebase exists, Step 1b is not dispatched and passes use only graph evidence (no flow evidence subsections to reference).\n\n**Key Difference from Task 1**\nThe audit dispatch prompt must include the bd architecture graph (nodes, edges, layers) in addition to structural findings. This is because the audit compares actual flows against declared graph edges -- a comparison not relevant in decomposition.\n\n## Success Criteria\n- [ ] Step 1b section present between evidence recording and Step 2\n- [ ] Step 1b dispatch prompt references both structural findings AND graph\n- [ ] Pass 1 Flow evidence subsection present with request path complection signal\n- [ ] Pass 3 Flow evidence subsection present with flow-derived ordering signal\n- [ ] Pass 4 Flow evidence subsection present with undeclared flow signal\n- [ ] All added text passes audit self-check (neutral analytical language)\n- [ ] Existing Step 1a dispatch unchanged\n- [ ] Passes 2, 5, 6 unchanged\n- [ ] Quick reference table reflects Step 1 change\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"feature","owner":"abugosh@gmail.com","created_at":"2026-02-15T09:23:36.132591-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-15T09:25:02.683253-05:00","closed_at":"2026-02-15T09:25:02.683253-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-tu6.1","depends_on_id":"bd-tu6","type":"parent-child","created_at":"2026-02-15T09:23:36.179117-05:00","created_by":"Alex Bugosh"}]}
{"id":"bd-xom","title":"Task 1: Delete wave files and edit brainstorming + using-hyper","design":"## Goal\nRemove all wave/team execution content: delete 3 files, surgically edit brainstorming and using-hyper to remove wave references, bump version.\n\n## Implementation\n\n### Step 1: Delete wave-specific files\n- rm -rf skills/wave-planning/\n- rm -rf skills/team-executing-plans/\n- rm commands/execute-wave.md\n\n### Step 2: Edit skills/brainstorming/SKILL.md\nRemove these wave-specific additions (use git diff b5fb3fa..d45815b as reference):\n\na) Remove CAPTURE for Parallelism Map block (lines ~134-139):\n   The block starting with 'CAPTURE for Parallelism Map:' through 'These observations inform the Parallelism Map section in the epic.'\n\nb) Remove Parallelism Map section from epic template (lines ~218-250):\n   The entire '## Parallelism Map' section including Independent Work Streams, Stream Dependencies, Suggested Waves, File Ownership Boundaries, Parallelism Assessment\n\nc) Remove Team vs Solo Decision section (lines ~436-475):\n   From 'REQUIRED: Team vs. Solo Decision' through the AskUserQuestion block and team path handoff.\n   Restore the original simple handoff that was there before.\n\nd) Remove the team path example in examples section (~lines 860-924):\n   The example about 'Epic includes Parallelism Map identifying team execution opportunity'\n\ne) Remove Parallelism Map items from verification_checklist:\n   Lines about 'Parallelism Map section present', 'Parallelism Map assessment recommends', 'Team vs. solo decision point'\n\nf) Remove wave-planning and team-executing-plans from integration section:\n   Restore simpler call chain without wave references\n\n### Step 3: Edit skills/using-hyper/SKILL.md\nRestore pre-wave routing:\n\na) Restore simple mandatory workflow (section 4):\n   Replace team/solo fork with:\n   - Use hyperpowers:writing-plans to create detailed plan\n   - Use hyperpowers:executing-plans to implement iteratively\n\nb) Remove Parallelism Map routing diagram\n\nc) Remove team-executing-plans from rigid skills list\n\nd) Restore original 'User says X, this means Y' examples:\n   'Add user authentication' means brainstorming -\u003e writing-plans -\u003e executing-plans -\u003e TDD -\u003e verification\n   Remove the microservice example that references team path\n\ne) Restore integration section:\n   Remove wave-planning -\u003e team-executing-plans from critical workflows\n   Keep writing-plans -\u003e executing-plans\n\n### Step 4: Bump version\nEdit .claude-plugin/plugin.json: version 2.9.0 -\u003e 2.10.0\n\n### Step 5: Verify\n- Grep for remaining references to wave-planning, team-executing-plans, Parallelism Map in edited files\n- Ensure agent files are untouched\n\n## Success Criteria\n- [ ] skills/wave-planning/ directory does not exist\n- [ ] skills/team-executing-plans/ directory does not exist\n- [ ] commands/execute-wave.md does not exist\n- [ ] brainstorming/SKILL.md has zero references to Parallelism Map, wave-planning, team-executing-plans, team path\n- [ ] using-hyper/SKILL.md has simple linear flow without team/solo fork\n- [ ] plugin.json version is 2.10.0\n- [ ] Agent files unchanged from current state\n- [ ] Pre-commit hooks passing","status":"closed","priority":2,"issue_type":"task","owner":"abugosh@gmail.com","created_at":"2026-02-14T07:43:24.907858-05:00","created_by":"Alex Bugosh","updated_at":"2026-02-14T07:52:51.126814-05:00","closed_at":"2026-02-14T07:52:51.126814-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bd-xom","depends_on_id":"bd-qsc","type":"blocks","created_at":"2026-02-14T07:43:35.076491-05:00","created_by":"Alex Bugosh"}]}
